{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a9b51ac-0c81-4ae2-a717-c9d35bb86de6",
   "metadata": {},
   "source": [
    "# AUTOENCODERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d361c29b-2701-4ba5-8a37-ed538f9e16df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T16:23:00.856584Z",
     "iopub.status.busy": "2024-03-10T16:23:00.856101Z",
     "iopub.status.idle": "2024-03-10T16:23:00.870902Z",
     "shell.execute_reply": "2024-03-10T16:23:00.869638Z",
     "shell.execute_reply.started": "2024-03-10T16:23:00.856548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc.weight', tensor([[-0.3223,  0.0716]])),\n",
       "             ('fc.bias', tensor([0.0114]))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple fully connected neural network class\n",
    "class SimpleFCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleFCNN, self).__init__()\n",
    "        \n",
    "        # Define a single linear layer since we want a model with only nn.Linear\n",
    "        # This layer directly maps 4 input features to 4 output features\n",
    "        self.fc = nn.Linear(in_features=2, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the fully connected layer\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "\n",
    "# Instantiate the fully connected neural network\n",
    "fcnn_model = SimpleFCNN()\n",
    "\n",
    "# Print the model structure\n",
    "fcnn_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8745651-b5b0-4d79-8282-214e288dff80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:13:55.096149Z",
     "iopub.status.busy": "2024-03-08T08:13:55.095587Z",
     "iopub.status.idle": "2024-03-08T08:13:55.113383Z",
     "shell.execute_reply": "2024-03-08T08:13:55.112100Z",
     "shell.execute_reply.started": "2024-03-08T08:13:55.096113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.weight',\n",
       "              tensor([[ 0.3309, -0.4868, -0.3303, -0.1680],\n",
       "                      [ 0.1641, -0.2915,  0.3169,  0.2656],\n",
       "                      [-0.2445, -0.3950, -0.1286, -0.4354],\n",
       "                      [ 0.2686, -0.1692,  0.3096, -0.1701]])),\n",
       "             ('encoder.bias', tensor([ 0.1251,  0.2211,  0.2355, -0.1253])),\n",
       "             ('decoder.weight',\n",
       "              tensor([[-0.1430,  0.0767,  0.2469, -0.0333],\n",
       "                      [-0.1145, -0.3200, -0.2623,  0.0253],\n",
       "                      [ 0.0284, -0.2398,  0.3292,  0.4865],\n",
       "                      [ 0.3379,  0.3544,  0.2553,  0.0811]])),\n",
       "             ('decoder.bias', tensor([-0.4867,  0.1027, -0.3841, -0.2913]))])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple autoencoder class\n",
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        \n",
    "        # Since this model only has input and output layers, and both have 4 neurons,\n",
    "        # we directly connect them without any hidden layers or compression\n",
    "        self.encoder = nn.Linear(in_features=4, out_features=4)\n",
    "        self.decoder = nn.Linear(in_features=4, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        encoded = self.encoder(x)\n",
    "        # Decoding\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleAutoencoder()\n",
    "\n",
    "# Print the model structure\n",
    "model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3977b054-e6d7-40e2-ad26-ecf982cf583c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T08:14:22.762079Z",
     "iopub.status.busy": "2024-03-08T08:14:22.761540Z",
     "iopub.status.idle": "2024-03-08T08:14:28.441517Z",
     "shell.execute_reply": "2024-03-08T08:14:28.440379Z",
     "shell.execute_reply.started": "2024-03-08T08:14:22.762043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Loss: 0.3521\n",
      "Epoch [201], Loss: 0.0708\n",
      "Epoch [401], Loss: 0.0479\n",
      "Epoch [601], Loss: 0.0386\n",
      "Epoch [801], Loss: 0.0322\n",
      "Epoch [1001], Loss: 0.0244\n",
      "Epoch [1201], Loss: 0.0162\n",
      "Epoch [1401], Loss: 0.0118\n",
      "Epoch [1601], Loss: 0.0094\n",
      "Epoch [1801], Loss: 0.0071\n",
      "Epoch [2001], Loss: 0.0053\n",
      "Epoch [2201], Loss: 0.0044\n",
      "Epoch [2401], Loss: 0.0039\n",
      "Epoch [2601], Loss: 0.0036\n",
      "Epoch [2801], Loss: 0.0034\n",
      "Epoch [3001], Loss: 0.0031\n",
      "Epoch [3201], Loss: 0.0029\n",
      "Epoch [3401], Loss: 0.0027\n",
      "Epoch [3601], Loss: 0.0026\n",
      "Epoch [3801], Loss: 0.0024\n",
      "Epoch [4001], Loss: 0.0022\n",
      "Epoch [4201], Loss: 0.0020\n",
      "Epoch [4401], Loss: 0.0019\n",
      "Epoch [4601], Loss: 0.0017\n",
      "Epoch [4801], Loss: 0.0015\n",
      "Epoch [5001], Loss: 0.0014\n",
      "Epoch [5201], Loss: 0.0013\n",
      "Epoch [5401], Loss: 0.0013\n",
      "Epoch [5601], Loss: 0.0013\n",
      "Epoch [5801], Loss: 0.0012\n",
      "Epoch [6001], Loss: 0.0012\n",
      "Epoch [6201], Loss: 0.0012\n",
      "Epoch [6401], Loss: 0.0012\n",
      "Epoch [6601], Loss: 0.0012\n",
      "Epoch [6801], Loss: 0.0011\n",
      "Epoch [7001], Loss: 0.0011\n",
      "Epoch [7201], Loss: 0.0011\n",
      "Epoch [7401], Loss: 0.0011\n",
      "Epoch [7601], Loss: 0.0010\n",
      "Epoch [7801], Loss: 0.0010\n",
      "Epoch [8001], Loss: 0.0009\n",
      "Epoch [8201], Loss: 0.0009\n",
      "Epoch [8401], Loss: 0.0008\n",
      "Epoch [8601], Loss: 0.0008\n",
      "Epoch [8801], Loss: 0.0007\n",
      "Epoch [9001], Loss: 0.0007\n",
      "Epoch [9201], Loss: 0.0006\n",
      "Epoch [9401], Loss: 0.0006\n",
      "Epoch [9601], Loss: 0.0006\n",
      "Epoch [9801], Loss: 0.0005\n",
      "Training stopped after reaching maximum epochs at Epoch [10000], Loss: 0.0005\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('encoder.0.weight', tensor([[-0.2985, -0.5488, -0.8609,  0.0186],\n",
      "        [-0.2296,  1.7202, -0.4502,  0.8622],\n",
      "        [-2.1323,  0.0362,  0.6688, -0.0542],\n",
      "        [ 0.0318,  0.4311, -0.5882, -0.5493]])), ('encoder.0.bias', tensor([ 0.9292, -1.8106,  1.3248, -0.0614])), ('decoder.0.weight', tensor([[-0.3472, -0.1198, -1.0738, -0.3162],\n",
      "        [-0.6869,  1.1415,  0.0114,  1.0410],\n",
      "        [-1.6802, -0.5308,  0.6121, -0.9965],\n",
      "        [ 0.5540,  1.4060, -0.3926, -1.5674]])), ('decoder.0.bias', tensor([ 0.9726,  1.7709, -0.2327,  1.0337]))])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, num_neurons, inputs, lr, max_epochs, stabilization_threshold, check_interval):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.inputs = inputs\n",
    "        self.lr = lr\n",
    "        self.max_epochs = max_epochs\n",
    "        self.stabilization_threshold = stabilization_threshold\n",
    "        self.check_interval = check_interval\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.loss_values = []\n",
    "\n",
    "        # Start training upon instantiation\n",
    "        self.train_autoencoder()\n",
    "\n",
    "        # Save the state dictionary for future use\n",
    "        self.state_dict = self.state_dict()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def train_autoencoder(self):\n",
    "        epoch = 0\n",
    "        while True:\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self(self.inputs)\n",
    "            loss = self.criterion(outputs, self.inputs)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.loss_values.append(loss.item())\n",
    "\n",
    "            # Print loss every 100 epochs\n",
    "            if epoch % 200 == 0:\n",
    "                print(f'Epoch [{epoch+1}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "            # Check for stopping condition every 'check_interval' epochs\n",
    "            if epoch >= self.check_interval:\n",
    "                recent_loss_decay = self.loss_values[-self.check_interval] - self.loss_values[-1]\n",
    "                if recent_loss_decay < self.stabilization_threshold:\n",
    "                    print(f'Training stopped due to loss stabilization at Epoch [{epoch+1}], Loss: {loss.item():.4f}')\n",
    "                    break\n",
    "\n",
    "            epoch += 1\n",
    "            if epoch >= self.max_epochs:\n",
    "                print(f'Training stopped after reaching maximum epochs at Epoch [{epoch}], Loss: {loss.item():.4f}')\n",
    "                break\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.loss_values)\n",
    "        plt.title('Autoencoder Training Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming the parameters are defined as before:\n",
    "autoencoder = Autoencoder(num_neurons=4, inputs=torch.rand(10, 4), lr=0.001, max_epochs=10000, stabilization_threshold=0.00001, check_interval=200)\n",
    "autoencoder.plot_loss()\n",
    "\n",
    "# To access the saved state_dict:\n",
    "print(autoencoder.state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10449a9e-16ee-4c72-950c-053e1be22f91",
   "metadata": {},
   "source": [
    "### Simple and ComplicatedFCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65ee0d-3daa-4dcf-8300-f4dcf4f04a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "class SimpleFCNN(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SimpleFCNN, self).__init__()\n",
    "        self.fc = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "    def train_model(self, inputs, targets, epochs=100, lr=0.01):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.SGD(self.parameters(), lr=lr)\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "class ComplicatedFCNN(nn.Module):\n",
    "    def __init__(self, input_layer_features, hidden_layers_neurons, output_layer_features, inputs, targets):\n",
    "        super(ComplicatedFCNN, self).__init__()\n",
    "        \n",
    "        # Instantiate and train SimpleFCNN with inputs\n",
    "        self.simple_fcnn = SimpleFCNN(in_features=hidden_layers_neurons, out_features=hidden_layers_neurons)\n",
    "        self.simple_fcnn.train_model(inputs, targets)\n",
    "        simple_fcnn_state_dict = self.simple_fcnn.state_dict()\n",
    "        \n",
    "        # Define the complicated model using nn.Sequential\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=input_layer_features, out_features=hidden_layers_neurons),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=hidden_layers_neurons, out_features=hidden_layers_neurons),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=hidden_layers_neurons, out_features=hidden_layers_neurons),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=hidden_layers_neurons, out_features=output_layer_features),\n",
    "        )\n",
    "        \n",
    "        # Load the trained state_dict from SimpleFCNN into the last hidden layer of ComplicatedFCNN\n",
    "        self.model[4].weight.data = simple_fcnn_state_dict['fc.weight']\n",
    "        self.model[4].bias.data = simple_fcnn_state_dict['fc.bias']\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a936e26a-1cb8-489e-8c19-fed40a6097ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the autoencoder class with dynamic neuron numbers\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, num_neurons=4):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the autoencoder\n",
    "autoencoder = Autoencoder(num_neurons=4)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "# Dummy input data\n",
    "inputs = torch.rand(10, 4)  # Batch size of 10, 4 features each\n",
    "\n",
    "# List to store loss values\n",
    "loss_values = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = autoencoder(inputs)\n",
    "    loss = criterion(outputs, inputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Plotting the loss\n",
    "plt.plot(loss_values)\n",
    "plt.title('Autoencoder Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02be5b6-e295-40e2-9110-5f05999beb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the autoencoder class with dynamic neuron numbers\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, num_neurons=4):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the autoencoder\n",
    "autoencoder = Autoencoder(num_neurons=4)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "# Dummy input data\n",
    "inputs = torch.rand(10, 4)  # Batch size of 10, 4 features each\n",
    "\n",
    "# List to store loss values\n",
    "loss_values = []\n",
    "\n",
    "# Training parameters\n",
    "max_epochs = 10000  # Maximum number of epochs\n",
    "stabilization_threshold = 0.0001  # Threshold for loss stabilization\n",
    "check_interval = 100  # Interval for checking loss stabilization\n",
    "\n",
    "# Training loop\n",
    "epoch = 0\n",
    "while True:\n",
    "    optimizer.zero_grad()\n",
    "    outputs = autoencoder(inputs)\n",
    "    loss = criterion(outputs, inputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Check for stopping condition every 'check_interval' epochs after at least 'check_interval' epochs have been run\n",
    "    if epoch >= check_interval:\n",
    "        # Calculate loss decay over the last 'check_interval' epochs\n",
    "        recent_loss_decay = loss_values[-check_interval] - loss_values[-1]\n",
    "        # Check if loss decay is below the threshold\n",
    "        if recent_loss_decay < stabilization_threshold:\n",
    "            print(f'Training stopped due to loss stabilization at Epoch [{epoch+1}], Loss: {loss.item():.4f}')\n",
    "            break\n",
    "\n",
    "    # Increment epoch counter\n",
    "    epoch += 1\n",
    "    # Check for maximum number of epochs\n",
    "    if epoch >= max_epochs:\n",
    "        print(f'Training stopped after reaching maximum epochs at Epoch [{epoch}], Loss: {loss.item():.4f}')\n",
    "        break\n",
    "\n",
    "# Plotting the loss\n",
    "plt.plot(loss_values)\n",
    "plt.title('Autoencoder Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea49fec8-aef9-4fc5-b838-bfd746b97890",
   "metadata": {},
   "source": [
    "## STEP 5: Training the PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b1400-b1e7-4f3d-a5ff-1386de8567c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47b02c-3e2e-4b3d-8ae2-ab3833bfb6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed114d8d-61d7-4a82-9275-28f178087d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51408128-78ef-4fe3-b9ad-51bf0ab23eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 50001\n",
    "start = time.time()\n",
    "# Creation of the variables loss1_history, loss2_history and loss3_history for printing the evolution of the contribution of every loss term:\n",
    "# Plot the loss history as before\n",
    "\n",
    "loss_ic1_history = []\n",
    "loss_ic2_history = []\n",
    "loss_differential_equation_history = []\n",
    "loss_total_history = []\n",
    "\n",
    "loss_history = []  # To track loss over epochs\n",
    "threshold = 0.0001  # Predetermined threshold for stopping\n",
    "check_range = 200\n",
    "#initial_loss_value = 0.05\n",
    "\n",
    "for i in range(epochs):\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # compute initial condition 1 loss:\n",
    "    ic1_predicted= original_model(ic1_t_mu)\n",
    "    \n",
    "    residuals_ic1 = ic1_predicted - ic1_scope\n",
    "    \n",
    "    loss_ic1 = torch.mean((ic1_predicted - ic1_scope)**2)\n",
    "    loss_ic1_history.append(loss_ic1.item())\n",
    "\n",
    "\n",
    "    # compute initial condition 2 loss:\n",
    "    du_dtdmu_initial = torch.autograd.grad(outputs = ic1_predicted, inputs = ic1_t_mu, grad_outputs= torch.ones_like(ic1_predicted), create_graph= True)[0]\n",
    "    ic2_du_dt, ic2_du_dmu = du_dtdmu_initial[:, 0:1], du_dtdmu_initial[:,1:2]\n",
    "    \n",
    "    residuals_ic2 = ic2_du_dt- ic2_scope\n",
    "    \n",
    "    loss_ic2 = torch.mean((ic2_du_dt- ic2_scope)**2)\n",
    "    loss_ic2_history.append(loss_ic2.item())\n",
    "\n",
    "    # compute physic loss:\n",
    "    physic_domain_predicted = original_model(physic_domain_t_mu)\n",
    "    physic_domain_du_dtdmu = torch.autograd.grad(outputs = physic_domain_predicted, inputs = physic_domain_t_mu, grad_outputs= torch.ones_like(physic_domain_predicted), create_graph= True)[0]\n",
    "    physic_domain_d2u_d2t_d2mu = torch.autograd.grad(outputs = physic_domain_du_dtdmu[:,0:1], inputs = physic_domain_t_mu, grad_outputs= torch.ones_like(physic_domain_du_dtdmu[:,0:1]), create_graph= True)[0]\n",
    "    \n",
    "    residuals_differential_equation = physic_domain_d2u_d2t_d2mu[:,0:1] + physic_domain_t_mu[:,1:2] * physic_domain_du_dtdmu[:,0:1] + k * physic_domain_predicted \n",
    "    \n",
    "    loss_differential_equation = torch.mean( (physic_domain_d2u_d2t_d2mu[:,0:1] + physic_domain_t_mu[:,1:2] * physic_domain_du_dtdmu[:,0:1] + k * physic_domain_predicted )**2)\n",
    "    loss_differential_equation_history.append(loss_differential_equation.item())\n",
    "    \n",
    "    loss = loss_ic1 + lambda1 * loss_ic2 + lambda2 * loss_differential_equation\n",
    "    loss_total_history.append(loss.item())\n",
    "    loss_history.append(loss.item())\n",
    "    if i ==1:\n",
    "        \n",
    "        initial_loss_value = loss.item()        \n",
    "    \n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    # Update loss history and ensure it contains the losses of the last check_range epochs\n",
    "    if len(loss_history) > check_range:\n",
    "        loss_history.pop(0)  # Remove the oldest loss value\n",
    "    \n",
    "    # Check if the difference between max and min loss in the last 100 epochs is within the threshold\n",
    "    max_min_range = max(loss_history) - min(loss_history)\n",
    "    absolut_loss_value = sum(loss_history) / len(loss_history)\n",
    "    if len(loss_history) == check_range and max_min_range <= threshold and  absolut_loss_value < initial_loss_value:\n",
    "        print(f\"Stopping training at epoch {i} as the loss stabilized within the threshold.\")\n",
    "        print(f\"max_min_range = {max_min_range} \\n absolute_loss_value: {absolut_loss_value} \")\n",
    "        break\n",
    "    \n",
    "    if i%1000 == 0:\n",
    "        print(f\"Shape of ic1 residuals: {residuals_ic1.shape}\")\n",
    "        print(f'Decomposition of the loss terms: \\n loss({loss}) = loss1({loss_ic1}) + {lambda1} * loss2({loss_ic2}) + {lambda2} * loss3({loss_differential_equation})')\n",
    "        \n",
    "        test_predicted = original_model(test_in_t_constant_mu)\n",
    "        \n",
    "        plt.figure(figsize=(10,2.5))\n",
    "        plt.plot(test_in_t_mu[0].detach().numpy(), \n",
    "                 u_exact, \n",
    "                 label=\"Exact solution\", \n",
    "                 color=\"tab:grey\", \n",
    "                 alpha=0.6\n",
    "        )\n",
    "        plt.plot(\n",
    "                test_in_t_mu[0], \n",
    "                test_predicted[:,0].detach().numpy(), \n",
    "                label=\"PINN solution\", \n",
    "                color=\"tab:green\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "                    physic_in_t_mu[0].detach().numpy(), \n",
    "                    torch.zeros_like(physic_in_t_mu[0]), \n",
    "                    s=20, \n",
    "                    lw=0, \n",
    "                    color=\"tab:red\",\n",
    "                    alpha=0.6,\n",
    "                    label= \"Training points\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "                    test_in_t_mu[0], \n",
    "                    torch.zeros_like(test_in_t_mu[0]), \n",
    "                    s=20, \n",
    "                    lw=0, \n",
    "                    color=\"tab:green\",\n",
    "                    alpha=0.6,\n",
    "                    label= \"Seed points(testing)\"\n",
    "        )\n",
    "        #plt.title(f\"Exact and predicted solution \\n u(t=(0,1), $\\mu$ = {test_mu}), model: {original_model.__class__.__name__}, activation function: {original_model.activation()}, epoch = {i} \\n (learning rate: {learning_rate}, lambda1: {lambda1}, lambda2: {lambda2})\")\n",
    "        plt.title(f\"Exact and predicted solution \\n u(t=(0,1), $\\mu$ = {test_mu}), model: {original_model.__class__.__name__}, activation function: Tanh, epoch = {i} \\n (learning rate: {learning_rate}, lambda1: {lambda1}, lambda2: {lambda2})\")\n",
    "\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        torch.save({\n",
    "                    \"epoch\": i,\n",
    "                    \"model_state_dict\": original_model.state_dict(),\n",
    "                    \"optimiser_state_dict\": optimiser.state_dict(),\n",
    "                    \"loss\": loss,\n",
    "                   },                    \n",
    "                    f\"lr{learning_rate}_epoch{i}.pth\") #f\"lr{learning_rate}_epoch{i}.pth\")\n",
    "        print(f\"Saved the checkpoint corresponding to epoch: {i}\")\n",
    "end = time.time()\n",
    "execution_time = (end - start)\n",
    "print(f\"Training elapsed time (s): {execution_time}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6649e2-a848-449f-8c69-b5361a65c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss history as before\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_history, label='Loss over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ddaae-922a-4283-bf3f-43f79596794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_total_history[-1000:], label='Loss over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc5ccf-a2ae-4d15-97d2-2874239b6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_total_history, label='Loss over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8f80d-2ccc-4f8f-bdb0-ab58b79cd665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0faa82cc-210b-4bea-917f-1e439e81bab5",
   "metadata": {},
   "source": [
    "## STEP 7: Investigation of the loss terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9487fd7-6866-43c2-ab32-f064be36a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the contribution of every loss term (loss1, loss2 and loss3)\n",
    "fig, (loss1_2, loss3) = plt.subplots(1,2, layout = 'constrained', sharex = True, figsize = (15,5))\n",
    "#fig.suptitle(f\"Decomposition of the loss terms using {original_model.__class__.__name__} model and Tanh #{original_model.activation()}# activation function \\n (learning_rate: {learning_rate}, lambda1: {lambda1}, lambda2: {lambda2})\", fontsize = 14)\n",
    "fig.suptitle(f\"Decomposition of the loss terms using {original_model.__class__.__name__} model and Tanh activation function \\n (learning_rate: {learning_rate}, lambda1: {lambda1}, lambda2: {lambda2})\", fontsize = 14)\n",
    "\n",
    "loss1_2.plot(loss_ic1_history, label = \"loss1: residuals of u(t=0)=1\", color = \"tab:red\")\n",
    "loss1_2.plot(loss_ic2_history, label = \"loss2: residuals of du/dt(t=0)=0\", color = \"tab:blue\")\n",
    "loss1_2.set_title(\"loss1: (u(t=0)=1) and loss2: (du/dt(t=0)=0)\")\n",
    "loss1_2.set_xlabel(\"epochs\")\n",
    "loss1_2.set_ylabel(\"residuals\")\n",
    "loss1_2.grid()\n",
    "loss1_2.legend()\n",
    "\n",
    "loss3.plot(loss_differential_equation_history, label= \"loss3: residuals of the differential equation\", color = \"tab:grey\")\n",
    "loss3.set_title(\"loss3: residuals of the differential equation\")\n",
    "loss3.set_xlabel(\"epochs\")\n",
    "loss3.set_ylabel(\"residuals\")\n",
    "loss3.legend()\n",
    "loss3.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12471976-8e6a-4bc3-9fc2-67de49835233",
   "metadata": {},
   "source": [
    "## STEP9: Training using a different initialization & activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f431204a-ce45-470f-8bd4-d1a626336f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_func = \"LeakyReLU\"\n",
    "model_init = FCN_init(2,1,64,4, activation= activation_func)\n",
    "model_init.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9997911-17ff-4dbc-908e-38cfa1b3e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(model_init.state_dict()[\"fcs.0.weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee4774-4326-489f-a0d1-16fbb3ad1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init.fcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40e860-0cb9-43c6-8254-d9f109fb5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_init.parameters)\n",
    "print(model_init.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c47c7c-21f5-4f33-94ef-0a7877a0c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted_init = model_init(test_in_t_constant_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b2b84-e5cf-49f4-ab3a-02eece464dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2.5))\n",
    "plt.plot(test_in_t_mu[0].detach().numpy(), \n",
    "                 u_exact, \n",
    "                 label=\"Exact solution\", \n",
    "                 color=\"tab:grey\", \n",
    "                 alpha=0.6\n",
    ")\n",
    "plt.plot(test_in_t_mu[0], \n",
    "                 test_predicted_init[:,0].detach().numpy(), \n",
    "                 label=\"PINN solution (initial)\", \n",
    "                 color=\"tab:green\"\n",
    ")\n",
    "plt.scatter(\n",
    "        test_in_t_mu[0], \n",
    "        torch.zeros_like(test_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:green\",\n",
    "        alpha=0.6,\n",
    "        label= \"Seed points(testing)\"\n",
    ")\n",
    "plt.scatter(\n",
    "        physic_in_t_mu[0].detach().numpy(), \n",
    "        torch.zeros_like(physic_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:purple\",\n",
    "        alpha=0.6,\n",
    "        label= \"Training points\"\n",
    ")\n",
    "plt.title(f\"Exact and predicted solution \\n u(t=(0,1), $\\mu$ = {test_mu}), epoch = 1, model: {model_init.__class__.__name__}, activation function: {activation_func}()\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783efd8-c3f3-45c9-b5e8-68c47f70c38e",
   "metadata": {},
   "source": [
    "## STEP10: Inference Case (Check for a fixed value of mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc64f4-5020-4b92-85b6-d0a3c873ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mu = 5\n",
    "test_in_t_constant_mu = torch.stack([torch.linspace(0,1,point_resolution_test), test_mu*torch.ones(point_resolution_test)], -1).view(-1,2)\n",
    "u_exact = exact_solution(test_mu/(2*mass), w0, test_in_t_mu[0])\n",
    "#print(f\" Point seed list for mesh grid domain points: \\n \\t {test_in_t_constant_mu}\")\n",
    "#print(f\"Size of Domain training points: \\n \\t {test_in_t_constant_mu.size()}\")b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64d80f-7b0d-4bd0-a617-9dda19c0c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted_init = model_init(test_in_t_constant_mu)\n",
    "#print(test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1997cb3-aa24-40fc-9555-c4fb369ff878",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2.5))\n",
    "plt.plot(test_in_t_mu[0].detach().numpy(), \n",
    "                 u_exact, \n",
    "                 label=\"Exact solution\", \n",
    "                 color=\"tab:grey\", \n",
    "                 alpha=0.6\n",
    ")\n",
    "plt.plot(test_in_t_mu[0], \n",
    "                 test_predicted_init[:,0].detach().numpy(), \n",
    "                 label=\"PINN solution (initial)\", \n",
    "                 color=\"tab:green\"\n",
    ")\n",
    "plt.scatter(\n",
    "        test_in_t_mu[0], \n",
    "        torch.zeros_like(test_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:green\",\n",
    "        alpha=0.6,\n",
    "        label= \"Seed points(testing)\"\n",
    ")\n",
    "plt.scatter(\n",
    "        physic_in_t_mu[0].detach().numpy(), \n",
    "        torch.zeros_like(physic_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:purple\",\n",
    "        alpha=0.6,\n",
    "        label= \"Training points\"\n",
    ")\n",
    "plt.title(f\"Exact and predicted solution \\n u(t=(0,1), $\\mu$ = {test_mu}), epoch = 1, model: {model.__class__.__name__}, activation function: {activation_func}()\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed92aa21-2f28-4237-9d17-970a2eb65f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic1_t_mu\n",
    "physic_domain_t_mu\n",
    "loss_ic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe3d64-6f43-4b01-8375-59debe22d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_init = torch.optim.Adam(model_init.parameters(), lr= learning_rate)\n",
    "epochs = 10001\n",
    "start = time.time()\n",
    "# Creation of the variables loss1_history, loss2_history and loss3_history for printing the evolution of the contribution of every loss term:\n",
    "\n",
    "loss_ic1_history = []\n",
    "loss_ic2_history = []\n",
    "loss_differential_equation_history = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    optimizer_init.zero_grad()\n",
    "\n",
    "    # compute initial condition 1 loss:\n",
    "    ic1_predicted= model_init(ic1_t_mu)\n",
    "    loss_ic1 = torch.mean((ic1_predicted - ic1_scope)**2)\n",
    "    loss_ic1_history.append(loss_ic1.item())\n",
    "\n",
    "\n",
    "    # compute initial condition 2 loss:\n",
    "    du_dtdmu_initial = torch.autograd.grad(outputs = ic1_predicted, inputs = ic1_t_mu, grad_outputs= torch.ones_like(ic1_predicted), create_graph= True)[0]\n",
    "    ic2_du_dt, ic2_du_dmu = du_dtdmu_initial[:, 0:1], du_dtdmu_initial[:,1:2]\n",
    "    loss_ic2 = torch.mean((ic2_du_dt- ic2_scope)**2)\n",
    "    loss_ic2_history.append(loss_ic2.item())\n",
    "\n",
    "    # compute physic loss:\n",
    "    physic_domain_predicted = model_init(physic_domain_t_mu)\n",
    "    physic_domain_du_dtdmu = torch.autograd.grad(outputs = physic_domain_predicted, inputs = physic_domain_t_mu, grad_outputs= torch.ones_like(physic_domain_predicted), create_graph= True)[0]\n",
    "    physic_domain_d2u_d2t_d2mu = torch.autograd.grad(outputs = physic_domain_du_dtdmu[:,0:1], inputs = physic_domain_t_mu, grad_outputs= torch.ones_like(physic_domain_du_dtdmu[:,0:1]), create_graph= True)[0]\n",
    "    loss_differential_equation = torch.mean( (physic_domain_d2u_d2t_d2mu[:,0:1] + physic_domain_t_mu[:,1:2] * physic_domain_du_dtdmu[:,0:1] + k * physic_domain_predicted )**2)\n",
    "    loss_differential_equation_history.append(loss_differential_equation.item())\n",
    "    \n",
    "    loss = loss_ic1 + lambda1 * loss_ic2 + lambda2 * loss_differential_equation\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer_init.step()\n",
    "    \n",
    "    \n",
    "    if i%1000 == 0:\n",
    "        print(f'Decomposition of the loss terms: \\n loss({loss}) = loss1({loss_ic1}) + {lambda1} * loss2({loss_ic2}) + {lambda2} * loss3({loss_differential_equation})')\n",
    "        \n",
    "        test_predicted_init = model_init(test_in_t_constant_mu)\n",
    "        \n",
    "        plt.figure(figsize=(10,2.5))\n",
    "        plt.plot(test_in_t_mu[0].detach().numpy(), \n",
    "                 u_exact, \n",
    "                 label=\"Exact solution\", \n",
    "                 color=\"tab:grey\", \n",
    "                 alpha=0.6\n",
    "        )\n",
    "        plt.plot(\n",
    "                test_in_t_mu[0], \n",
    "                test_predicted_init[:,0].detach().numpy(), \n",
    "                label=\"PINN solution\", \n",
    "                color=\"tab:green\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "                    physic_in_t_mu[0].detach().numpy(), \n",
    "                    torch.zeros_like(physic_in_t_mu[0]), \n",
    "                    s=20, \n",
    "                    lw=0, \n",
    "                    color=\"tab:red\",\n",
    "                    alpha=0.6,\n",
    "                    label= \"Training points\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "                    test_in_t_mu[0], \n",
    "                    torch.zeros_like(test_in_t_mu[0]), \n",
    "                    s=20, \n",
    "                    lw=0, \n",
    "                    color=\"tab:green\",\n",
    "                    alpha=0.6,\n",
    "                    label= \"Seed points(testing)\"\n",
    "        )\n",
    "        plt.title(f\"Exact and predicted solution \\n u(t=(0,1), $\\mu$ = {test_mu}), model: {model_init.__class__.__name__}, activation function: {activation_func}, epoch = {i} \\n (learning rate: {learning_rate}, lambda1: {lambda1}, lambda2: {lambda2})\")\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "end = time.time()\n",
    "execution_time = (end - start)\n",
    "print(f\"Training elapsed time (s): {execution_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4dc233-a77a-4900-8de5-3654ccecd37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9487f44-ad23-4420-88c7-41131790de83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ae528-306f-40b5-a298-5dce14eaba59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e39052-be98-4bfb-b520-a2feaa0c01c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ad365-6b1e-4a56-9a2c-2aec7265400c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebfc107-2874-42bf-bb72-db2a75a19744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe967186-9538-49ad-a528-8ce63ac9dbb1",
   "metadata": {},
   "source": [
    "### Predicted values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29191fe-e164-4266-924f-748c213b7645",
   "metadata": {},
   "source": [
    "#### Generation of testing points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723f617-9cb9-41f5-93d3-4f4a8ec48c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generation of t and mu test points within the domain:\n",
    "point_resolution_test = 100\n",
    "\n",
    "# Testing points:\n",
    "test_in_t_mu = [torch.linspace(0,1,point_resolution_test), torch.linspace(1,10,point_resolution_test) ]\n",
    "test_domain_t_mu = torch.stack(torch.meshgrid(*test_in_t_mu, indexing='ij'), -1).view(-1, 2)\n",
    "\n",
    "# print(f\"Point seed list for mesh grid test points: \\n \\t \\n \\t: {test_in_t_mu}\")\n",
    "# print(f\"Test points \\n \\t [t, mu]: \\n \\t {test_domain_t_mu}\")\n",
    "# print(f\"Size of the test domain points: \\n \\t {test_domain_t_mu.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6805e044-070c-4c10-ad27-6293ac074988",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = original_model(test_in_t_constant_mu)\n",
    "#test_predicted.size()\n",
    "#test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd5d74-5f22-4316-9aac-43ca096917b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2.5))\n",
    "plt.plot(test_in_t_mu[0].detach().numpy(), \n",
    "                 u_exact, \n",
    "                 label=\"Exact solution\", \n",
    "                 color=\"tab:grey\", \n",
    "                 alpha=0.6\n",
    ")\n",
    "plt.plot(test_in_t_mu[0], \n",
    "                 test_predicted[:,0].detach().numpy(), \n",
    "                 label=\"PINN solution (initial)\", \n",
    "                 color=\"tab:green\"\n",
    ")\n",
    "plt.scatter(\n",
    "        test_in_t_mu[0], \n",
    "        torch.zeros_like(test_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:green\",\n",
    "        alpha=0.6,\n",
    "        label= \"Seed points(testing)\"\n",
    ")\n",
    "plt.scatter(\n",
    "        physic_in_t_mu[0].detach().numpy(), \n",
    "        torch.zeros_like(physic_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:purple\",\n",
    "        alpha=0.6,\n",
    "        label= \"Training points\"\n",
    ")\n",
    "### model and activation has to be manually adapted\n",
    "plt.title(f\"Exact and predicted solution for a nn with following architecture: [{original_input_size}, {original_hidden_layers}, {original_output_size}] \\n u(t=(0,1), $\\mu$ = {test_mu}), model: {original_model.__class__.__name__}, activation function: {original_model.activation}, epoch = 1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff570665-c6de-4a72-b37a-f63478a196ac",
   "metadata": {},
   "source": [
    "### Exact solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dd8001-d35a-4fb3-8415-645c98683966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_solution(d, w0, t):\n",
    "    \"Defines the analytical solution to the under-damped harmonic oscillator problem above.\"\n",
    "    assert d < w0             \n",
    "    w = np.sqrt(w0**2-d**2)\n",
    "    phi = np.arctan(-d/w)\n",
    "    A = 1/(2*np.cos(phi))\n",
    "    cos = torch.cos(phi+w*t)\n",
    "    exp = torch.exp(-d*t)\n",
    "    u = exp*2*A*cos\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8e8cd-082b-45c6-ab5e-379601fdb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to check if it works (calculation of the exact solution):\n",
    "test_mu = 5\n",
    "u_exact = exact_solution(test_mu/(2*mass), w0, test_in_t_mu[0])\n",
    "#u_exact.view(-1,1)\n",
    "#u_exact.size()\n",
    "#u_exact.numel()\n",
    "#u_exact.dim()\n",
    "#u_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8a0ae-39a3-4364-9611-283ecc3833ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#physic_in_t_mu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb8e88b-e242-4414-bd08-08551277e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the exact solution:\n",
    "plt.figure(figsize=(10,2.5))\n",
    "plt.plot(\n",
    "        test_in_t_mu[0], \n",
    "        u_exact, \n",
    "        label=\"Exact solution\", \n",
    "        color=\"tab:grey\", \n",
    "        alpha=0.6)\n",
    "plt.scatter(\n",
    "        test_in_t_mu[0], \n",
    "        torch.zeros_like(test_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:green\",\n",
    "        alpha=0.6,\n",
    "        label= \"Seed points (testing)\")\n",
    "plt.scatter(\n",
    "        physic_in_t_mu[0].detach().numpy(), \n",
    "        torch.zeros_like(physic_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:red\",\n",
    "        alpha=0.6,\n",
    "        label= \"Training points\")\n",
    "\n",
    "plt.title(f\"Exact solution \\n u(t=(0,1), $\\mu$ = {test_mu}) using {point_resolution_test} seed points\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e5ff1-1230-4fae-8dc7-3c584d695376",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = original_model(test_in_t_constant_mu)\n",
    "        \n",
    "        plt.figure(figsize=(10,2.5))\n",
    "        plt.plot(test_in_t_mu[0].detach().numpy(), \n",
    "                 u_exact, \n",
    "                 label=\"Exact solution\", \n",
    "                 color=\"tab:grey\", \n",
    "                 alpha=0.6\n",
    "        )\n",
    "        plt.plot(\n",
    "                test_in_t_mu[0], \n",
    "                test_predicted[:,0].detach().numpy(), \n",
    "                label=\"PINN solution\", \n",
    "                color=\"tab:green\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "                    physic_in_t_mu[0].detach().numpy(), \n",
    "                    torch.zeros_like(physic_in_t_mu[0]), \n",
    "                    s=20, \n",
    "                    lw=0, \n",
    "                    color=\"tab:red\",\n",
    "                    alpha=0.6,\n",
    "                    label= \"Training points\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "                    test_in_t_mu[0], \n",
    "                    torch.zeros_like(test_in_t_mu[0]), \n",
    "                    s=20, \n",
    "                    lw=0, \n",
    "                    color=\"tab:green\",\n",
    "                    alpha=0.6,\n",
    "                    label= \"Seed points(testing)\"\n",
    "        )\n",
    "        #plt.title(f\"Exact and predicted solution \\n u(t=(0,1), $\\mu$ = {test_mu}), model: {original_model.__class__.__name__}, activation function: {original_model.activation()}, epoch = {i} \\n (learning rate: {learning_rate}, lambda1: {lambda1}, lambda2: {lambda2})\")\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
