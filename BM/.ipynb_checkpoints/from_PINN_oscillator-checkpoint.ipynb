{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a9b51ac-0c81-4ae2-a717-c9d35bb86de6",
   "metadata": {},
   "source": [
    "# AUTOENCODERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d361c29b-2701-4ba5-8a37-ed538f9e16df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T09:54:53.046840Z",
     "iopub.status.busy": "2024-03-07T09:54:53.046414Z",
     "iopub.status.idle": "2024-03-07T09:54:53.060888Z",
     "shell.execute_reply": "2024-03-07T09:54:53.059605Z",
     "shell.execute_reply.started": "2024-03-07T09:54:53.046803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc.weight',\n",
       "              tensor([[-0.2300,  0.0610, -0.4844, -0.3599],\n",
       "                      [ 0.4819, -0.4584, -0.0099, -0.0046],\n",
       "                      [-0.4039, -0.3126,  0.3936, -0.0550],\n",
       "                      [-0.0478,  0.3998, -0.1586,  0.3507]])),\n",
       "             ('fc.bias', tensor([-0.3470,  0.3965,  0.1496, -0.4944]))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple fully connected neural network class\n",
    "class SimpleFCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleFCNN, self).__init__()\n",
    "        \n",
    "        # Define a single linear layer since we want a model with only nn.Linear\n",
    "        # This layer directly maps 4 input features to 4 output features\n",
    "        self.fc = nn.Linear(in_features=4, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the fully connected layer\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "\n",
    "# Instantiate the fully connected neural network\n",
    "fcnn_model = SimpleFCNN()\n",
    "\n",
    "# Print the model structure\n",
    "fcnn_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8745651-b5b0-4d79-8282-214e288dff80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T09:47:58.915595Z",
     "iopub.status.busy": "2024-03-07T09:47:58.915128Z",
     "iopub.status.idle": "2024-03-07T09:47:58.931981Z",
     "shell.execute_reply": "2024-03-07T09:47:58.930952Z",
     "shell.execute_reply.started": "2024-03-07T09:47:58.915559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.weight',\n",
       "              tensor([[-0.4837, -0.4077, -0.3691, -0.4330],\n",
       "                      [ 0.3193, -0.2560, -0.0922,  0.4375],\n",
       "                      [-0.2979, -0.0092,  0.3443, -0.3966],\n",
       "                      [-0.1895, -0.2794,  0.4555, -0.3780]])),\n",
       "             ('encoder.bias', tensor([ 0.2094,  0.1711, -0.3463,  0.4835])),\n",
       "             ('decoder.weight',\n",
       "              tensor([[ 0.4930, -0.0099,  0.1320, -0.0663],\n",
       "                      [ 0.0148,  0.0960,  0.2305, -0.0680],\n",
       "                      [ 0.0771, -0.3006,  0.2287, -0.2696],\n",
       "                      [-0.0929,  0.0299,  0.2040,  0.1660]])),\n",
       "             ('decoder.bias', tensor([-0.3453,  0.2428,  0.1851,  0.4270]))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple autoencoder class\n",
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        \n",
    "        # Since this model only has input and output layers, and both have 4 neurons,\n",
    "        # we directly connect them without any hidden layers or compression\n",
    "        self.encoder = nn.Linear(in_features=4, out_features=4)\n",
    "        self.decoder = nn.Linear(in_features=4, out_features=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        encoded = self.encoder(x)\n",
    "        # Decoding\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleAutoencoder()\n",
    "\n",
    "# Print the model structure\n",
    "model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3977b054-e6d7-40e2-ad26-ecf982cf583c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T09:49:13.106751Z",
     "iopub.status.busy": "2024-03-07T09:49:13.106291Z",
     "iopub.status.idle": "2024-03-07T09:49:17.911617Z",
     "shell.execute_reply": "2024-03-07T09:49:17.910676Z",
     "shell.execute_reply.started": "2024-03-07T09:49:13.106715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Loss: 0.2750\n",
      "Epoch [101], Loss: 0.1124\n",
      "Epoch [201], Loss: 0.0582\n",
      "Epoch [301], Loss: 0.0396\n",
      "Epoch [401], Loss: 0.0297\n",
      "Epoch [501], Loss: 0.0240\n",
      "Epoch [601], Loss: 0.0205\n",
      "Epoch [701], Loss: 0.0181\n",
      "Epoch [801], Loss: 0.0162\n",
      "Epoch [901], Loss: 0.0147\n",
      "Epoch [1001], Loss: 0.0134\n",
      "Epoch [1101], Loss: 0.0122\n",
      "Epoch [1201], Loss: 0.0111\n",
      "Epoch [1301], Loss: 0.0100\n",
      "Epoch [1401], Loss: 0.0089\n",
      "Epoch [1501], Loss: 0.0078\n",
      "Epoch [1601], Loss: 0.0067\n",
      "Epoch [1701], Loss: 0.0056\n",
      "Epoch [1801], Loss: 0.0047\n",
      "Epoch [1901], Loss: 0.0040\n",
      "Epoch [2001], Loss: 0.0035\n",
      "Epoch [2101], Loss: 0.0030\n",
      "Epoch [2201], Loss: 0.0027\n",
      "Epoch [2301], Loss: 0.0025\n",
      "Epoch [2401], Loss: 0.0023\n",
      "Epoch [2501], Loss: 0.0021\n",
      "Epoch [2601], Loss: 0.0020\n",
      "Epoch [2701], Loss: 0.0019\n",
      "Epoch [2801], Loss: 0.0018\n",
      "Epoch [2901], Loss: 0.0018\n",
      "Epoch [3001], Loss: 0.0017\n",
      "Epoch [3101], Loss: 0.0016\n",
      "Epoch [3201], Loss: 0.0016\n",
      "Epoch [3301], Loss: 0.0016\n",
      "Epoch [3401], Loss: 0.0015\n",
      "Epoch [3501], Loss: 0.0015\n",
      "Epoch [3601], Loss: 0.0015\n",
      "Epoch [3701], Loss: 0.0014\n",
      "Epoch [3801], Loss: 0.0014\n",
      "Epoch [3901], Loss: 0.0014\n",
      "Epoch [4001], Loss: 0.0014\n",
      "Epoch [4101], Loss: 0.0013\n",
      "Epoch [4201], Loss: 0.0013\n",
      "Epoch [4301], Loss: 0.0013\n",
      "Epoch [4401], Loss: 0.0013\n",
      "Epoch [4501], Loss: 0.0013\n",
      "Epoch [4601], Loss: 0.0012\n",
      "Epoch [4701], Loss: 0.0012\n",
      "Epoch [4801], Loss: 0.0012\n",
      "Epoch [4901], Loss: 0.0012\n",
      "Epoch [5001], Loss: 0.0012\n",
      "Epoch [5101], Loss: 0.0012\n",
      "Epoch [5201], Loss: 0.0011\n",
      "Epoch [5301], Loss: 0.0011\n",
      "Epoch [5401], Loss: 0.0011\n",
      "Epoch [5501], Loss: 0.0011\n",
      "Epoch [5601], Loss: 0.0011\n",
      "Epoch [5701], Loss: 0.0010\n",
      "Epoch [5801], Loss: 0.0010\n",
      "Epoch [5901], Loss: 0.0010\n",
      "Epoch [6001], Loss: 0.0010\n",
      "Epoch [6101], Loss: 0.0009\n",
      "Epoch [6201], Loss: 0.0009\n",
      "Epoch [6301], Loss: 0.0009\n",
      "Epoch [6401], Loss: 0.0009\n",
      "Epoch [6501], Loss: 0.0008\n",
      "Epoch [6601], Loss: 0.0008\n",
      "Epoch [6701], Loss: 0.0008\n",
      "Epoch [6801], Loss: 0.0007\n",
      "Epoch [6901], Loss: 0.0007\n",
      "Epoch [7001], Loss: 0.0007\n",
      "Epoch [7101], Loss: 0.0006\n",
      "Epoch [7201], Loss: 0.0006\n",
      "Epoch [7301], Loss: 0.0006\n",
      "Epoch [7401], Loss: 0.0006\n",
      "Epoch [7501], Loss: 0.0006\n",
      "Epoch [7601], Loss: 0.0005\n",
      "Epoch [7701], Loss: 0.0005\n",
      "Epoch [7801], Loss: 0.0005\n",
      "Epoch [7901], Loss: 0.0005\n",
      "Epoch [8001], Loss: 0.0005\n",
      "Epoch [8101], Loss: 0.0005\n",
      "Epoch [8201], Loss: 0.0005\n",
      "Epoch [8301], Loss: 0.0005\n",
      "Epoch [8401], Loss: 0.0004\n",
      "Epoch [8501], Loss: 0.0004\n",
      "Epoch [8601], Loss: 0.0004\n",
      "Epoch [8701], Loss: 0.0004\n",
      "Epoch [8801], Loss: 0.0004\n",
      "Epoch [8901], Loss: 0.0004\n",
      "Epoch [9001], Loss: 0.0004\n",
      "Training stopped due to loss stabilization at Epoch [9081], Loss: 0.0004\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('encoder.0.weight', tensor([[-1.3054e+00,  1.9935e-04,  1.3269e+00,  4.4422e-01],\n",
      "        [-3.1163e-01,  1.5596e+00,  6.8023e-01, -4.7007e-02],\n",
      "        [ 5.4279e-01, -4.8818e-01, -6.8223e-01,  1.0614e+00],\n",
      "        [ 1.7337e+00, -6.7088e-01, -5.9707e-01, -4.3808e-01]])), ('encoder.0.bias', tensor([ 0.3764,  0.3129, -0.5110, -0.4567])), ('decoder.0.weight', tensor([[-0.1671,  0.9679,  0.0744,  1.1380],\n",
      "        [-1.5278,  1.4326, -0.0323, -0.5101],\n",
      "        [ 1.2768,  0.6781, -0.3281,  1.1439],\n",
      "        [ 0.4583,  0.9958,  1.4477, -0.0614]])), ('decoder.0.bias', tensor([ 0.3444,  0.0301, -0.2844, -0.0803]))])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, num_neurons, inputs, lr, max_epochs, stabilization_threshold, check_interval):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.inputs = inputs\n",
    "        self.lr = lr\n",
    "        self.max_epochs = max_epochs\n",
    "        self.stabilization_threshold = stabilization_threshold\n",
    "        self.check_interval = check_interval\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.loss_values = []\n",
    "\n",
    "        # Start training upon instantiation\n",
    "        self.train_autoencoder()\n",
    "\n",
    "        # Save the state dictionary for future use\n",
    "        self.state_dict = self.state_dict()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def train_autoencoder(self):\n",
    "        epoch = 0\n",
    "        while True:\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self(self.inputs)\n",
    "            loss = self.criterion(outputs, self.inputs)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.loss_values.append(loss.item())\n",
    "\n",
    "            # Print loss every 100 epochs\n",
    "            if epoch % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "            # Check for stopping condition every 'check_interval' epochs\n",
    "            if epoch >= self.check_interval:\n",
    "                recent_loss_decay = self.loss_values[-self.check_interval] - self.loss_values[-1]\n",
    "                if recent_loss_decay < self.stabilization_threshold:\n",
    "                    print(f'Training stopped due to loss stabilization at Epoch [{epoch+1}], Loss: {loss.item():.4f}')\n",
    "                    break\n",
    "\n",
    "            epoch += 1\n",
    "            if epoch >= self.max_epochs:\n",
    "                print(f'Training stopped after reaching maximum epochs at Epoch [{epoch}], Loss: {loss.item():.4f}')\n",
    "                break\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.loss_values)\n",
    "        plt.title('Autoencoder Training Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming the parameters are defined as before:\n",
    "autoencoder = Autoencoder(num_neurons=4, inputs=torch.rand(10, 4), lr=0.001, max_epochs=10000, stabilization_threshold=0.00001, check_interval=200)\n",
    "autoencoder.plot_loss()\n",
    "\n",
    "# To access the saved state_dict:\n",
    "print(autoencoder.state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a936e26a-1cb8-489e-8c19-fed40a6097ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the autoencoder class with dynamic neuron numbers\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, num_neurons=4):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the autoencoder\n",
    "autoencoder = Autoencoder(num_neurons=4)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "# Dummy input data\n",
    "inputs = torch.rand(10, 4)  # Batch size of 10, 4 features each\n",
    "\n",
    "# List to store loss values\n",
    "loss_values = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = autoencoder(inputs)\n",
    "    loss = criterion(outputs, inputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Plotting the loss\n",
    "plt.plot(loss_values)\n",
    "plt.title('Autoencoder Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02be5b6-e295-40e2-9110-5f05999beb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the autoencoder class with dynamic neuron numbers\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, num_neurons=4):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(num_neurons, num_neurons),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the autoencoder\n",
    "autoencoder = Autoencoder(num_neurons=4)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n",
    "\n",
    "# Dummy input data\n",
    "inputs = torch.rand(10, 4)  # Batch size of 10, 4 features each\n",
    "\n",
    "# List to store loss values\n",
    "loss_values = []\n",
    "\n",
    "# Training parameters\n",
    "max_epochs = 10000  # Maximum number of epochs\n",
    "stabilization_threshold = 0.0001  # Threshold for loss stabilization\n",
    "check_interval = 100  # Interval for checking loss stabilization\n",
    "\n",
    "# Training loop\n",
    "epoch = 0\n",
    "while True:\n",
    "    optimizer.zero_grad()\n",
    "    outputs = autoencoder(inputs)\n",
    "    loss = criterion(outputs, inputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Check for stopping condition every 'check_interval' epochs after at least 'check_interval' epochs have been run\n",
    "    if epoch >= check_interval:\n",
    "        # Calculate loss decay over the last 'check_interval' epochs\n",
    "        recent_loss_decay = loss_values[-check_interval] - loss_values[-1]\n",
    "        # Check if loss decay is below the threshold\n",
    "        if recent_loss_decay < stabilization_threshold:\n",
    "            print(f'Training stopped due to loss stabilization at Epoch [{epoch+1}], Loss: {loss.item():.4f}')\n",
    "            break\n",
    "\n",
    "    # Increment epoch counter\n",
    "    epoch += 1\n",
    "    # Check for maximum number of epochs\n",
    "    if epoch >= max_epochs:\n",
    "        print(f'Training stopped after reaching maximum epochs at Epoch [{epoch}], Loss: {loss.item():.4f}')\n",
    "        break\n",
    "\n",
    "# Plotting the loss\n",
    "plt.plot(loss_values)\n",
    "plt.title('Autoencoder Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10449a9e-16ee-4c72-950c-053e1be22f91",
   "metadata": {},
   "source": [
    "### Simple and ComplicatedFCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65ee0d-3daa-4dcf-8300-f4dcf4f04a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "class SimpleFCNN(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(SimpleFCNN, self).__init__()\n",
    "        self.fc = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "    def train_model(self, inputs, targets, epochs=100, lr=0.01):\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.SGD(self.parameters(), lr=lr)\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "class ComplicatedFCNN(nn.Module):\n",
    "    def __init__(self, input_layer_features, hidden_layers_neurons, output_layer_features, inputs, targets):\n",
    "        super(ComplicatedFCNN, self).__init__()\n",
    "        \n",
    "        # Instantiate and train SimpleFCNN with inputs\n",
    "        self.simple_fcnn = SimpleFCNN(in_features=hidden_layers_neurons, out_features=hidden_layers_neurons)\n",
    "        self.simple_fcnn.train_model(inputs, targets)\n",
    "        simple_fcnn_state_dict = self.simple_fcnn.state_dict()\n",
    "        \n",
    "        # Define the complicated model using nn.Sequential\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=input_layer_features, out_features=hidden_layers_neurons),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=hidden_layers_neurons, out_features=hidden_layers_neurons),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=hidden_layers_neurons, out_features=hidden_layers_neurons),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=hidden_layers_neurons, out_features=output_layer_features),\n",
    "        )\n",
    "        \n",
    "        # Load the trained state_dict from SimpleFCNN into the last hidden layer of ComplicatedFCNN\n",
    "        self.model[4].weight.data = simple_fcnn_state_dict['fc.weight']\n",
    "        self.model[4].bias.data = simple_fcnn_state_dict['fc.bias']\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea49fec8-aef9-4fc5-b838-bfd746b97890",
   "metadata": {},
   "source": [
    "## STEP 5: Training the PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b1400-b1e7-4f3d-a5ff-1386de8567c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47b02c-3e2e-4b3d-8ae2-ab3833bfb6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed114d8d-61d7-4a82-9275-28f178087d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51408128-78ef-4fe3-b9ad-51bf0ab23eaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 50001\n",
    "start = time.time()\n",
    "# Creation of the variables loss1_history, loss2_history and loss3_history for printing the evolution of the contribution of every loss term:\n",
    "# Plot the loss history as before\n",
    "\n",
    "loss_ic1_history = []\n",
    "loss_ic2_history = []\n",
    "loss_differential_equation_history = []\n",
    "loss_total_history = []\n",
    "\n",
    "loss_history = []  # To track loss over epochs\n",
    "threshold = 0.0001  # Predetermined threshold for stopping\n",
    "check_range = 200\n",
    "#initial_loss_value = 0.05\n",
    "\n",
    "for i in range(epochs):\n",
    "    optimiser.zero_grad()\n",
    "\n",
    "    # compute initial condition 1 loss:\n",
    "    ic1_predicted= original_model(ic1_t_mu)\n",
    "    \n",
    "    residuals_ic1 = ic1_predicted - ic1_scope\n",
    "    \n",
    "    loss_ic1 = torch.mean((ic1_predicted - ic1_scope)**2)\n",
    "    loss_ic1_history.append(loss_ic1.item())\n",
    "\n",
    "\n",
    "    # compute initial condition 2 loss:\n",
    "    du_dtdmu_initial = torch.autograd.grad(outputs = ic1_predicted, inputs = ic1_t_mu, grad_outputs= torch.ones_like(ic1_predicted), create_graph= True)[0]\n",
    "    ic2_du_dt, ic2_du_dmu = du_dtdmu_initial[:, 0:1], du_dtdmu_initial[:,1:2]\n",
    "    \n",
    "    residuals_ic2 = ic2_du_dt- ic2_scope\n",
    "    \n",
    "    loss_ic2 = torch.mean((ic2_du_dt- ic2_scope)**2)\n",
    "    loss_ic2_history.append(loss_ic2.item())\n",
    "\n",
    "    # compute physic loss:\n",
    "    physic_domain_predicted = original_model(physic_domain_t_mu)\n",
    "    physic_domain_du_dtdmu = torch.autograd.grad(outputs = physic_domain_predicted, inputs = physic_domain_t_mu, grad_outputs= torch.ones_like(physic_domain_predicted), create_graph= True)[0]\n",
    "    physic_domain_d2u_d2t_d2mu = torch.autograd.grad(outputs = physic_domain_du_dtdmu[:,0:1], inputs = physic_domain_t_mu, grad_outputs= torch.ones_like(physic_domain_du_dtdmu[:,0:1]), create_graph= True)[0]\n",
    "    \n",
    "    residuals_differential_equation = physic_domain_d2u_d2t_d2mu[:,0:1] + physic_domain_t_mu[:,1:2] * physic_domain_du_dtdmu[:,0:1] + k * physic_domain_predicted \n",
    "    \n",
    "    loss_differential_equation = torch.mean( (physic_domain_d2u_d2t_d2mu[:,0:1] + physic_domain_t_mu[:,1:2] * physic_domain_du_dtdmu[:,0:1] + k * physic_domain_predicted )**2)\n",
    "    loss_differential_equation_history.append(loss_differential_equation.item())\n",
    "    \n",
    "    loss = loss_ic1 + lambda1 * loss_ic2 + lambda2 * loss_differential_equation\n",
    "    loss_total_history.append(loss.item())\n",
    "    loss_history.append(loss.item())\n",
    "    if i ==1:\n",
    "        \n",
    "        initial_loss_value = loss.item()        \n",
    "    \n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "    # Update loss history and ensure it contains the losses of the last check_range epochs\n",
    "    if len(loss_history) > check_range:\n",
    "        loss_history.pop(0)  # Remove the oldest loss value\n",
    "    \n",
    "    # Check if the difference between max and min loss in the last 100 epochs is within the threshold\n",
    "    max_min_range = max(loss_history) - min(loss_history)\n",
    "    absolut_loss_value = sum(loss_history) / len(loss_history)\n",
    "    if len(loss_history) == check_range and max_min_range <= threshold and  absolut_loss_value < initial_loss_value:\n",
    "        print(f\"Stopping training at epoch {i} as the loss stabilized within the threshold.\")\n",
    "        print(f\"max_min_range = {max_min_range} \\n absolute_loss_value: {absolut_loss_value} \")\n",
    "        break\n",
    "    \n",
    "    if i%1000 == 0:\n",
    "        print(f\"Shape of ic1 residuals: {residuals_ic1.shape}\")\n",
    "        print(f'Decomposition of the loss terms: \\n loss({loss}) = loss1({loss_ic1}) + {lambda1} * loss2({loss_ic2}) + {lambda2} * loss3({loss_differential_equation})')\n",
    "        \n",
    "        test_predicted = original_model(test_in_t_constant_mu)\n",
    "        \n",
    "        plt.figure(figsize=(10,2.5))\n",
    "        plt.plot(test_in_t_mu[0].detach().numpy(), \n",
    "                 u_exact, \n",
    "                 label=\"Exact solution\", \n",
    "                 color=\"tab:grey\", \n",
    "                 alpha=0.6\n",
    "        )\n",
    "        plt.plot(\n",
    "                test_in_t_mu[0], \n",
    "                test_predicted[:,0].detach().numpy(), \n",
    "                label=\"PINN solution\", \n",
    "                color=\"tab:green\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "                    physic_in_t_mu[0].detach().numpy(), \n",
    "                    torch.zeros_like(physic_in_t_mu[0]), \n",
    "                    s=20, \n",
    "                    lw=0, \n",
    "                    color=\"tab:red\",\n",
    "                    alpha=0.6,\n",
    "                    label= \"Training points\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "                    test_in_t_mu[0], \n",
    "                    torch.zeros_like(test_in_t_mu[0]), \n",
    "                    s=20, \n",
    "                    lw=0, \n",
    "                    color=\"tab:green\",\n",
    "                    alpha=0.6,\n",
    "                    label= \"Seed points(testing)\"\n",
    "        )\n",
    "        #plt.title(f\"Exact and predicted solution \\n u(t=(0,1), $\\mu$ = {test_mu}), model: {original_model.__class__.__name__}, activation function: {original_model.activation()}, epoch = {i} \\n (learning rate: {learning_rate}, lambda1: {lambda1}, lambda2: {lambda2})\")\n",
    "        plt.title(f\"Exact and predicted solution \\n u(t=(0,1), $\\mu$ = {test_mu}), model: {original_model.__class__.__name__}, activation function: Tanh, epoch = {i} \\n (learning rate: {learning_rate}, lambda1: {lambda1}, lambda2: {lambda2})\")\n",
    "\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        torch.save({\n",
    "                    \"epoch\": i,\n",
    "                    \"model_state_dict\": original_model.state_dict(),\n",
    "                    \"optimiser_state_dict\": optimiser.state_dict(),\n",
    "                    \"loss\": loss,\n",
    "                   },                    \n",
    "                    f\"lr{learning_rate}_epoch{i}.pth\") #f\"lr{learning_rate}_epoch{i}.pth\")\n",
    "        print(f\"Saved the checkpoint corresponding to epoch: {i}\")\n",
    "end = time.time()\n",
    "execution_time = (end - start)\n",
    "print(f\"Training elapsed time (s): {execution_time}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6649e2-a848-449f-8c69-b5361a65c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss history as before\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_history, label='Loss over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ddaae-922a-4283-bf3f-43f79596794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_total_history[-1000:], label='Loss over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedc5ccf-a2ae-4d15-97d2-2874239b6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_total_history, label='Loss over epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8f80d-2ccc-4f8f-bdb0-ab58b79cd665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0faa82cc-210b-4bea-917f-1e439e81bab5",
   "metadata": {},
   "source": [
    "## STEP 7: Investigation of the loss terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9487fd7-6866-43c2-ab32-f064be36a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the contribution of every loss term (loss1, loss2 and loss3)\n",
    "fig, (loss1_2, loss3) = plt.subplots(1,2, layout = 'constrained', sharex = True, figsize = (15,5))\n",
    "#fig.suptitle(f\"Decomposition of the loss terms using {original_model.__class__.__name__} model and Tanh #{original_model.activation()}# activation function \\n (learning_rate: {learning_rate}, lambda1: {lambda1}, lambda2: {lambda2})\", fontsize = 14)\n",
    "fig.suptitle(f\"Decomposition of the loss terms using {original_model.__class__.__name__} model and Tanh activation function \\n (learning_rate: {learning_rate}, lambda1: {lambda1}, lambda2: {lambda2})\", fontsize = 14)\n",
    "\n",
    "loss1_2.plot(loss_ic1_history, label = \"loss1: residuals of u(t=0)=1\", color = \"tab:red\")\n",
    "loss1_2.plot(loss_ic2_history, label = \"loss2: residuals of du/dt(t=0)=0\", color = \"tab:blue\")\n",
    "loss1_2.set_title(\"loss1: (u(t=0)=1) and loss2: (du/dt(t=0)=0)\")\n",
    "loss1_2.set_xlabel(\"epochs\")\n",
    "loss1_2.set_ylabel(\"residuals\")\n",
    "loss1_2.grid()\n",
    "loss1_2.legend()\n",
    "\n",
    "loss3.plot(loss_differential_equation_history, label= \"loss3: residuals of the differential equation\", color = \"tab:grey\")\n",
    "loss3.set_title(\"loss3: residuals of the differential equation\")\n",
    "loss3.set_xlabel(\"epochs\")\n",
    "loss3.set_ylabel(\"residuals\")\n",
    "loss3.legend()\n",
    "loss3.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12471976-8e6a-4bc3-9fc2-67de49835233",
   "metadata": {},
   "source": [
    "## STEP9: Training using a different initialization & activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f431204a-ce45-470f-8bd4-d1a626336f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_func = \"LeakyReLU\"\n",
    "model_init = FCN_init(2,1,64,4, activation= activation_func)\n",
    "model_init.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9997911-17ff-4dbc-908e-38cfa1b3e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(model_init.state_dict()[\"fcs.0.weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee4774-4326-489f-a0d1-16fbb3ad1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_init.fcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40e860-0cb9-43c6-8254-d9f109fb5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_init.parameters)\n",
    "print(model_init.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c47c7c-21f5-4f33-94ef-0a7877a0c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted_init = model_init(test_in_t_constant_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b2b84-e5cf-49f4-ab3a-02eece464dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2.5))\n",
    "plt.plot(test_in_t_mu[0].detach().numpy(), \n",
    "                 u_exact, \n",
    "                 label=\"Exact solution\", \n",
    "                 color=\"tab:grey\", \n",
    "                 alpha=0.6\n",
    ")\n",
    "plt.plot(test_in_t_mu[0], \n",
    "                 test_predicted_init[:,0].detach().numpy(), \n",
    "                 label=\"PINN solution (initial)\", \n",
    "                 color=\"tab:green\"\n",
    ")\n",
    "plt.scatter(\n",
    "        test_in_t_mu[0], \n",
    "        torch.zeros_like(test_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:green\",\n",
    "        alpha=0.6,\n",
    "        label= \"Seed points(testing)\"\n",
    ")\n",
    "plt.scatter(\n",
    "        physic_in_t_mu[0].detach().numpy(), \n",
    "        torch.zeros_like(physic_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:purple\",\n",
    "        alpha=0.6,\n",
    "        label= \"Training points\"\n",
    ")\n",
    "plt.title(f\"Exact and predicted solution \\n u(t=(0,1), $\\mu$ = {test_mu}), epoch = 1, model: {model_init.__class__.__name__}, activation function: {activation_func}()\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783efd8-c3f3-45c9-b5e8-68c47f70c38e",
   "metadata": {},
   "source": [
    "## STEP10: Inference Case (Check for a fixed value of mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc64f4-5020-4b92-85b6-d0a3c873ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mu = 5\n",
    "test_in_t_constant_mu = torch.stack([torch.linspace(0,1,point_resolution_test), test_mu*torch.ones(point_resolution_test)], -1).view(-1,2)\n",
    "u_exact = exact_solution(test_mu/(2*mass), w0, test_in_t_mu[0])\n",
    "#print(f\" Point seed list for mesh grid domain points: \\n \\t {test_in_t_constant_mu}\")\n",
    "#print(f\"Size of Domain training points: \\n \\t {test_in_t_constant_mu.size()}\")b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64d80f-7b0d-4bd0-a617-9dda19c0c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted_init = model_init(test_in_t_constant_mu)\n",
    "#print(test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1997cb3-aa24-40fc-9555-c4fb369ff878",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2.5))\n",
    "plt.plot(test_in_t_mu[0].detach().numpy(), \n",
    "                 u_exact, \n",
    "                 label=\"Exact solution\", \n",
    "                 color=\"tab:grey\", \n",
    "                 alpha=0.6\n",
    ")\n",
    "plt.plot(test_in_t_mu[0], \n",
    "                 test_predicted_init[:,0].detach().numpy(), \n",
    "                 label=\"PINN solution (initial)\", \n",
    "                 color=\"tab:green\"\n",
    ")\n",
    "plt.scatter(\n",
    "        test_in_t_mu[0], \n",
    "        torch.zeros_like(test_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:green\",\n",
    "        alpha=0.6,\n",
    "        label= \"Seed points(testing)\"\n",
    ")\n",
    "plt.scatter(\n",
    "        physic_in_t_mu[0].detach().numpy(), \n",
    "        torch.zeros_like(physic_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:purple\",\n",
    "        alpha=0.6,\n",
    "        label= \"Training points\"\n",
    ")\n",
    "plt.title(f\"Exact and predicted solution \\n u(t=(0,1), $\\mu$ = {test_mu}), epoch = 1, model: {model.__class__.__name__}, activation function: {activation_func}()\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed92aa21-2f28-4237-9d17-970a2eb65f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic1_t_mu\n",
    "physic_domain_t_mu\n",
    "loss_ic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe3d64-6f43-4b01-8375-59debe22d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_init = torch.optim.Adam(model_init.parameters(), lr= learning_rate)\n",
    "epochs = 10001\n",
    "start = time.time()\n",
    "# Creation of the variables loss1_history, loss2_history and loss3_history for printing the evolution of the contribution of every loss term:\n",
    "\n",
    "loss_ic1_history = []\n",
    "loss_ic2_history = []\n",
    "loss_differential_equation_history = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    optimizer_init.zero_grad()\n",
    "\n",
    "    # compute initial condition 1 loss:\n",
    "    ic1_predicted= model_init(ic1_t_mu)\n",
    "    loss_ic1 = torch.mean((ic1_predicted - ic1_scope)**2)\n",
    "    loss_ic1_history.append(loss_ic1.item())\n",
    "\n",
    "\n",
    "    # compute initial condition 2 loss:\n",
    "    du_dtdmu_initial = torch.autograd.grad(outputs = ic1_predicted, inputs = ic1_t_mu, grad_outputs= torch.ones_like(ic1_predicted), create_graph= True)[0]\n",
    "    ic2_du_dt, ic2_du_dmu = du_dtdmu_initial[:, 0:1], du_dtdmu_initial[:,1:2]\n",
    "    loss_ic2 = torch.mean((ic2_du_dt- ic2_scope)**2)\n",
    "    loss_ic2_history.append(loss_ic2.item())\n",
    "\n",
    "    # compute physic loss:\n",
    "    physic_domain_predicted = model_init(physic_domain_t_mu)\n",
    "    physic_domain_du_dtdmu = torch.autograd.grad(outputs = physic_domain_predicted, inputs = physic_domain_t_mu, grad_outputs= torch.ones_like(physic_domain_predicted), create_graph= True)[0]\n",
    "    physic_domain_d2u_d2t_d2mu = torch.autograd.grad(outputs = physic_domain_du_dtdmu[:,0:1], inputs = physic_domain_t_mu, grad_outputs= torch.ones_like(physic_domain_du_dtdmu[:,0:1]), create_graph= True)[0]\n",
    "    loss_differential_equation = torch.mean( (physic_domain_d2u_d2t_d2mu[:,0:1] + physic_domain_t_mu[:,1:2] * physic_domain_du_dtdmu[:,0:1] + k * physic_domain_predicted )**2)\n",
    "    loss_differential_equation_history.append(loss_differential_equation.item())\n",
    "    \n",
    "    loss = loss_ic1 + lambda1 * loss_ic2 + lambda2 * loss_differential_equation\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer_init.step()\n",
    "    \n",
    "    \n",
    "    if i%1000 == 0:\n",
    "        print(f'Decomposition of the loss terms: \\n loss({loss}) = loss1({loss_ic1}) + {lambda1} * loss2({loss_ic2}) + {lambda2} * loss3({loss_differential_equation})')\n",
    "        \n",
    "        test_predicted_init = model_init(test_in_t_constant_mu)\n",
    "        \n",
    "        plt.figure(figsize=(10,2.5))\n",
    "        plt.plot(test_in_t_mu[0].detach().numpy(), \n",
    "                 u_exact, \n",
    "                 label=\"Exact solution\", \n",
    "                 color=\"tab:grey\", \n",
    "                 alpha=0.6\n",
    "        )\n",
    "        plt.plot(\n",
    "                test_in_t_mu[0], \n",
    "                test_predicted_init[:,0].detach().numpy(), \n",
    "                label=\"PINN solution\", \n",
    "                color=\"tab:green\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "                    physic_in_t_mu[0].detach().numpy(), \n",
    "                    torch.zeros_like(physic_in_t_mu[0]), \n",
    "                    s=20, \n",
    "                    lw=0, \n",
    "                    color=\"tab:red\",\n",
    "                    alpha=0.6,\n",
    "                    label= \"Training points\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "                    test_in_t_mu[0], \n",
    "                    torch.zeros_like(test_in_t_mu[0]), \n",
    "                    s=20, \n",
    "                    lw=0, \n",
    "                    color=\"tab:green\",\n",
    "                    alpha=0.6,\n",
    "                    label= \"Seed points(testing)\"\n",
    "        )\n",
    "        plt.title(f\"Exact and predicted solution \\n u(t=(0,1), $\\mu$ = {test_mu}), model: {model_init.__class__.__name__}, activation function: {activation_func}, epoch = {i} \\n (learning rate: {learning_rate}, lambda1: {lambda1}, lambda2: {lambda2})\")\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "end = time.time()\n",
    "execution_time = (end - start)\n",
    "print(f\"Training elapsed time (s): {execution_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4dc233-a77a-4900-8de5-3654ccecd37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9487f44-ad23-4420-88c7-41131790de83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ae528-306f-40b5-a298-5dce14eaba59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e39052-be98-4bfb-b520-a2feaa0c01c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ad365-6b1e-4a56-9a2c-2aec7265400c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebfc107-2874-42bf-bb72-db2a75a19744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe967186-9538-49ad-a528-8ce63ac9dbb1",
   "metadata": {},
   "source": [
    "### Predicted values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29191fe-e164-4266-924f-748c213b7645",
   "metadata": {},
   "source": [
    "#### Generation of testing points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723f617-9cb9-41f5-93d3-4f4a8ec48c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Generation of t and mu test points within the domain:\n",
    "point_resolution_test = 100\n",
    "\n",
    "# Testing points:\n",
    "test_in_t_mu = [torch.linspace(0,1,point_resolution_test), torch.linspace(1,10,point_resolution_test) ]\n",
    "test_domain_t_mu = torch.stack(torch.meshgrid(*test_in_t_mu, indexing='ij'), -1).view(-1, 2)\n",
    "\n",
    "# print(f\"Point seed list for mesh grid test points: \\n \\t \\n \\t: {test_in_t_mu}\")\n",
    "# print(f\"Test points \\n \\t [t, mu]: \\n \\t {test_domain_t_mu}\")\n",
    "# print(f\"Size of the test domain points: \\n \\t {test_domain_t_mu.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6805e044-070c-4c10-ad27-6293ac074988",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = original_model(test_in_t_constant_mu)\n",
    "#test_predicted.size()\n",
    "#test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd5d74-5f22-4316-9aac-43ca096917b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,2.5))\n",
    "plt.plot(test_in_t_mu[0].detach().numpy(), \n",
    "                 u_exact, \n",
    "                 label=\"Exact solution\", \n",
    "                 color=\"tab:grey\", \n",
    "                 alpha=0.6\n",
    ")\n",
    "plt.plot(test_in_t_mu[0], \n",
    "                 test_predicted[:,0].detach().numpy(), \n",
    "                 label=\"PINN solution (initial)\", \n",
    "                 color=\"tab:green\"\n",
    ")\n",
    "plt.scatter(\n",
    "        test_in_t_mu[0], \n",
    "        torch.zeros_like(test_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:green\",\n",
    "        alpha=0.6,\n",
    "        label= \"Seed points(testing)\"\n",
    ")\n",
    "plt.scatter(\n",
    "        physic_in_t_mu[0].detach().numpy(), \n",
    "        torch.zeros_like(physic_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:purple\",\n",
    "        alpha=0.6,\n",
    "        label= \"Training points\"\n",
    ")\n",
    "### model and activation has to be manually adapted\n",
    "plt.title(f\"Exact and predicted solution for a nn with following architecture: [{original_input_size}, {original_hidden_layers}, {original_output_size}] \\n u(t=(0,1), $\\mu$ = {test_mu}), model: {original_model.__class__.__name__}, activation function: {original_model.activation}, epoch = 1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff570665-c6de-4a72-b37a-f63478a196ac",
   "metadata": {},
   "source": [
    "### Exact solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dd8001-d35a-4fb3-8415-645c98683966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_solution(d, w0, t):\n",
    "    \"Defines the analytical solution to the under-damped harmonic oscillator problem above.\"\n",
    "    assert d < w0             \n",
    "    w = np.sqrt(w0**2-d**2)\n",
    "    phi = np.arctan(-d/w)\n",
    "    A = 1/(2*np.cos(phi))\n",
    "    cos = torch.cos(phi+w*t)\n",
    "    exp = torch.exp(-d*t)\n",
    "    u = exp*2*A*cos\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8e8cd-082b-45c6-ab5e-379601fdb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to check if it works (calculation of the exact solution):\n",
    "test_mu = 5\n",
    "u_exact = exact_solution(test_mu/(2*mass), w0, test_in_t_mu[0])\n",
    "#u_exact.view(-1,1)\n",
    "#u_exact.size()\n",
    "#u_exact.numel()\n",
    "#u_exact.dim()\n",
    "#u_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8a0ae-39a3-4364-9611-283ecc3833ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#physic_in_t_mu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb8e88b-e242-4414-bd08-08551277e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the exact solution:\n",
    "plt.figure(figsize=(10,2.5))\n",
    "plt.plot(\n",
    "        test_in_t_mu[0], \n",
    "        u_exact, \n",
    "        label=\"Exact solution\", \n",
    "        color=\"tab:grey\", \n",
    "        alpha=0.6)\n",
    "plt.scatter(\n",
    "        test_in_t_mu[0], \n",
    "        torch.zeros_like(test_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:green\",\n",
    "        alpha=0.6,\n",
    "        label= \"Seed points (testing)\")\n",
    "plt.scatter(\n",
    "        physic_in_t_mu[0].detach().numpy(), \n",
    "        torch.zeros_like(physic_in_t_mu[0]), \n",
    "        s=20, \n",
    "        lw=0, \n",
    "        color=\"tab:red\",\n",
    "        alpha=0.6,\n",
    "        label= \"Training points\")\n",
    "\n",
    "plt.title(f\"Exact solution \\n u(t=(0,1), $\\mu$ = {test_mu}) using {point_resolution_test} seed points\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e5ff1-1230-4fae-8dc7-3c584d695376",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted = original_model(test_in_t_constant_mu)\n",
    "        \n",
    "        plt.figure(figsize=(10,2.5))\n",
    "        plt.plot(test_in_t_mu[0].detach().numpy(), \n",
    "                 u_exact, \n",
    "                 label=\"Exact solution\", \n",
    "                 color=\"tab:grey\", \n",
    "                 alpha=0.6\n",
    "        )\n",
    "        plt.plot(\n",
    "                test_in_t_mu[0], \n",
    "                test_predicted[:,0].detach().numpy(), \n",
    "                label=\"PINN solution\", \n",
    "                color=\"tab:green\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "                    physic_in_t_mu[0].detach().numpy(), \n",
    "                    torch.zeros_like(physic_in_t_mu[0]), \n",
    "                    s=20, \n",
    "                    lw=0, \n",
    "                    color=\"tab:red\",\n",
    "                    alpha=0.6,\n",
    "                    label= \"Training points\"\n",
    "        )\n",
    "        plt.scatter(\n",
    "                    test_in_t_mu[0], \n",
    "                    torch.zeros_like(test_in_t_mu[0]), \n",
    "                    s=20, \n",
    "                    lw=0, \n",
    "                    color=\"tab:green\",\n",
    "                    alpha=0.6,\n",
    "                    label= \"Seed points(testing)\"\n",
    "        )\n",
    "        #plt.title(f\"Exact and predicted solution \\n u(t=(0,1), $\\mu$ = {test_mu}), model: {original_model.__class__.__name__}, activation function: {original_model.activation()}, epoch = {i} \\n (learning rate: {learning_rate}, lambda1: {lambda1}, lambda2: {lambda2})\")\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
