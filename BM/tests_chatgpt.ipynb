{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7b585-85ca-4aec-b02a-63c992f545cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the neural network architecture\n",
    "class DampedOscillatorPINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DampedOscillatorPINN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.net(t)\n",
    "\n",
    "# Modified function to compute both loss and residuals\n",
    "def compute_loss_and_residuals(model, t, omega_0, zeta):\n",
    "    t.requires_grad = True\n",
    "    x = model(t)\n",
    "    dx_dt = torch.autograd.grad(x, t, torch.ones_like(x), create_graph=True)[0]\n",
    "    d2x_dt2 = torch.autograd.grad(dx_dt, t, torch.ones_like(dx_dt), create_graph=True)[0]\n",
    "    residuals = d2x_dt2 + 2*zeta*omega_0*dx_dt + omega_0**2*x\n",
    "    loss = torch.mean(residuals**2)\n",
    "    return loss, residuals\n",
    "\n",
    "# Model, optimizer, and training loop setup\n",
    "model = DampedOscillatorPINN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "omega_0 = 1.0  # Natural frequency\n",
    "zeta = 0.1    # Damping ratio\n",
    "\n",
    "# Initialization\n",
    "losses = []\n",
    "epoch_residuals = []\n",
    "\n",
    "# Adjusted training loop\n",
    "for epoch in range(5000):\n",
    "    t = torch.rand(100, 1) * 10  # Generate random time points\n",
    "    loss, residuals = compute_loss_and_residuals(model, t, omega_0, zeta)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:  # Adjust based on your preference for data collection frequency\n",
    "        losses.append(loss.item())\n",
    "        epoch_residuals.append(residuals.mean().item())  # Example: storing mean residual\n",
    "\n",
    "# After training, plot the collected data\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_residuals, label='Mean Residual')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Residual')\n",
    "plt.title('Mean Residual Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "495baa4e-495e-4049-8e3d-bd266f035076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T07:47:33.184647Z",
     "iopub.status.busy": "2024-02-28T07:47:33.182545Z",
     "iopub.status.idle": "2024-02-28T07:47:41.703799Z",
     "shell.execute_reply": "2024-02-28T07:47:41.703279Z",
     "shell.execute_reply.started": "2024-02-28T07:47:33.184598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the neural network architecture\n",
    "class DampedOscillatorPINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DampedOscillatorPINN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.net(t)\n",
    "\n",
    "# Modified function to compute both loss and residuals\n",
    "def compute_loss_and_residuals(model, t, omega_0, zeta):\n",
    "    t.requires_grad = True\n",
    "    x = model(t)\n",
    "    dx_dt = torch.autograd.grad(x, t, torch.ones_like(x), create_graph=True)[0]\n",
    "    d2x_dt2 = torch.autograd.grad(dx_dt, t, torch.ones_like(dx_dt), create_graph=True)[0]\n",
    "    residuals = d2x_dt2 + 2*zeta*omega_0*dx_dt + omega_0**2*x\n",
    "    loss = torch.mean(residuals**2)\n",
    "    return loss, residuals\n",
    "\n",
    "# Model, optimizer, and training loop setup\n",
    "model = DampedOscillatorPINN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "omega_0 = 1.0  # Natural frequency\n",
    "zeta = 0.1    # Damping ratio\n",
    "\n",
    "\n",
    "# Initialization for residuals collection\n",
    "all_residuals = []\n",
    "selected_epoch = 5000  # Example: Collecting residuals at the last epoch\n",
    "\n",
    "for epoch in range(selected_epoch):\n",
    "    t = torch.rand(100, 1) * 10  # Generate random time points within the domain\n",
    "    optimizer.zero_grad()\n",
    "    loss, residuals = compute_loss_and_residuals(model, t, omega_0, zeta)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch == selected_epoch - 1:  # Collect residuals at the specified epoch\n",
    "        all_residuals.append(residuals.detach().numpy())\n",
    "\n",
    "# After training, plot the collected residuals for the specified epoch\n",
    "# Assuming `t` still holds the training points used in the last epoch\n",
    "plt.scatter(t.detach().numpy(), all_residuals[0], alpha=0.6)\n",
    "plt.xlabel('Training Points (t)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals at Training Points')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba5834-a06d-44b2-a6aa-c7fb375245fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the rest of the model setup is as before\n",
    "\n",
    "# Initialization for residuals collection\n",
    "all_residuals = []\n",
    "selected_epoch = 5000  # Example: Collecting residuals at the last epoch\n",
    "\n",
    "for epoch in range(selected_epoch):\n",
    "    t = torch.rand(100, 1) * 10  # Generate random time points within the domain\n",
    "    optimizer.zero_grad()\n",
    "    loss, residuals = compute_loss_and_residuals(model, t, omega_0, zeta)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch == selected_epoch - 1:  # Collect residuals at the specified epoch\n",
    "        all_residuals.append(residuals.detach().numpy())\n",
    "\n",
    "# After training, plot the collected residuals for the specified epoch\n",
    "# Assuming `t` still holds the training points used in the last epoch\n",
    "plt.scatter(t.detach().numpy(), all_residuals[0], alpha=0.6)\n",
    "plt.xlabel('Training Points (t)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals at Training Points')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df13307-7587-4330-af64-fcfc017b5e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8da46-ca62-4ee3-b9ef-fa4659087f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bad782-f2b8-4abc-86c3-81232136f722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a1f2e-68c7-4cc5-8c69-ffb8044c3cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d94f10-7676-422a-8957-94ecf85b59a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6e4a3-6b0a-4ced-8037-a408eba22d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25443f7-d90b-409d-8269-6db300b4ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the weights and biases for the original network\n",
    "# Replace these with your actual values\n",
    "original_weights = {\n",
    "    'hidden_layer1': torch.randn(8, 2),\n",
    "    'hidden_layer2': torch.randn(8, 8),\n",
    "    'output_layer': torch.randn(1, 8),\n",
    "}\n",
    "\n",
    "original_biases = {\n",
    "    'hidden_layer1': torch.randn(8),\n",
    "    'hidden_layer2': torch.randn(8),\n",
    "    'output_layer': torch.randn(1),\n",
    "}\n",
    "\n",
    "# Define the architecture of the new network\n",
    "new_input_size = 2\n",
    "new_hidden_layers = [8, 8]\n",
    "new_output_size = 1\n",
    "\n",
    "# Create a new model with the same architecture as the original one\n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(NewModel, self).__init__()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layers[0])\n",
    "        \n",
    "        # Hidden layers with weights and biases from the original model\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers)-1)\n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the new model\n",
    "new_model = NewModel(new_input_size, new_hidden_layers, new_output_size)\n",
    "\n",
    "# Set the weights and biases from the original model\n",
    "new_model.input_layer.weight.data = torch.transpose(original_weights['hidden_layer1'], 0, 1)\n",
    "new_model.input_layer.bias.data = original_biases['hidden_layer1']\n",
    "\n",
    "for i, layer in enumerate(new_model.hidden_layers):\n",
    "    layer.weight.data = torch.transpose(original_weights[f'hidden_layer{i+2}'], 0, 1)\n",
    "    layer.bias.data = original_biases[f'hidden_layer{i+2}']\n",
    "\n",
    "new_model.output_layer.weight.data = torch.transpose(original_weights['output_layer'], 0, 1)\n",
    "new_model.output_layer.bias.data = original_biases['output_layer']\n",
    "\n",
    "# Visualize the differences in weights and biases\n",
    "def visualize_difference(original, new, layer_name):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Plot weights\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f'{layer_name} Weights')\n",
    "    plt.imshow(original, cmap='viridis')\n",
    "    plt.colorbar(label='Weight Values')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f'Difference in {layer_name} Weights')\n",
    "    plt.imshow(new - original, cmap='coolwarm')\n",
    "    plt.colorbar(label='Weight Difference')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize differences for each layer\n",
    "for layer_name, original_weight in original_weights.items():\n",
    "    new_weight = getattr(new_model, layer_name).weight.data\n",
    "    visualize_difference(original_weight, new_weight, layer_name)\n",
    "\n",
    "# Visualize differences for biases\n",
    "for layer_name, original_bias in original_biases.items():\n",
    "    new_bias = getattr(new_model, layer_name).bias.data\n",
    "    visualize_difference(original_bias.unsqueeze(0), new_bias.unsqueeze(0), layer_name + ' Bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c9143-f857-489d-b2e3-5002526a88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    im = ax.imshow(weights, cmap='coolwarm', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "layer_sizes = [2, 4, 8, 4, 1]\n",
    "\n",
    "# Initialize random weights\n",
    "np.random.seed(42)\n",
    "weights = [np.random.randn(layer_sizes[i], layer_sizes[i+1]) for i in range(len(layer_sizes)-1)]\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(layer_sizes)-1, figsize=(15, 5))\n",
    "\n",
    "# Plot the weights for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Weights Layer {i+1}')\n",
    "\n",
    "    # Show the colorbars\n",
    "    fig.colorbar(im, ax=ax, orientation='horizontal')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f79653-125e-40e6-b8fb-4e54d88d82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Weights Layer {i+1}')\n",
    "\n",
    "    # Show the colorbars\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ecc82c-fb1d-4d91-b682-fc5009231f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2b93b-bc9c-4372-81a1-57ff6125a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='black', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Weights Layer {i+1}')\n",
    "\n",
    "    # Show the colorbars\n",
    "    fig.colorbar(im, ax=ax, orientation='horizontal')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7fd272-7286-4fc7-bc0c-10930b19f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf248e3-097e-4154-a886-d31df6d9f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4598e-ae08-4009-9a5b-27915ec1d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights and biases from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Layer {i+1}')\n",
    "\n",
    "    # Show the colorbars\n",
    "    #fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16750952-921f-4553-b7d8-1cd1b33e71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title, labels):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers and labels to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}\\n{labels[i, j]}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights and biases from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create labels to indicate weights or biases\n",
    "labels = np.array([['Weight' if 'weight' in key else 'Bias' for key in state_dict.keys()]])\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Layer {i+1}', labels)\n",
    "\n",
    "    # Show the colorbars\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78ada7-6e69-4a32-a1d9-80b36cc856e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title, labels):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers and labels to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}\\n{labels[i, j]}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights and biases from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create labels to indicate weights or biases\n",
    "labels = np.array([['Weight' if 'weight' in key else 'Bias' for key in state_dict.keys()]])  # Note the extra square brackets\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Layer {i+1}', labels)\n",
    "\n",
    "    # Show the colorbars\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad298fdb-673c-42db-af69-79ab371b8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title, labels):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers and labels to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}\\n{labels[i, j]}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights and biases from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create labels to indicate weights or biases\n",
    "labels = np.array([['Weight' if 'weight' in key else 'Bias' for key in state_dict.keys()]])\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Layer {i+1}', labels)\n",
    "\n",
    "    # Show the colorbars\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e298ec2-8613-47d2-bb4d-1df53fa9e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60fb4a-401c-4709-955c-196ca5eae7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f670323e-a753-4f5f-8a01-1339a3104cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the architecture of the original network\n",
    "original_input_size = 2\n",
    "original_hidden_layers = [8, 8]\n",
    "original_output_size = 1\n",
    "\n",
    "# Create the original model with Xavier initialization\n",
    "class OriginalModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(OriginalModel, self).__init__()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layers[0])\n",
    "        init.xavier_uniform_(self.input_layer.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        init.zeros_(self.input_layer.bias.data)\n",
    "        \n",
    "        # Hidden layers with Xavier initialization\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers)-1)\n",
    "        ])\n",
    "        for layer in self.hidden_layers:\n",
    "            init.xavier_uniform_(layer.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "            init.zeros_(layer.bias.data)\n",
    "        \n",
    "        # Output layer with Xavier initialization\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "        init.xavier_uniform_(self.output_layer.weight.data, gain=nn.init.calculate_gain('linear'))\n",
    "        init.zeros_(self.output_layer.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the original model\n",
    "original_model = OriginalModel(original_input_size, original_hidden_layers, original_output_size)\n",
    "\n",
    "# Define the architecture of the new network with increased neurons\n",
    "new_input_size = 2\n",
    "new_hidden_layers = [16, 16]  # Increase the number of neurons\n",
    "new_output_size = 1\n",
    "\n",
    "# Create a new model with the same architecture as the original one\n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(NewModel, self).__init__()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layers[0])\n",
    "        \n",
    "        # Hidden layers with weights and biases from the original model\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers)-1)\n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the new model\n",
    "new_model = NewModel(new_input_size, new_hidden_layers, new_output_size)\n",
    "\n",
    "# Set the weights from the original model using He initialization\n",
    "def initialize_weights_he(model):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            init.kaiming_uniform_(layer.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "            init.zeros_(layer.bias.data)\n",
    "\n",
    "# Initialize weights of the new model using He initialization\n",
    "initialize_weights_he(new_model)\n",
    "\n",
    "# Visualize the differences in weights and biases\n",
    "def visualize_difference(original, new, layer_name):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Plot weights\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f'{layer_name} Weights')\n",
    "    plt.imshow(original, cmap='viridis')\n",
    "    plt.colorbar(label='Weight Values')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f'Difference in {layer_name} Weights')\n",
    "    plt.imshow(new - original, cmap='coolwarm')\n",
    "    plt.colorbar(label='Weight Difference')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize differences for each layer\n",
    "for layer_name, original_weight in original_model.state_dict().items():\n",
    "    new_weight = new_model.state_dict()[layer_name]\n",
    "    visualize_difference(original_weight, new_weight, layer_name)\n",
    "\n",
    "# Visualize differences for biases\n",
    "for layer_name, original_bias in original_model.state_dict().items():\n",
    "    if 'bias' in layer_name:\n",
    "        new_bias = new_model.state_dict()[layer_name]\n",
    "        visualize_difference(original_bias.unsqueeze(0), new_bias.unsqueeze(0), layer_name + ' Bias')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807ef4d-b443-481d-9d9a-eaae0d389ab7",
   "metadata": {},
   "source": [
    "# ADAPTIVE SCHEME II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3695ebe-797f-4ff5-a2d8-510dd00f7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the original model\n",
    "class OriginalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OriginalModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 4)\n",
    "        self.output = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Train and save the original model\n",
    "original_model = OriginalModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(original_model.parameters(), lr=0.01)\n",
    "\n",
    "# Dummy data for training\n",
    "input_data = torch.rand((100, 2))\n",
    "target_data = torch.rand((100, 1))\n",
    "\n",
    "original_weights = []  # List to store original model weights\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = original_model(input_data)\n",
    "    loss = criterion(output, target_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Store the weights for visualization\n",
    "    original_weights.append(original_model.fc1.weight.data.numpy().flatten())\n",
    "\n",
    "# Save the weights and biases\n",
    "torch.save(original_model.state_dict(), 'original_model.pth')\n",
    "\n",
    "# Define the new model with an additional hidden layer\n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NewModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 4)\n",
    "        self.new_layer = nn.Linear(4, 4)  # Additional hidden layer\n",
    "        self.output = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.new_layer(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the new model with the weights and biases of the original model\n",
    "new_model = NewModel()\n",
    "new_model.load_state_dict(torch.load('original_model.pth'))\n",
    "\n",
    "# Check the weights of the new model\n",
    "new_weights = []\n",
    "for epoch in range(10):  # Only for visualization, you can further train as needed\n",
    "    # Store the weights for visualization\n",
    "    new_weights.append(new_model.fc1.weight.data.numpy().flatten())\n",
    "\n",
    "# Plotting the weights\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(original_weights)\n",
    "plt.title('Original Model Weights')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Weight Values')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(new_weights)\n",
    "plt.title('New Model Weights (Initialized from Original)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Weight Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad98b63-762c-45c1-b7cc-9c3c88f57168",
   "metadata": {},
   "source": [
    "# Initialization and activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba85e4-23a0-4a24-9e9d-57a9f153d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_sizes, activation='relu', initialization='xavier'):\n",
    "        super(FCN, self).__init__()\n",
    "\n",
    "        # Define input and output layers\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "        # Define hidden layers\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(in_size, out_size) for in_size, out_size in zip(hidden_sizes[:-1], hidden_sizes[1:])\n",
    "        ])\n",
    "\n",
    "        # Define ModuleDict for activation functions\n",
    "        self.activations = nn.ModuleDict({\n",
    "            'relu': nn.ReLU(),\n",
    "            'tanh': nn.Tanh(),\n",
    "        })\n",
    "\n",
    "        # Initialize layers\n",
    "        self.init_weights(initialization)\n",
    "\n",
    "        # Set activation function\n",
    "        if activation not in self.activations:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "        self.activation = self.activations[activation]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.activation(hidden_layer(x))\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    def init_weights(self, initialization):\n",
    "        # Initialize input layer\n",
    "        if initialization == 'xavier':\n",
    "            init.xavier_uniform_(self.input_layer.weight)\n",
    "        elif initialization == 'kaiming':\n",
    "            init.kaiming_uniform_(self.input_layer.weight, nonlinearity='relu')\n",
    "        elif initialization == 'zeros':\n",
    "            init.zeros_(self.input_layer.weight)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported initialization type\")\n",
    "\n",
    "        # Initialize hidden layers\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            if initialization == 'xavier':\n",
    "                init.xavier_uniform_(hidden_layer.weight)\n",
    "            elif initialization == 'kaiming':\n",
    "                init.kaiming_uniform_(hidden_layer.weight, nonlinearity='relu')\n",
    "            elif initialization == 'zeros':\n",
    "                init.zeros_(hidden_layer.weight)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported initialization type\")\n",
    "\n",
    "        # Initialize output layer\n",
    "        if initialization == 'xavier':\n",
    "            init.xavier_uniform_(self.output_layer.weight)\n",
    "        elif initialization == 'kaiming':\n",
    "            init.kaiming_uniform_(self.output_layer.weight, nonlinearity='relu')\n",
    "        elif initialization == 'zeros':\n",
    "            init.zeros_(self.output_layer.weight)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported initialization type\")\n",
    "\n",
    "# Example usage:\n",
    "input_size = 10\n",
    "output_size = 5\n",
    "hidden_sizes = [20, 30, 15, 10, 25]  # You can specify any number of neurons in each hidden layer\n",
    "\n",
    "# Create an instance of FCN with ReLU activation and Xavier initialization\n",
    "model = FCN(input_size, output_size, hidden_sizes, activation='relu', initialization='xavier')\n",
    "\n",
    "# Check the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee48140-fe23-422a-9c95-d78e16dd4743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T11:22:43.139375Z",
     "iopub.status.busy": "2024-02-08T11:22:43.138785Z",
     "iopub.status.idle": "2024-02-08T11:22:43.145227Z",
     "shell.execute_reply": "2024-02-08T11:22:43.144152Z",
     "shell.execute_reply.started": "2024-02-08T11:22:43.139338Z"
    }
   },
   "source": [
    "## Visualization of the weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0db1a-1f39-47fb-abce-b6acbe6d6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights and biases from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Layer {i+1}')\n",
    "\n",
    "    # Show the colorbars\n",
    "    #fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c02d2-c029-474c-b95c-1c7f2cb00ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Filter out keys containing \"bias\"\n",
    "weights_dict = {key: value for key, value in state_dict.items() if 'bias' not in key}\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights_dict), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights for each layer using a for-loop\n",
    "for i, (key, weights) in enumerate(weights_dict.items()):\n",
    "    im = plot_weights(axes[i], weights.numpy(), f'{key}')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d1c31-0eca-4e88-8092-6042fef13bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Combine both dictionaries for weights and biases into a single dictionary\n",
    "weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights_biases_dict), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer\n",
    "for i, (key, data) in enumerate(weights_biases_dict.items()):\n",
    "    if 'bias' in key:\n",
    "        im = plot_weights(axes[i], data.numpy().reshape(-1, 1), f'{key} (Biases)')\n",
    "    elif 'weight' in key:\n",
    "        im = plot_weights(axes[i], data.numpy(), f'{key} (Weights)')\n",
    "# Add a colorbar for all the plots\n",
    "divider = make_axes_locatable(axes[-3])\n",
    "cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "cbar.set_label('Value')\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbb7d7-f8e6-4142-b597-9b17f958b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Combine both dictionaries for weights and biases into a single dictionary\n",
    "weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights_biases_dict), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer\n",
    "max_intensity = 0  # Track the maximum intensity across all plots\n",
    "for i, (key, data) in enumerate(weights_biases_dict.items()):\n",
    "    if 'bias' in key:\n",
    "        im = plot_weights(axes[i], data.numpy().reshape(-1, 1), f'{key} (Biases)')\n",
    "    elif 'weight' in key:\n",
    "        im = plot_weights(axes[i], data.numpy(), f'{key} (Weights)')\n",
    "    \n",
    "    max_intensity = max(max_intensity, np.max(np.abs(data.numpy())))  # Update max intensity\n",
    "\n",
    "# Add a colorbar below all the plots\n",
    "divider = make_axes_locatable(axes[-1])\n",
    "cax = divider.append_axes(\"bottom\", size=\"10%\", pad=0.5)\n",
    "cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "cbar.set_label('Value')\n",
    "\n",
    "# Normalize the color bar based on the maximum intensity across all plots\n",
    "cbar.set_clim(-max_intensity, max_intensity)\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb2b5d-6a51-4366-82a4-6b8e2d768433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def plot_weights(self):\n",
    "        state_dict = self.state_dict()\n",
    "        weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Create a figure for visualization\n",
    "        num_plots = len(weights_biases_dict)\n",
    "        fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))\n",
    "\n",
    "        # Plot the weights and biases for each layer\n",
    "        #max_intensity = 0  # Track the maximum intensity across all plots\n",
    "        for i, (key, data) in enumerate(weights_biases_dict.items()):\n",
    "            ax = axes[i] if num_plots > 1 else axes\n",
    "            if 'bias' in key:\n",
    "                title = f'{key} (Biases)'\n",
    "            elif 'weight' in key:\n",
    "                title = f'{key} (Weights)'\n",
    "                \n",
    "            if len(data.shape) == 1:\n",
    "                # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "                data = data.reshape(1, -1)\n",
    "                \n",
    "            im = ax.imshow(data.numpy(), cmap='viridis', interpolation='none')\n",
    "\n",
    "            # Add numbers to the cells\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    ax.text(j, i, f'{data[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "            ax.set_title(title)\n",
    "            #max_intensity = max(max_intensity, np.max(np.abs(data.numpy())))  # Update max intensity\n",
    "\n",
    "        # Add a colorbar below all the plots\n",
    "        #divider = make_axes_locatable(ax)\n",
    "        #cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "        #cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "        #cbar.set_label('Value')\n",
    "\n",
    "        # Normalize the color bar based on the maximum intensity across all plots\n",
    "        #cbar.set_clim(-max_intensity, max_intensity)\n",
    "\n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Call the plot_weights method\n",
    "model.plot_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38e34b-a6a9-4189-a187-877cf854f2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b66da6-c48d-4b1d-8bbb-ffc11e2b16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT, N_OUTPUT, hidden_layers, activation='Tanh', initialization='He'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_functions = nn.ModuleDict([\n",
    "            [\"Tanh\", nn.Tanh()],\n",
    "            [\"ReLU\", nn.ReLU()],\n",
    "            [\"LeakyReLU\", nn.LeakyReLU()],\n",
    "            [\"Sigmoid\", nn.Sigmoid()],\n",
    "            [\"Softmax\", nn.Softmax(dim=-1)],\n",
    "        ])\n",
    "\n",
    "        if activation not in self.activation_functions:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.activation = self.activation_functions[activation]\n",
    "\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(N_INPUT, hidden_layers[0]),\n",
    "            self.activation\n",
    "        )\n",
    "\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_layers[i], hidden_layers[i + 1]),\n",
    "                self.activation\n",
    "            ) for i in range(len(hidden_layers) - 1)\n",
    "        ])\n",
    "\n",
    "        self.fce = nn.Linear(hidden_layers[-1], N_OUTPUT)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        for layer in self.fch:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.fce(x)\n",
    "        return x\n",
    "    \n",
    "    def initialize_parameters(self, initialization):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if initialization == 'Uniform':\n",
    "                    init.uniform_(module.weight.data, -0.1, 0.1)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Normal':\n",
    "                    init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Xavier':\n",
    "                    init.xavier_uniform_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'He':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Orthogonal':\n",
    "                    init.orthogonal_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Kaiming':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported initialization type\")\n",
    "\n",
    "    def plot_weights(self):\n",
    "        state_dict = self.state_dict()\n",
    "        weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Create a figure for visualization\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols -1) // num_cols\n",
    "        #fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))\n",
    "        fig, axes = plt.subplots(num_rows,\n",
    "                                 ncols, \n",
    "                                 figsize=(5*num_plots, 5)\n",
    "                                )\n",
    "\n",
    "        # Plot the weights and biases for each layer\n",
    "        #max_intensity = 0  # Track the maximum intensity across all plots\n",
    "        for i, (key, data) in enumerate(weights_biases_dict.items()):\n",
    "            ax = axes[i] if num_plots > 1 else axes\n",
    "            if 'bias' in key:\n",
    "                title = f'{key} (Biases)'\n",
    "            elif 'weight' in key:\n",
    "                title = f'{key} (Weights)'\n",
    "                \n",
    "            if len(data.shape) == 1:\n",
    "                # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "                data = data.reshape(1, -1)\n",
    "                \n",
    "            im = ax.imshow(data.numpy(), cmap='viridis', interpolation='none')\n",
    "\n",
    "            # Add numbers to the cells\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    ax.text(j, i, f'{data[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "            ax.set_title(title)\n",
    "            #max_intensity = max(max_intensity, np.max(np.abs(data.numpy())))  # Update max intensity\n",
    "\n",
    "        # Add a colorbar below all the plots\n",
    "        #divider = make_axes_locatable(ax)\n",
    "        #cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "        #cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "        #cbar.set_label('Value')\n",
    "\n",
    "        # Normalize the color bar based on the maximum intensity across all plots\n",
    "        #cbar.set_clim(-max_intensity, max_intensity)\n",
    "\n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_difference(self, original, new, layer_name):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        # Plot weights\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f'{layer_name} Weights')\n",
    "        plt.imshow(original, cmap='viridis')\n",
    "        plt.colorbar(label='Weight Values')\n",
    "        plt.xlabel('Neurons in Previous Layer')\n",
    "        plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(f'Difference in {layer_name} Weights')\n",
    "        plt.imshow(new - original, cmap='coolwarm')\n",
    "        plt.colorbar(label='Weight Difference')\n",
    "        plt.xlabel('Neurons in Previous Layer')\n",
    "        plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Step 1: Create the original model\n",
    "original_input_size = 2\n",
    "original_hidden_layers = [8, 8]\n",
    "original_output_size = 1\n",
    "original_model = FCN(original_input_size, original_output_size, original_hidden_layers, activation='Tanh', initialization='He')\n",
    "original_model.plot_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd8aa2-150b-451a-b4d1-331a33e8036e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27d860-509c-4130-97d7-2c6d64eca1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each tensor using Matplotlib\n",
    "for idx, (key, tensor) in enumerate(tensor_dict.items()):\n",
    "    row = idx // num_cols\n",
    "    col = idx % num_cols\n",
    "    axs[row, col].imshow(tensor, cmap='gray')  # Adjust colormap as needed\n",
    "    axs[row, col].set_title(key)\n",
    "    axs[row, col].axis('off')  # Turn off axis\n",
    "    axs[row, col].set_aspect('auto')  # Set aspect ratio to auto\n",
    "# Plot data in each subplot\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i < num_subplots:\n",
    "        ax.plot(x, y)\n",
    "        ax.set_title(f\"Subplot {i+1}\")\n",
    "    else:\n",
    "        ax.axis('off')  # Hide extra subplots\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5239886-74b9-44e3-bfc5-21baa07774ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = original_model.state_dict()\n",
    "weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "type(weights_biases_dict['fcs.0.weight'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d48ba9-36a0-4281-9354-545452915d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure for visualization\n",
    "num_plots = len(weights_biases_dict)\n",
    "#fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))\n",
    "fig, axes = plt.subplots(nrows = (num_plots +1)//2,\n",
    "                                 ncols = 2, \n",
    "                                 figsize=(5*num_plots, 5)\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6772df81-9738-400c-b3ea-fe2fe7246695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Visualize the weights and biases of the original model\n",
    "for layer_name, param in original_model.named_parameters():\n",
    "    original_weight = param.detach().numpy()\n",
    "    original_model.visualize_difference(original_weight, original_weight, layer_name)\n",
    "\n",
    "# Step 3: Create the extended model with 16 neurons in hidden layers and ReLU activation\n",
    "extended_hidden_layers = [16, 16]\n",
    "extended_model = FCN(original_input_size, original_output_size, extended_hidden_layers, activation='ReLU', initialization='He')\n",
    "\n",
    "# Step 4: Visualize the weights and biases of the extended model\n",
    "for layer_name, param in extended_model.named_parameters():\n",
    "    extended_weight = param.detach().numpy()\n",
    "    extended_model.visualize_difference(extended_weight, extended_weight, layer_name)\n",
    "\n",
    "# Step 5: Overwrite the weights and biases of the extended model with the original model\n",
    "for original_param, extended_param in zip(original_model.parameters(), extended_model.parameters()):\n",
    "    extended_param.data.copy_(original_param.data)\n",
    "\n",
    "# Step 6: Visualize the weights and biases of the extended model after overwriting\n",
    "for layer_name, param in extended_model.named_parameters():\n",
    "    extended_weight = param.detach().numpy()\n",
    "    extended_model.visualize_difference(original_weight, extended_weight, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d710f3-6544-460d-ae4b-8baa198f9685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def plot_weights(self):\n",
    "        state_dict = self.state_dict()\n",
    "        \n",
    "        num_plots = len(state_dict)\n",
    "        fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))\n",
    "\n",
    "        max_intensity = 0  \n",
    "        for i, (key, data) in enumerate(state_dict.items()):\n",
    "            ax = axes[i] if num_plots > 1 else axes\n",
    "            title = f'{key} (Biases)' if 'bias' in key else f'{key} (Weights)'\n",
    "            \n",
    "            if len(data.shape) == 1:\n",
    "                data = data.reshape(1, -1)\n",
    "                \n",
    "            im = ax.imshow(data.numpy(), cmap='viridis', interpolation='none')\n",
    "\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    ax.text(j, i, f'{data[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "            ax.set_title(title)\n",
    "            max_intensity = max(max_intensity, np.max(np.abs(data.numpy()))) \n",
    "\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "        cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "        cbar.set_label('Value')\n",
    "        cbar.set_clim(-max_intensity, max_intensity)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Call the plot_weights method\n",
    "model.plot_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac6b86-d3f3-4d2b-a8a4-28c6ce31ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example dictionary with tensors as values\n",
    "tensor_dict = {\n",
    "    'tensor1': np.random.rand(10, 10),\n",
    "    'tensor2': np.random.rand(10, 10)\n",
    "}\n",
    "\n",
    "# Determine the number of subplots needed\n",
    "num_subplots = len(tensor_dict)\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, num_subplots, figsize=(10, 5))\n",
    "\n",
    "# Plot each tensor using Matplotlib\n",
    "for idx, (key, tensor) in enumerate(tensor_dict.items()):\n",
    "    axs[idx].imshow(tensor, cmap='gray')  # Adjust colormap as needed\n",
    "    axs[idx].set_title(key)\n",
    "    axs[idx].axis('off')  # Turn off axis\n",
    "    axs[idx].set_aspect('auto')  # Set aspect ratio to auto\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f808dce-bc84-4e03-82b3-74667b6c7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example dictionary with tensors as values\n",
    "tensor_dict = {\n",
    "    'tensor1': np.random.rand(10, 10),\n",
    "    'tensor2': np.random.rand(10, 10),\n",
    "    'tensor3': np.random.rand(10, 10),\n",
    "    'tensor4': np.random.rand(10, 10),\n",
    "    'tensor5': np.random.rand(10, 10)\n",
    "}\n",
    "\n",
    "# Determine the number of subplots needed\n",
    "num_subplots = len(tensor_dict)\n",
    "\n",
    "# Create subplots with 3 rows and 2 columns\n",
    "num_rows = 3\n",
    "num_cols = 2\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "\n",
    "# Plot each tensor using Matplotlib\n",
    "for idx, (key, tensor) in enumerate(tensor_dict.items()):\n",
    "    row = idx // num_cols\n",
    "    col = idx % num_cols\n",
    "    axs[row, col].imshow(tensor, cmap='gray')  # Adjust colormap as needed\n",
    "    axs[row, col].set_title(key)\n",
    "    axs[row, col].axis('off')  # Turn off axis\n",
    "    axs[row, col].set_aspect('auto')  # Set aspect ratio to auto\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d6cf6-01b8-42f3-b59e-bb3765a547df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example dictionary with tensors as values\n",
    "tensor_dict = {\n",
    "    'tensor1': np.random.rand(10, 10),\n",
    "    'tensor2': np.random.rand(10, 10),\n",
    "    'tensor3': np.random.rand(10, 10),\n",
    "    'tensor4': np.random.rand(10, 10),\n",
    "    'tensor5': np.random.rand(10, 10)\n",
    "}\n",
    "\n",
    "# Determine the number of subplots needed\n",
    "num_subplots = len(tensor_dict)\n",
    "\n",
    "# Create subplots with 3 rows and 2 columns\n",
    "num_rows = 3\n",
    "num_cols = 2\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "type(axs)\n",
    "# Plot each tensor using Matplotlib\n",
    "for idx, (key, tensor) in enumerate(tensor_dict.items()):\n",
    "    if idx < num_rows * num_cols:\n",
    "        row = idx // num_cols\n",
    "        col = idx % num_cols\n",
    "        axs[row, col].imshow(tensor, cmap='gray')  # Adjust colormap as needed\n",
    "        axs[row, col].set_title(key)\n",
    "        axs[row, col].axis('off')  # Turn off axis\n",
    "        axs[row, col].set_aspect('auto')  # Set aspect ratio to auto\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8680a61-cab7-479b-a4b9-1bd8cf58f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65a30b-767e-48fd-9f2e-b1bf32009626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Create odd number of subplots\n",
    "num_subplots = 5\n",
    "num_cols = 2\n",
    "num_rows = (num_subplots + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "\n",
    "# Plot data in each subplot\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i < num_subplots:\n",
    "        ax.plot(x, y)\n",
    "        ax.set_title(f\"Subplot {i+1}\")\n",
    "    else:\n",
    "        ax.axis('off')  # Hide extra subplots\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e7c03-eb99-4d14-8977-15a00c4068b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "data = np.random.rand(28, 28, 5)  # Example image data, assuming grayscale images of size 28x28\n",
    "\n",
    "# Create odd number of subplots\n",
    "num_subplots = 5\n",
    "num_cols = 3\n",
    "num_rows = (num_subplots + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "\n",
    "# Plot images in each subplot\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i < num_subplots:\n",
    "        ax.imshow(data[:, :, i], cmap='gray')  # Assuming grayscale images\n",
    "        ax.set_title(f\"Subplot {i+1}\")\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')  # Hide extra subplots\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d03c2-fb59-4107-a25f-b86e03c77d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example dictionary with tensors as values\n",
    "tensor_dict = {\n",
    "    'tensor1': np.random.rand(28, 28),\n",
    "    'tensor2': np.random.rand(28, 28),\n",
    "    'tensor3': np.random.rand(28, 28),\n",
    "    'tensor4': np.random.rand(28, 28),\n",
    "    'tensor5': np.random.rand(28, 28)\n",
    "}\n",
    "\n",
    "# Create odd number of subplots\n",
    "num_subplots = len(tensor_dict)\n",
    "num_cols = 2\n",
    "num_rows = (num_subplots + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "\n",
    "# Plot images in each subplot\n",
    "for i, (key, tensor) in enumerate(tensor_dict.items()):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    axs[row, col].imshow(tensor, cmap='gray')  # Assuming grayscale tensors\n",
    "    axs[row, col].set_title(key)\n",
    "    axs[row, col].axis('off')\n",
    "\n",
    "# Hide extra subplots\n",
    "for i in range(num_subplots, num_rows * num_cols):\n",
    "    axs.flatten()[i].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3cc7a-a031-4787-80e1-e65ddf322412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example dictionary with tensors as values\n",
    "tensor_dict = {\n",
    "    'tensor1': np.random.rand(2, 1),\n",
    "    'tensor2': np.random.rand(1, 4),\n",
    "    'tensor3': np.random.rand(4, 4),\n",
    "    'tensor4': np.random.rand(1, 4),\n",
    "    'tensor5': np.random.rand(1, 1)\n",
    "}\n",
    "\n",
    "# Create odd number of subplots\n",
    "num_subplots = len(tensor_dict)\n",
    "num_cols = 2\n",
    "num_rows = (num_subplots + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n",
    "\n",
    "# Plot images and add values in each subplot\n",
    "for i, (key, tensor) in enumerate(tensor_dict.items()):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    ax = axs[row, col]\n",
    "    print(\"*\"*50)\n",
    "    print(i)\n",
    "    print(key)\n",
    "    print(tensor)\n",
    "    print(\"*\"*10)\n",
    "    print(f\"tensor shape: {tensor.shape}\")\n",
    "    print(tensor.ndim)\n",
    "    print(\"Now tensor\")\n",
    "    ax.imshow(tensor, cmap='viridis', interpolation='none')  # Assuming grayscale tensors\n",
    "    print(\"printed\")\n",
    "    print(\"*\"*50)\n",
    "    ax.set_title(key)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add values in the middle of the cell\n",
    "    for y in range(tensor.shape[0]):\n",
    "        for x in range(tensor.shape[1]):\n",
    "            value = tensor[y, x]\n",
    "            ax.text(x, y, f'{value:.2f}', fontsize = 8, color='red', ha='center', va='center')\n",
    "\n",
    "# Hide extra subplots\n",
    "for i in range(num_subplots, num_rows * num_cols):\n",
    "    axs.flatten()[i].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "type(tensor_dict)\n",
    "print(tensor_dict[\"tensor1\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747a575-9b1b-46f9-97f0-4a6eace57ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tensor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8629d476-85b0-4ff5-866d-6b25a01567cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tensor_dict[\"tensor1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7ee9d-35f5-42a7-9316-88ddf9703c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def plot_weights(self):\n",
    "        weights_biases_dict = self.state_dict()\n",
    "        #weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Definition of columns, rows and subplots\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols - 1) // num_cols  \n",
    "        \n",
    "        # For colorbar (collect minimum and maximum values across all tensors)\n",
    "        all_values = np.concatenate([tensor.flatten() for tensor in weights_biases_dict.values()])\n",
    "        min_val = round(all_values.min(), 1)\n",
    "        max_val = round(all_values.max(), 1)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "        \n",
    "        # Plot images and add values in each subplot\n",
    "        for i, (key, tensor) in enumerate(weights_biases_dict.items()):\n",
    "            row = i // num_cols\n",
    "            col = i % num_cols\n",
    "            ax = axs[row, col]\n",
    "            if 'weight' in key:\n",
    "                im = ax.imshow(tensor, cmap='viridis',vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}')\n",
    "            elif 'bias' in key:\n",
    "                im = ax.imshow(tensor.unsqueeze(0), cmap='viridis', vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}')\n",
    "            #ax.axis('off')\n",
    "            \n",
    "            # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "            if len(tensor.shape) == 1:\n",
    "                tensor = tensor.reshape(1, -1)\n",
    "\n",
    "            # Add xticks and yticks\n",
    "            ax.set_xticks(np.arange(0, tensor.shape[1] , step=1))  \n",
    "            ax.set_yticks(np.arange(0, tensor.shape[0] , step=1))  \n",
    "           \n",
    "            # Add values in the middle of the cell\n",
    "            for y in range(tensor.shape[0]):\n",
    "                for x in range(tensor.shape[1]):\n",
    "                    value = tensor[y, x]\n",
    "                    ax.text(x, y, f'{value:.2f}', fontsize = 8, color='white', ha='center', va='center')\n",
    "            \n",
    "         # Hide extra subplots\n",
    "        for i in range(num_subplots, num_rows * num_cols):\n",
    "            axs.flatten()[i].axis('off')\n",
    "            \n",
    "        # Add a title to the figure\n",
    "        plt.suptitle('Weights and Biases of the Neural Network')\n",
    "        \n",
    "        # Add a colorbar\n",
    "            # Set custom ticks and intervals\n",
    "        tick_interval = 0.2\n",
    "        ticks = np.arange(min_val, max_val, step=tick_interval)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.01])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', ticks = ticks)\n",
    "        #cbar.set_label('Colorbar Label') Label for the Colorbar\n",
    "        \n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "# Call the plot_weights method\n",
    "model.plot_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f69ab5-1321-46bf-91df-13b2506d460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def plot_weights(self):\n",
    "        state_dict = self.state_dict()\n",
    "        weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Create a figure for visualization\n",
    "        num_plots = len(weights_biases_dict)\n",
    "        fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))\n",
    "\n",
    "        # Plot the weights and biases for each layer\n",
    "        #max_intensity = 0  # Track the maximum intensity across all plots\n",
    "        for i, (key, data) in enumerate(weights_biases_dict.items()):\n",
    "            ax = axes[i] if num_plots > 1 else axes\n",
    "            if 'bias' in key:\n",
    "                title = f'{key} (Biases)'\n",
    "            elif 'weight' in key:\n",
    "                title = f'{key} (Weights)'\n",
    "                \n",
    "            if len(data.shape) == 1:\n",
    "                # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "                data = data.reshape(1, -1)\n",
    "                \n",
    "            im = ax.imshow(data.numpy(), cmap='viridis', interpolation='none')\n",
    "\n",
    "            # Add numbers to the cells\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    ax.text(j, i, f'{data[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "            ax.set_title(title)\n",
    "            #max_intensity = max(max_intensity, np.max(np.abs(data.numpy())))  # Update max intensity\n",
    "\n",
    "        # Add a colorbar below all the plots\n",
    "        #divider = make_axes_locatable(ax)\n",
    "        #cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "        #cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "        #cbar.set_label('Value')\n",
    "\n",
    "        # Normalize the color bar based on the maximum intensity across all plots\n",
    "        #cbar.set_clim(-max_intensity, max_intensity)\n",
    "\n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Call the plot_weights method\n",
    "model.plot_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd479b9-cd2b-4335-9160-c3783430e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def plot_weights(self):\n",
    "        state_dict = self.state_dict()\n",
    "        weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Create a figure for visualization\n",
    "        num_plots = len(weights_biases_dict)\n",
    "        fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))\n",
    "\n",
    "        # Plot the weights and biases for each layer\n",
    "        max_intensity = 0  # Track the maximum intensity across all plots\n",
    "        for i, (key, data) in enumerate(weights_biases_dict.items()):\n",
    "            ax = axes[i] if num_plots > 1 else axes\n",
    "            if 'bias' in key:\n",
    "                title = f'{key} (Biases)'\n",
    "            elif 'weight' in key:\n",
    "                title = f'{key} (Weights)'\n",
    "                \n",
    "            if len(data.shape) == 1:\n",
    "                # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "                data = data.reshape(1, -1)\n",
    "                \n",
    "            im = ax.imshow(data.numpy(), cmap='viridis', interpolation='none')\n",
    "\n",
    "            # Add numbers to the cells\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    ax.text(j, i, f'{data[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "            ax.set_title(title)\n",
    "            max_intensity = max(max_intensity, np.max(np.abs(data.numpy())))  # Update max intensity\n",
    "\n",
    "        # Add a colorbar below all the plots\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "        cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "        cbar.set_label('Value')\n",
    "\n",
    "        # Normalize the color bar based on the maximum intensity across all plots\n",
    "        #cbar.set_clim(-max_intensity, max_intensity)\n",
    "\n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Call the plot_weights method\n",
    "model.plot_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c597434c-a599-4385-b04e-b8b0fb823d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def visualize_difference(self, original, new, layer_name):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        # Plot weights\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f'{layer_name} Weights')\n",
    "        plt.imshow(original, cmap='viridis')\n",
    "        plt.colorbar(label='Weight Values')\n",
    "        plt.xlabel('Neurons in Previous Layer')\n",
    "        plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(f'Difference in {layer_name} Weights')\n",
    "        plt.imshow(new - original, cmap='coolwarm')\n",
    "        plt.colorbar(label='Weight Difference')\n",
    "        plt.xlabel('Neurons in Previous Layer')\n",
    "        plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572688d-29c9-4dec-9758-50c715c9fec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a10a8f-101c-467b-a329-3236684a38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize the weights and biases\n",
    "def visualize_difference(original, new, layer_name):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Plot weights\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f'{layer_name} Weights')\n",
    "    plt.imshow(original, cmap='viridis')\n",
    "    plt.colorbar(label='Weight Values')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f'Difference in {layer_name} Weights')\n",
    "    plt.imshow(new - original, cmap='coolwarm')\n",
    "    plt.colorbar(label='Weight Difference')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to create a model with specified initialization\n",
    "def create_model(input_size, hidden_layers, output_size, initialization='he'):\n",
    "    model = nn.Sequential()\n",
    "    \n",
    "    # Add input layer\n",
    "    model.add_module('input_layer', nn.Linear(input_size, hidden_layers[0]))\n",
    "    if initialization == 'he':\n",
    "        init.kaiming_uniform_(model.input_layer.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "        init.zeros_(model.input_layer.bias.data)\n",
    "\n",
    "    # Add hidden layers\n",
    "    for i in range(len(hidden_layers) - 1):\n",
    "        layer = nn.Linear(hidden_layers[i], hidden_layers[i + 1])\n",
    "        model.add_module(f'hidden_layer{i + 1}', layer)\n",
    "        if initialization == 'he':\n",
    "            init.kaiming_uniform_(layer.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "            init.zeros_(layer.bias.data)\n",
    "\n",
    "    # Add output layer\n",
    "    model.add_module('output_layer', nn.Linear(hidden_layers[-1], output_size))\n",
    "    if initialization == 'he':\n",
    "        init.kaiming_uniform_(model.output_layer.weight.data, mode='fan_in', nonlinearity='linear')\n",
    "        init.zeros_(model.output_layer.bias.data)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Step 1: Create the original model\n",
    "original_input_size = 2\n",
    "original_hidden_layers = [8, 8]\n",
    "original_output_size = 1\n",
    "original_model = create_model(original_input_size, original_hidden_layers, original_output_size, initialization='he')\n",
    "\n",
    "# Step 2: Visualize the weights and biases of the original model\n",
    "for layer_name, original_weight in original_model.named_parameters():\n",
    "    visualize_difference(original_weight.detach().numpy(), original_weight.detach().numpy(), layer_name)\n",
    "\n",
    "# Step 3: Create the extended model with 16 neurons in hidden layers\n",
    "extended_input_size = 2\n",
    "extended_hidden_layers = [16, 16]\n",
    "extended_output_size = 1\n",
    "extended_model = create_model(extended_input_size, extended_hidden_layers, extended_output_size, initialization='he')\n",
    "\n",
    "# Step 4: Visualize the weights and biases of the extended model\n",
    "for layer_name, extended_weight in extended_model.named_parameters():\n",
    "    visualize_difference(extended_weight.detach().numpy(), extended_weight.detach().numpy(), layer_name)\n",
    "\n",
    "# Step 5: Overwrite the weights and biases of the extended model with the original model\n",
    "for original_param, extended_param in zip(original_model.parameters(), extended_model.parameters()):\n",
    "    extended_param.data.copy_(original_param.data)\n",
    "\n",
    "# Step 6: Visualize the weights and biases of the extended model after overwriting\n",
    "for layer_name, extended_weight in extended_model.named_parameters():\n",
    "    visualize_difference(original_weight.detach().numpy(), extended_weight.detach().numpy(), layer_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b3a93-0bbd-4f43-a9d2-b560f9cab46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple fully connected neural network\n",
    "class MyFCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyFCNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)  # Example: input size=10, output size=5\n",
    "        self.fc2 = nn.Linear(4, 1)   # Example: input size=5, output size=2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "model = MyFCNet()\n",
    "\n",
    "# Get the state_dict of the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights and biases from the state_dict\n",
    "for key, value in state_dict.items():\n",
    "    if 'weight' in key:\n",
    "        print(f\"Layer: {key}, Shape: {value.shape}\")\n",
    "        print(\"Weights:\")\n",
    "        print(value)\n",
    "    elif 'bias' in key:\n",
    "        print(f\"Layer: {key}, Shape: {value.shape}\")\n",
    "        print(\"Biases:\")\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee472dbf-d387-426f-8942-802ecdae1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor with shape (4,)\n",
    "tensor = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "# Transform the tensor to shape (4, 1)\n",
    "tensor_reshaped = tensor.unsqueeze(0)\n",
    "\n",
    "print(\"Original tensor shape:\", tensor.shape)\n",
    "print(\"Transformed tensor shape:\", tensor_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5880b-7921-4ad0-9cf9-ef7b703b96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model using nn.Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "\n",
    "# Initialize some input data\n",
    "input_data = torch.randn(3, 10)\n",
    "\n",
    "# Forward pass through the model\n",
    "output = model(input_data)\n",
    "\n",
    "# Print the output\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff3d373-98fd-45e5-b52f-036ce297e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the model parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef18881-6a28-4ad2-967f-407273319db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7252d31-6e6d-4280-b553-f8ffe5029832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_sizes[0]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_sizes[i], hidden_size),\n",
    "                nn.ReLU()\n",
    "            ) for i, hidden_size in enumerate(hidden_sizes[1:])\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_size = 2\n",
    "hidden_sizes = [4, 8, 8, 4]\n",
    "output_size = 1\n",
    "\n",
    "model = SimpleModel(input_size, hidden_sizes, output_size)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da54a9ec-0513-4c65-a53c-73678ada7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932e9bb-3f85-4ee7-b67b-97b7035e0e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2d73c-3b29-4cb5-a6d2-4839ef00060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example weight matrix (2x3) and bias vector (2,)\n",
    "W = torch.randn(2, 3)\n",
    "x = torch.randn(3)\n",
    "b = torch.randn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea815ca-818c-4400-88b9-06f40a0fb0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5c51ec-fe88-4440-a80e-6481fda30610",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbd9c8-b29c-4516-819d-2a6ea91f3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff30b63-ecd2-4d50-b67d-894bf4552da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform matrix multiplication\n",
    "result = torch.matmul(W, x)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871d93a-aadf-4e56-800c-bc19857a2319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bias vector element-wise to each row of the result\n",
    "result_with_bias = result + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b012fff-da02-4693-be63-9f492aa77dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result with bias:\", result_with_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594b1e5-52f7-410a-8ef9-80495b5c2433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db9d4e-0776-4a88-8923-056cdd4226ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8247e4-9b73-4686-8014-3e763b485550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture of the original network\n",
    "original_input_size = 2\n",
    "original_hidden_layers = [8, 8]\n",
    "original_output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8380b3-6539-4a36-bdb6-c6de593e4233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the original model with Xavier initialization\n",
    "class OriginalModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(OriginalModel, self).__init__()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layers[0])\n",
    "        init.xavier_uniform_(self.input_layer.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        init.zeros_(self.input_layer.bias.data)\n",
    "        \n",
    "        # Hidden layers with Xavier initialization\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers)-1)\n",
    "        ])\n",
    "        for layer in self.hidden_layers:\n",
    "            init.xavier_uniform_(layer.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "            init.zeros_(layer.bias.data)\n",
    "        \n",
    "        # Output layer with Xavier initialization\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "        init.xavier_uniform_(self.output_layer.weight.data, gain=nn.init.calculate_gain('linear'))\n",
    "        init.zeros_(self.output_layer.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4ade0-d2a1-4ea8-96cf-cf26a48c74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create an instance of the original model\n",
    "original_model = OriginalModel(original_input_size, original_hidden_layers, original_output_size)\n",
    "\n",
    "# Define the architecture of the new network with increased neurons\n",
    "new_input_size = 2\n",
    "new_hidden_layers = [16, 16]  # Increase the number of neurons\n",
    "new_output_size = 1\n",
    "\n",
    "# Create a new model with the same architecture as the original one\n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(NewModel, self).__init__()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layers[0])\n",
    "        \n",
    "        # Hidden layers with weights and biases from the original model\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers)-1)\n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the new model\n",
    "new_model = NewModel(new_input_size, new_hidden_layers, new_output_size)\n",
    "\n",
    "# Set the weights from the original model using He initialization\n",
    "def initialize_weights_he(model):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            init.kaiming_uniform_(layer.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "            init.zeros_(layer.bias.data)\n",
    "\n",
    "# Initialize weights of the new model using He initialization\n",
    "initialize_weights_he(new_model)\n",
    "\n",
    "# Visualize the differences in weights and biases\n",
    "def visualize_difference(original, new, layer_name):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Plot weights\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f'{layer_name} Weights')\n",
    "    plt.imshow(original, cmap='viridis')\n",
    "    plt.colorbar(label='Weight Values')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f'Difference in {layer_name} Weights')\n",
    "    plt.imshow(new - original, cmap='coolwarm')\n",
    "    plt.colorbar(label='Weight Difference')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize differences for each layer\n",
    "for layer_name, original_weight in original_model.state_dict().items():\n",
    "    new_weight = new_model.state_dict()[layer_name]\n",
    "    visualize_difference(original_weight, new_weight, layer_name)\n",
    "\n",
    "# Visualize differences for biases\n",
    "for layer_name, original_bias in original_model.state_dict().items():\n",
    "    if 'bias' in layer_name:\n",
    "        new_bias = new_model.state_dict()[layer_name]\n",
    "        visualize_difference(original_bias.unsqueeze(0), new_bias.unsqueeze(0), layer_name + ' Bias')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afdd9b6-a055-431c-8591-16a4c9a946a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def find_max_min_values(state_dict):\n",
    "    max_value = float('-inf')\n",
    "    min_value = float('inf')\n",
    "\n",
    "    for key, tensor in state_dict.items():\n",
    "        if isinstance(tensor, torch.Tensor):\n",
    "            if tensor.dim() == 0:\n",
    "                tensor_max = tensor.item()\n",
    "                tensor_min = tensor.item()\n",
    "            else:\n",
    "                tensor_max = torch.max(tensor).item()\n",
    "                tensor_min = torch.min(tensor).item()\n",
    "            max_value = max(max_value, tensor_max)\n",
    "            min_value = min(min_value, tensor_min)\n",
    "\n",
    "    return max_value, min_value\n",
    "\n",
    "# Example usage\n",
    "model = YourModel()  # Instantiate your model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "max_value, min_value = find_max_min_values(state_dict)\n",
    "print(\"Max value:\", max_value)\n",
    "print(\"Min value:\", min_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316ffe9-fd28-403d-ad7b-dbecfbf5f61e",
   "metadata": {},
   "source": [
    "# AS II Old versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1003e-bf5a-4777-9cf5-d3d4b1e35741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT = 2, hidden_layers = [4], N_OUTPUT = 1,  activation='Tanh', initialization='Xavier'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_functions = nn.ModuleDict([\n",
    "            [\"Tanh\", nn.Tanh()],\n",
    "            [\"ReLU\", nn.ReLU()],\n",
    "            [\"LeakyReLU\", nn.LeakyReLU()],\n",
    "            [\"Sigmoid\", nn.Sigmoid()],\n",
    "            [\"Softmax\", nn.Softmax(dim=-1)],\n",
    "        ])\n",
    "\n",
    "        if activation not in self.activation_functions:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.activation = self.activation_functions[activation]\n",
    "\n",
    "        #self.fci = nn.Sequential(\n",
    "        #    nn.Linear(N_INPUT, hidden_layers[0]),\n",
    "        #    self.activation\n",
    "        #)\n",
    "        self.fci = nn.Linear(N_INPUT, hidden_layers[0])\n",
    "\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_layers[i], hidden_layers[i + 1]),\n",
    "                self.activation\n",
    "            ) for i in range(len(hidden_layers) - 1)\n",
    "        ])\n",
    "\n",
    "        self.fco = nn.Linear(hidden_layers[-1], N_OUTPUT)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fci(x))\n",
    "        for layer in self.fch:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "    \n",
    "    def initialize_parameters(self, initialization):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if initialization == 'Uniform':\n",
    "                    init.uniform_(module.weight.data, -0.1, 0.1)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Normal':\n",
    "                    init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Xavier':\n",
    "                    init.xavier_uniform_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'He':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Orthogonal':\n",
    "                    init.orthogonal_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Kaiming':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported initialization type\")\n",
    "\n",
    "    def plot_weights(self, figsize = (10,5)):\n",
    "        self.figsize = figsize\n",
    "        weights_biases_dict = self.state_dict()\n",
    "        #weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Definition of columns, rows and subplots\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols - 1) // num_cols  \n",
    "        \n",
    "        # For colorbar (collect minimum and maximum values across all tensors)\n",
    "        all_values = np.concatenate([tensor.flatten() for tensor in weights_biases_dict.values()])\n",
    "        min_val = round(all_values.min(), 2)\n",
    "        max_val = round(all_values.max(), 2)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize = self.figsize)\n",
    "        \n",
    "        # Plot images and add values in each subplot\n",
    "        for i, (key, tensor) in enumerate(weights_biases_dict.items()):\n",
    "            row = i // num_cols\n",
    "            col = i % num_cols\n",
    "            ax = axs[row, col]\n",
    "            if 'weight' in key:\n",
    "                im = ax.imshow(tensor, cmap='viridis',vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            elif 'bias' in key:\n",
    "                im = ax.imshow(tensor.unsqueeze(0), cmap='viridis', vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            #ax.axis('off')\n",
    "            \n",
    "            # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "            if len(tensor.shape) == 1:\n",
    "                tensor = tensor.reshape(1, -1)\n",
    "\n",
    "            # Add xticks and yticks\n",
    "            ax.set_xticks(np.arange(0, tensor.shape[1] , step=1))  \n",
    "            ax.tick_params(axis='x', labelsize = 8)\n",
    "            ax.set_yticks(np.arange(0, tensor.shape[0] , step=1))\n",
    "            ax.tick_params(axis='y', labelsize = 8)\n",
    "\n",
    "           \n",
    "            # Add values in the middle of the cell\n",
    "            for y in range(tensor.shape[0]):\n",
    "                for x in range(tensor.shape[1]):\n",
    "                    value = tensor[y, x]\n",
    "                    ax.text(x, y, f'{value:.2f}', fontsize = 8, color='white', ha='center', va='center')\n",
    "            \n",
    "         # Hide extra subplots\n",
    "        for i in range(num_subplots, num_rows * num_cols):\n",
    "            axs.flatten()[i].axis('off')\n",
    "            \n",
    "        # Add a title to the figure\n",
    "        plt.suptitle('Weights and Biases of the Neural Network')\n",
    "        \n",
    "        # Add a colorbar\n",
    "            # Set custom ticks and intervals\n",
    "        tick_interval = 0.2\n",
    "        ticks = np.arange(min_val, max_val, step=tick_interval)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.01])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', ticks = ticks)\n",
    "        cbar.set_label('Range of Weights and Biases') \n",
    "        \n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "# Step 1: Create the original model\n",
    "original_input_size = 2\n",
    "original_hidden_layers = [4,4]\n",
    "original_output_size = 1\n",
    "original_model = FCN(original_input_size, original_hidden_layers, original_output_size, activation='Tanh', initialization='Xavier')\n",
    "original_model.plot_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f043097-7e86-4887-a7c6-8ed63f1e8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326f56d-362a-4349-af0c-c5c5ae09312a",
   "metadata": {},
   "source": [
    "## ASII: extended methods added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe6533-4807-430b-b43b-0a9db3982b10",
   "metadata": {},
   "source": [
    "### BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636809c5-91a5-4df4-9d8b-93cb3ff1c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT = 2, hidden_layers = [4], N_OUTPUT = 1, activation='Tanh', initialization='Xavier'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_functions = nn.ModuleDict([\n",
    "            [\"Tanh\", nn.Tanh()],\n",
    "            [\"ReLU\", nn.ReLU()],\n",
    "            [\"LeakyReLU\", nn.LeakyReLU()],\n",
    "            [\"Sigmoid\", nn.Sigmoid()],\n",
    "            [\"Softmax\", nn.Softmax(dim=-1)],\n",
    "        ])\n",
    "\n",
    "        if activation not in self.activation_functions:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.activation = self.activation_functions[activation]\n",
    "\n",
    "        self.fci = nn.Linear(N_INPUT, hidden_layers[0])\n",
    "\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_layers[i], hidden_size),\n",
    "                self.activation\n",
    "            ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        ])\n",
    "\n",
    "        self.fco = nn.Linear(hidden_layers[-1], N_OUTPUT)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fci(x))\n",
    "        for layer in self.fch:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "        \n",
    "    def initialize_parameters(self, initialization):\n",
    "        \n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if initialization == 'Uniform':\n",
    "                    init.uniform_(module.weight.data, -0.1, 0.1)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Normal':\n",
    "                    init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Xavier':\n",
    "                    init.xavier_uniform_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'He':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Orthogonal':\n",
    "                    init.orthogonal_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Kaiming':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported initialization type\")\n",
    "\n",
    "    def plot_weights(self, figsize = (10,5)):\n",
    "        \n",
    "        self.figsize = figsize\n",
    "        \n",
    "        weights_biases_dict = self.state_dict()\n",
    "        #weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Definition of columns, rows and subplots\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols - 1) // num_cols  \n",
    "        \n",
    "        # For colorbar (collect minimum and maximum values across all tensors)\n",
    "        all_values = np.concatenate([tensor.flatten() for tensor in weights_biases_dict.values()])\n",
    "        min_val = round(all_values.min(), 2)\n",
    "        max_val = round(all_values.max(), 2)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize = self.figsize)\n",
    "        \n",
    "        # Plot images and add values in each subplot\n",
    "        for i, (key, tensor) in enumerate(weights_biases_dict.items()):\n",
    "            row = i // num_cols\n",
    "            col = i % num_cols\n",
    "            ax = axs[row, col]\n",
    "            if 'weight' in key:\n",
    "                im = ax.imshow(tensor, cmap='viridis',vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            elif 'bias' in key:\n",
    "                im = ax.imshow(tensor.unsqueeze(0), cmap='viridis', vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            #ax.axis('off')\n",
    "            \n",
    "            # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "            if len(tensor.shape) == 1:\n",
    "                tensor = tensor.reshape(1, -1)\n",
    "\n",
    "            # Add xticks and yticks\n",
    "            ax.set_xticks(np.arange(0, tensor.shape[1] , step=1))  \n",
    "            ax.tick_params(axis='x', labelsize = 8)\n",
    "            ax.set_yticks(np.arange(0, tensor.shape[0] , step=1))\n",
    "            ax.tick_params(axis='y', labelsize = 8)\n",
    "\n",
    "           \n",
    "            # Add values in the middle of the cell\n",
    "            for y in range(tensor.shape[0]):\n",
    "                for x in range(tensor.shape[1]):\n",
    "                    value = tensor[y, x]\n",
    "                    ax.text(x, y, f'{value:.2f}', fontsize = 8, color='white', ha='center', va='center')\n",
    "            \n",
    "         # Hide extra subplots\n",
    "        for i in range(num_subplots, num_rows * num_cols):\n",
    "            axs.flatten()[i].axis('off')\n",
    "            \n",
    "        # Add a title to the figure\n",
    "        plt.suptitle('Weights and Biases of the Neural Network')\n",
    "        \n",
    "        # Add a colorbar\n",
    "            # Set custom ticks and intervals\n",
    "        tick_interval = 0.2\n",
    "        ticks = np.arange(min_val, max_val, step=tick_interval)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.01])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', ticks = ticks)\n",
    "        cbar.set_label('Range of Weights and Biases') \n",
    "        \n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "class FCN_extended(FCN):\n",
    "    def __init__(self, N_INPUT, hidden_layers, N_OUTPUT, activation='Tanh', initialization='Xavier', original_model_path=None):\n",
    "        super().__init__(N_INPUT, hidden_layers, N_OUTPUT, activation, initialization)\n",
    "    \n",
    "        self.original_model_path = original_model_path\n",
    "        \n",
    "        self.load_override_original_weights_biases()\n",
    "\n",
    "    def load_override_original_weights_biases(self):\n",
    "        if self.original_model_path is None:\n",
    "            raise ValueError(\"Path to the original model checkpoint is not provided.\")\n",
    "\n",
    "        if not os.path.exists(self.original_model_path):\n",
    "            raise FileNotFoundError(f\"Provided path '{self.original_model_path}' does not exist.\")\n",
    "\n",
    "        if not os.path.isfile(self.original_model_path):\n",
    "            raise ValueError(f\"Provided path '{self.original_model_path}' is not a file.\")\n",
    "\n",
    "        _, ext = os.path.splitext(self.original_model_path)\n",
    "        if ext not in ['.pt', '.pth']:\n",
    "            raise ValueError(\"Provided file is not a valid checkpoint file.\")\n",
    "        \n",
    "        # Load weights and biases from original_model\n",
    "        original_state_dict = torch.load(self.original_model_path)['model_state_dict']\n",
    "        \n",
    "        # Update extended model state dictionary with original model's parameters\n",
    "        self.load_state_dict(original_state_dict, strict=False)\n",
    "        \n",
    "        # Override weights and biases from original model\n",
    "        for name, param in self.named_parameters():\n",
    "            #print(f\"name: {name}, param: {param}\")\n",
    "            if name in original_state_dict:\n",
    "                param.data.copy_(original_state_dict[name].data)\n",
    "\n",
    "    def extend_hidden_layers(self, num_hidden_layers):\n",
    "        current_hidden_layers = len(self.fch)\n",
    "        if current_hidden_layers > num_hidden_layers:\n",
    "            raise ValueError(\"Cannot reduce the number of hidden layers.\")\n",
    "\n",
    "        for _ in range(num_hidden_layers - current_hidden_layers):\n",
    "            new_layer = nn.Sequential(\n",
    "                nn.Linear(self.hidden_layers[-1], self.hidden_layers[-1]),\n",
    "                self.activation)\n",
    "\n",
    "            self.fch.append(new_layer)\n",
    "\n",
    "    def extend_neurons(self, num_neurons):\n",
    "        if len(self.fch) == 0:\n",
    "            raise ValueError(\"Cannot extend neurons with no hidden layers.\")\n",
    "\n",
    "        for layer in self.fch:\n",
    "            current_neurons = layer[0].in_features\n",
    "            if current_neurons < num_neurons:\n",
    "                new_weights = torch.cat([layer[0].weight.data, torch.randn(num_neurons - current_neurons, current_neurons)], dim=0)\n",
    "                new_biases = torch.cat([layer[0].bias.data, torch.zeros(num_neurons - current_neurons)], dim=0)\n",
    "                layer[0].weight.data = new_weights\n",
    "                layer[0].bias.data = new_biases\n",
    "            elif current_neurons > num_neurons:\n",
    "                layer[0].weight.data = layer[0].weight.data[:num_neurons, :]\n",
    "                layer[0].bias.data = layer[0].bias.data[:num_neurons]\n",
    "\n",
    "class TrainModel:\n",
    "    def __init__(self, model, num_epochs, save_interval, loss_threshold=None):\n",
    "        self.model = model\n",
    "        self.num_epochs = num_epochs\n",
    "        self.save_interval = save_interval\n",
    "        self.loss_threshold = loss_threshold\n",
    "\n",
    "    def train(self):\n",
    "        optimizer = optim.Adam(self.model.parameters())\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            # Train the model\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = self.model(torch.randn(10, original_input_size))\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, torch.randn(10, original_output_size))\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save model checkpoint\n",
    "            if epoch % self.save_interval == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss\n",
    "                }, f\"original_model_{epoch}.pt\")\n",
    "\n",
    "            # Check loss threshold\n",
    "            if self.loss_threshold is not None and loss.item() < self.loss_threshold:\n",
    "                print(f\"Loss threshold reached at epoch {epoch}. Stopping training.\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94c7c03-1e5f-4596-a754-ff86eac07be0",
   "metadata": {},
   "source": [
    "### Updating the FCN_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8113b5f-0306-4ef7-b059-e8f34d192cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BACKUP:\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT = 2, hidden_layers = [4], N_OUTPUT = 1, activation='Tanh', initialization='Xavier'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_functions = nn.ModuleDict([\n",
    "            [\"Tanh\", nn.Tanh()],\n",
    "            [\"ReLU\", nn.ReLU()],\n",
    "            [\"LeakyReLU\", nn.LeakyReLU()],\n",
    "            [\"Sigmoid\", nn.Sigmoid()],\n",
    "            [\"Softmax\", nn.Softmax(dim=-1)],\n",
    "        ])\n",
    "\n",
    "        if activation not in self.activation_functions:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.activation = self.activation_functions[activation]\n",
    "\n",
    "        # self.fci = nn.Linear(N_INPUT, hidden_layers[0])\n",
    "\n",
    "        # self.fch = nn.ModuleList([\n",
    "        #     nn.Sequential(\n",
    "        #         nn.Linear(hidden_layers[i], hidden_size),\n",
    "        #         self.activation\n",
    "        #     ) for i, hidden_size in enumerate(hidden_layers[1:])    # ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        # ])\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(N_INPUT if i == 0 else hidden_sizes[i-1], hidden_size),\n",
    "                self.activation\n",
    "            ) for i, hidden_size in enumerate(hidden_layers[:])    # ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        ])\n",
    "\n",
    "        self.fco = nn.Linear(hidden_layers[-1], N_OUTPUT)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.activation(self.fci(x))\n",
    "        for layer in self.fch:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "    def initialize_parameters(self, initialization):\n",
    "        \n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if initialization == 'Uniform':\n",
    "                    init.uniform_(module.weight.data, -0.1, 0.1)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Normal':\n",
    "                    init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Xavier':\n",
    "                    init.xavier_uniform_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'He':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Orthogonal':\n",
    "                    init.orthogonal_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Kaiming':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported initialization type\")\n",
    "    \n",
    "    def plot_weights(self, figsize = (10,5)):\n",
    "        \n",
    "        self.figsize = figsize\n",
    "        \n",
    "        weights_biases_dict = self.state_dict()\n",
    "        #weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Definition of columns, rows and subplots\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols - 1) // num_cols  \n",
    "        \n",
    "        # For colorbar (collect minimum and maximum values across all tensors)\n",
    "        all_values = np.concatenate([tensor.flatten() for tensor in weights_biases_dict.values()])\n",
    "        min_val = round(all_values.min(), 2)\n",
    "        max_val = round(all_values.max(), 2)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize = self.figsize)\n",
    "        \n",
    "        # Plot images and add values in each subplot\n",
    "        for i, (key, tensor) in enumerate(weights_biases_dict.items()):\n",
    "            row = i // num_cols\n",
    "            col = i % num_cols\n",
    "            ax = axs[row, col]\n",
    "            if 'weight' in key:\n",
    "                im = ax.imshow(tensor, cmap='viridis',vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            elif 'bias' in key:\n",
    "                im = ax.imshow(tensor.unsqueeze(0), cmap='viridis', vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            #ax.axis('off')\n",
    "            \n",
    "            # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "            if len(tensor.shape) == 1:\n",
    "                tensor = tensor.reshape(1, -1)\n",
    "\n",
    "            # Add xticks and yticks\n",
    "            ax.set_xticks(np.arange(0, tensor.shape[1] , step=1))  \n",
    "            ax.tick_params(axis='x', labelsize = 8)\n",
    "            ax.set_yticks(np.arange(0, tensor.shape[0] , step=1))\n",
    "            ax.tick_params(axis='y', labelsize = 8)\n",
    "\n",
    "           \n",
    "            # Add values in the middle of the cell\n",
    "            for y in range(tensor.shape[0]):\n",
    "                for x in range(tensor.shape[1]):\n",
    "                    value = tensor[y, x]\n",
    "                    ax.text(x, y, f'{value:.2f}', fontsize = 8, color='white', ha='center', va='center')\n",
    "            \n",
    "         # Hide extra subplots\n",
    "        for i in range(num_subplots, num_rows * num_cols):\n",
    "            axs.flatten()[i].axis('off')\n",
    "            \n",
    "        # Add a title to the figure\n",
    "        plt.suptitle('Weights and Biases of the Neural Network')\n",
    "        \n",
    "        # Add a colorbar\n",
    "            # Set custom ticks and intervals\n",
    "        tick_interval = 0.2\n",
    "        ticks = np.arange(min_val, max_val, step=tick_interval)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.01])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', ticks = ticks)\n",
    "        cbar.set_label('Range of Weights and Biases') \n",
    "        \n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "class FCN_extended(FCN):\n",
    "    def __init__(self, N_INPUT, hidden_layers, N_OUTPUT, activation='Tanh', initialization='Xavier', original_model_path=None):\n",
    "        super().__init__(N_INPUT, hidden_layers, N_OUTPUT, activation, initialization)\n",
    "    \n",
    "        self.original_model_path = original_model_path\n",
    "        self.original_neurons =  self.fch[0]0].in_features # assuming that all hidden layers have the same number of neurons \n",
    "        print(f\"Original_neurons in __init__: {self.original_neurons}\")      \n",
    "        self.extended_neurons = hidden_layers[-1] # assuming that all hidden layers have the same number of neurons \n",
    "        print(f\"extended_neurons: {self.extended_neurons}\")\n",
    "        # Check if hidden layers need to be extended\n",
    "        if len(hidden_layers) < len(self.fch): \n",
    "            raise ValueError(\"The number of hidden layers of the extended model must be larger as the original model\")\n",
    "        elif len(hidden_layers) > len(self.fch):\n",
    "            #self.extend_hidden_layers(len(hidden_layers))\n",
    "            self.load_override_original_weights_biases()\n",
    "        else:\n",
    "            self.extend_neurons() \n",
    "            \n",
    "    def load_override_original_weights_biases(self):\n",
    "        if self.original_model_path is None:\n",
    "            raise ValueError(\"Path to the original model checkpoint is not provided.\")\n",
    "\n",
    "        if not os.path.exists(self.original_model_path):\n",
    "            raise FileNotFoundError(f\"Provided path '{self.original_model_path}' does not exist.\")\n",
    "\n",
    "        if not os.path.isfile(self.original_model_path):\n",
    "            raise ValueError(f\"Provided path '{self.original_model_path}' is not a file.\")\n",
    "\n",
    "        _, ext = os.path.splitext(self.original_model_path)\n",
    "        if ext not in ['.pt', '.pth']:\n",
    "            raise ValueError(\"Provided file is not a valid checkpoint file.\")\n",
    "        \n",
    "        # Load weights and biases from original_model\n",
    "        original_state_dict = torch.load(self.original_model_path)['model_state_dict']\n",
    "        \n",
    "        # Update extended model state dictionary with original model's parameters\n",
    "        self.load_state_dict(original_state_dict, strict=False)\n",
    "        \n",
    "        # Override weights and biases from original model\n",
    "        for name, param in self.named_parameters():\n",
    "            if name in original_state_dict:\n",
    "                param.data.copy_(original_state_dict[name].data)\n",
    "\n",
    "    def extend_hidden_layers(self, num_hidden_layers):\n",
    "        current_hidden_layers = len(self.fch)\n",
    "        if current_hidden_layers > num_hidden_layers:\n",
    "            raise ValueError(\"Cannot reduce the number of hidden layers.\")\n",
    "\n",
    "        for _ in range(num_hidden_layers - current_hidden_layers):\n",
    "            new_layer = nn.Sequential(\n",
    "                nn.Linear(self.hidden_layers[-1], self.hidden_layers[-1]),\n",
    "                self.activation)\n",
    "\n",
    "            self.fch.append(new_layer)\n",
    "\n",
    "    def extend_neurons(self):\n",
    "        if len(self.fch) == 0:\n",
    "            raise ValueError(\"Cannot extend neurons with no hidden layers.\")\n",
    "\n",
    "        for layer in self.fch:\n",
    "            original_neurons = layer[0].weight.size(0)\n",
    "            print(f\"Original_neurons: {original_neurons}\")\n",
    "            print(f\"Original neurons in layer {layer[0]} extend_neurons: {original_neurons}\")\n",
    "            # if original_neurons < self.extended_neurons:\n",
    "            #     # Extend weights using the provided initialization\n",
    "            #     init_fn = getattr(init, self.initialization)      # getattr( use to access dynamically the attributes or methods of an object based on a string name )\n",
    "            #     new_weights = init_fn(layer[0].weight.new_empty(self.extended_neurons - original_neurons, original_neurons))\n",
    "            #     new_biases = init.constant_(layer[0].bias.new_empty(self.extended_neurons - original_neurons), 0)\n",
    "            #     layer[0].weight.data = torch.cat([layer[0].weight.data, new_weights], dim=0)\n",
    "            #     layer[0].bias.data = torch.cat([layer[0].bias.data, new_biases], dim=0)\n",
    "            # else:\n",
    "            #     raise ValueError(\"Maintaining or reducing the number of neurons is not allowed\")\n",
    "class TrainModel:\n",
    "    def __init__(self, model, num_epochs, save_interval, loss_threshold=None):\n",
    "        self.model = model\n",
    "        self.num_epochs = num_epochs\n",
    "        self.save_interval = save_interval\n",
    "        self.loss_threshold = loss_threshold\n",
    "\n",
    "    def train(self):\n",
    "        optimizer = optim.Adam(self.model.parameters())\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            # Train the model\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = self.model(torch.randn(10, original_input_size))\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, torch.randn(10, original_output_size))\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save model checkpoint\n",
    "            if epoch % self.save_interval == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss\n",
    "                }, f\"original_model_{epoch}.pt\")\n",
    "\n",
    "            # Check loss threshold\n",
    "            if self.loss_threshold is not None and loss.item() < self.loss_threshold:\n",
    "                print(f\"Loss threshold reached at epoch {epoch}. Stopping training.\")\n",
    "                break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc03e1f4-6aaf-4a37-aacf-f35d923a968e",
   "metadata": {},
   "source": [
    "## New version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b3653-531a-41ca-9cbf-f25779eaf9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT = 2, hidden_layers = [4], N_OUTPUT = 1, activation='Tanh', initialization='Xavier'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_functions = nn.ModuleDict([\n",
    "            [\"Tanh\", nn.Tanh()],\n",
    "            [\"ReLU\", nn.ReLU()],\n",
    "            [\"LeakyReLU\", nn.LeakyReLU()],\n",
    "            [\"Sigmoid\", nn.Sigmoid()],\n",
    "            [\"Softmax\", nn.Softmax(dim=-1)],\n",
    "        ])\n",
    "\n",
    "        if activation not in self.activation_functions:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.activation = self.activation_functions[activation]\n",
    "\n",
    "        # self.fci = nn.Linear(N_INPUT, hidden_layers[0])\n",
    "\n",
    "        # self.fch = nn.ModuleList([\n",
    "        #     nn.Sequential(\n",
    "        #         nn.Linear(hidden_layers[i], hidden_size),\n",
    "        #         self.activation\n",
    "        #     ) for i, hidden_size in enumerate(hidden_layers[1:])    # ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        # ])\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(N_INPUT if i == 0 else hidden_size, hidden_size),\n",
    "                self.activation\n",
    "            ) for i, hidden_size in enumerate(hidden_layers[:])    # ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        ])\n",
    "\n",
    "        self.fco = nn.Linear(hidden_layers[-1], N_OUTPUT)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.activation(self.fci(x))\n",
    "        for layer in self.fch:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "    def initialize_parameters(self, initialization):\n",
    "        \n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if initialization == 'Uniform':\n",
    "                    init.uniform_(module.weight.data, -0.1, 0.1)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Normal':\n",
    "                    init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Xavier':\n",
    "                    init.xavier_uniform_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'He':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Orthogonal':\n",
    "                    init.orthogonal_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Kaiming':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported initialization type\")\n",
    "    \n",
    "    def plot_weights(self, figsize = (10,5)):\n",
    "        \n",
    "        self.figsize = figsize\n",
    "        \n",
    "        weights_biases_dict = self.state_dict()\n",
    "        #weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Definition of columns, rows and subplots\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols - 1) // num_cols  \n",
    "        \n",
    "        # For colorbar (collect minimum and maximum values across all tensors)\n",
    "        all_values = np.concatenate([tensor.flatten() for tensor in weights_biases_dict.values()])\n",
    "        min_val = round(all_values.min(), 2)\n",
    "        max_val = round(all_values.max(), 2)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize = self.figsize)\n",
    "        \n",
    "        # Plot images and add values in each subplot\n",
    "        for i, (key, tensor) in enumerate(weights_biases_dict.items()):\n",
    "            row = i // num_cols\n",
    "            col = i % num_cols\n",
    "            ax = axs[row, col]\n",
    "            if 'weight' in key:\n",
    "                im = ax.imshow(tensor, cmap='viridis',vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            elif 'bias' in key:\n",
    "                im = ax.imshow(tensor.unsqueeze(0), cmap='viridis', vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            #ax.axis('off')\n",
    "            \n",
    "            # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "            if len(tensor.shape) == 1:\n",
    "                tensor = tensor.reshape(1, -1)\n",
    "\n",
    "            # Add xticks and yticks\n",
    "            ax.set_xticks(np.arange(0, tensor.shape[1] , step=1))  \n",
    "            ax.tick_params(axis='x', labelsize = 8)\n",
    "            ax.set_yticks(np.arange(0, tensor.shape[0] , step=1))\n",
    "            ax.tick_params(axis='y', labelsize = 8)\n",
    "\n",
    "           \n",
    "            # Add values in the middle of the cell\n",
    "            for y in range(tensor.shape[0]):\n",
    "                for x in range(tensor.shape[1]):\n",
    "                    value = tensor[y, x]\n",
    "                    ax.text(x, y, f'{value:.2f}', fontsize = 8, color='white', ha='center', va='center')\n",
    "            \n",
    "         # Hide extra subplots\n",
    "        for i in range(num_subplots, num_rows * num_cols):\n",
    "            axs.flatten()[i].axis('off')\n",
    "            \n",
    "        # Add a title to the figure\n",
    "        plt.suptitle('Weights and Biases of the Neural Network')\n",
    "        \n",
    "        # Add a colorbar\n",
    "            # Set custom ticks and intervals\n",
    "        tick_interval = 0.2\n",
    "        ticks = np.arange(min_val, max_val, step=tick_interval)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.01])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', ticks = ticks)\n",
    "        cbar.set_label('Range of Weights and Biases') \n",
    "        \n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "class FCN_extended(FCN):\n",
    "    def __init__(self, N_INPUT, hidden_layers, N_OUTPUT, activation='Tanh', initialization='Xavier', original_model_path=None):\n",
    "        super().__init__(N_INPUT, hidden_layers, N_OUTPUT, activation, initialization)\n",
    "    \n",
    "        self.original_model_path = original_model_path\n",
    "        self.original_state_dict = self.load_original_state_dict()\n",
    "        self.original_state_dict_keys = list(self.original_state_dict.keys()) \n",
    "        self.original_hidden_layers_neurons = self.original_state_dict[self.original_state_dict_keys[-4]].size(0)\n",
    "        self.original_hidden_layers_keys = [key for key in self.original_state_dict_keys if \"fch\" in key and \"weight\" in key]\n",
    "        self.original_hidden_layers_num = len(set([key.split('.')[-1] for key in self.original_hidden_layers_keys]))\n",
    "\n",
    "        self.extended_neurons = hidden_layers[-1] # assuming that all hidden layers have the same number of neurons\n",
    "        #print(self.original_state_dict_keys)\n",
    "        #print(self.original_hidden_layers_keys)\n",
    "        #print(len(hidden_layers))\n",
    "        #print(self.original_hidden_layers_num)\n",
    "        # len(set([key.split('.')[1] for key in hidden_layers_keys]))\n",
    "        \n",
    "        # Check if hidden layers need to be extended\n",
    "        if len(hidden_layers) < self.original_hidden_layers_num: \n",
    "            raise ValueError(f\"The number of hidden layers of the extended model({len(hidden_layers)}) must be larger as from the original model({self.original_hidden_layers_num})\")\n",
    "        elif len(hidden_layers) > self.original_hidden_layers_num:\n",
    "            self.extend_hidden_layers()\n",
    "        else:\n",
    "            self.extend_neurons() \n",
    "            \n",
    "    def load_original_state_dict(self):\n",
    "        if self.original_model_path is None:\n",
    "            raise ValueError(\"Path to the original model checkpoint is not provided.\")\n",
    "\n",
    "        if not os.path.exists(self.original_model_path):\n",
    "            raise FileNotFoundError(f\"Provided path '{self.original_model_path}' does not exist.\")\n",
    "\n",
    "        if not os.path.isfile(self.original_model_path):\n",
    "            raise ValueError(f\"Provided path '{self.original_model_path}' is not a file.\")\n",
    "\n",
    "        _, ext = os.path.splitext(self.original_model_path)\n",
    "        if ext not in ['.pt', '.pth']:\n",
    "            raise ValueError(\"Provided file is not a valid checkpoint file.\")\n",
    "        \n",
    "        # Load weights and biases from original_model\n",
    "        return torch.load(self.original_model_path)['model_state_dict']\n",
    "\n",
    "    def extend_hidden_layers(self):        \n",
    "        # Update extended model state dictionary with original model's parameters\n",
    "        self.load_state_dict(self.original_state_dict, strict=False)\n",
    "        \n",
    "        # Transfer weights and biases from original model to extended model\n",
    "        for name, param in self.named_parameters():\n",
    "            if name in self.original_state_dict:\n",
    "                param.data.copy_(self.original_state_dict[name].data)\n",
    "\n",
    "    def extend_hidden_layers_old(self, num_hidden_layers):\n",
    "        current_hidden_layers = len(self.fch)\n",
    "        if current_hidden_layers > num_hidden_layers:\n",
    "            raise ValueError(\"Cannot reduce the number of hidden layers.\")\n",
    "\n",
    "        for _ in range(num_hidden_layers - current_hidden_layers):\n",
    "            new_layer = nn.Sequential(\n",
    "                nn.Linear(self.hidden_layers[-1], self.hidden_layers[-1]),\n",
    "                self.activation)\n",
    "\n",
    "            self.fch.append(new_layer)\n",
    "\n",
    "    def extend_neurons(self):\n",
    "        if len(self.fch) == 0:\n",
    "            raise ValueError(\"Cannot extend neurons with no hidden layers.\")\n",
    "\n",
    "        for ((name, param)) in zip(self.named_parameters(), self.original_state_dict.items()):\n",
    "            print(f\"Current model - {name}: shape {param.shape}\")\n",
    "            print(f\"Old model - {name}: shape {param.shape}\")\n",
    "        # for  ((),())layer_extended, layer_original in zip(self.fch, :\n",
    "        #     #original_neurons = layer[0].weight.size(0)\n",
    "        #     #print(f\"Original_neurons: {original_neurons}\")\n",
    "        #     #print(f\"Original neurons in layer {layer[0]} extend_neurons: {original_neurons}\")\n",
    "        #     if self.original_hidden_layers_neurons < self.extended_neurons:\n",
    "        #         # self.initialize_parameters(self.initialization)\n",
    "        #         # # Extend weights using the provided initialization\n",
    "        #         # init_fn = getattr(init, self.initialization)      # getattr( use to access dynamically the attributes or methods of an object based on a string name )\n",
    "        #         # new_weights = init_fn(layer[0].weight.new_empty(self.extended_neurons - self.original_neurons_hidden_layers, self.original_neurons_hidden_layers))\n",
    "        #         # new_biases = init.constant_(layer[0].bias.new_empty(self.extended_neurons - self.original_neurons_hidden_layers), 0)\n",
    "        #         # layer[0].weight.data = torch.cat([layer[0].weight.data, new_weights], dim=0)\n",
    "        #         # layer[0].bias.data = torch.cat([layer[0].bias.data, new_biases], dim=0)\n",
    "        #         # Initialize new weights for additional neurons\n",
    "        #         #print(self.fch.keys())\n",
    "        #         print(layer[0].weight)\n",
    "        #         new_weights = torch.cat([layer[0].weight, layer[0].weight.data.new_empty(self.extended_neurons - self.original_hidden_layers_neurons, self.original_hidden_layers_neurons)], dim=0)\n",
    "\n",
    "        #         #new_weights = torch.cat([layer[0].weight.data, layer[0].weight.data.new_empty(self.extended_neurons - self.original_hidden_layers_neurons, self.original_hidden_layers_neurons)], dim=0)\n",
    "        #         #new_biases = torch.cat([layer[0].bias.data, layer[0].bias.data.new_empty(self.extended_neurons - self.original_hidden_layers_neurons)], dim=0)\n",
    "        #         # Update the layer's weights and biases\n",
    "        #         #layer[0].weight.data = new_weights\n",
    "        #         #layer[0].bias.data = new_biases\n",
    "        #     else:\n",
    "        #         raise ValueError(\"Maintaining or reducing the number of neurons is not allowed\")\n",
    "class TrainModel:\n",
    "    def __init__(self, model, num_epochs, save_interval, loss_threshold=None):\n",
    "        self.model = model\n",
    "        self.num_epochs = num_epochs\n",
    "        self.save_interval = save_interval\n",
    "        self.loss_threshold = loss_threshold\n",
    "\n",
    "    def train(self):\n",
    "        optimizer = optim.Adam(self.model.parameters())\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            # Train the model\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = self.model(torch.randn(10, original_input_size))\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, torch.randn(10, original_output_size))\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save model checkpoint\n",
    "            if epoch % self.save_interval == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss\n",
    "                }, f\"original_model_{epoch}.pt\")\n",
    "\n",
    "            # Check loss threshold\n",
    "            if self.loss_threshold is not None and loss.item() < self.loss_threshold:\n",
    "                print(f\"Loss threshold reached at epoch {epoch}. Stopping training.\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f4a1f-37a5-46d1-b12b-2233732a84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "original = torch.rand(1,4)\n",
    "original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da63d95c-c6ff-443c-a9b7-3c6003a7f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended = torch.rand(1,8)\n",
    "extended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f1de9-af25-4b06-a82c-61cd2797082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3980874-a0ff-4079-bd3b-401c008a00b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1231f15-a408-452d-80a5-0ac3e7ef8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended[0,:original.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a58676-45ec-4166-b315-f15e6cbfe28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended[0,:original.size(1)].copy_(original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315ff37-edf2-480c-8a30-08836a987862",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"a\", \"b\",\"c\"]\n",
    "test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96087aa4-a0d0-4faf-bf44-96ed65345ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param.data[:old_param.size(0),:].copy_(old_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333639d-b2e5-4de7-90d3-3ce68e0242ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT = 2, hidden_layers = [4], N_OUTPUT = 1, activation='Tanh', initialization='Xavier'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_functions = nn.ModuleDict([\n",
    "            [\"Tanh\", nn.Tanh()],\n",
    "            [\"ReLU\", nn.ReLU()],\n",
    "            [\"LeakyReLU\", nn.LeakyReLU()],\n",
    "            [\"Sigmoid\", nn.Sigmoid()],\n",
    "            [\"Softmax\", nn.Softmax(dim=-1)],\n",
    "        ])\n",
    "\n",
    "        if activation not in self.activation_functions:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.activation = self.activation_functions[activation]\n",
    "\n",
    "        # self.fci = nn.Linear(N_INPUT, hidden_layers[0])\n",
    "\n",
    "        # self.fch = nn.ModuleList([\n",
    "        #     nn.Sequential(\n",
    "        #         nn.Linear(hidden_layers[i], hidden_size),\n",
    "        #         self.activation\n",
    "        #     ) for i, hidden_size in enumerate(hidden_layers[1:])    # ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        # ])\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(N_INPUT if i == 0 else hidden_size, hidden_size),\n",
    "                self.activation\n",
    "            ) for i, hidden_size in enumerate(hidden_layers[:])    # ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        ])\n",
    "\n",
    "        self.fco = nn.Linear(hidden_layers[-1], N_OUTPUT)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.activation(self.fci(x))\n",
    "        for layer in self.fch:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "    def initialize_parameters(self, initialization):\n",
    "        \n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if initialization == 'Uniform':\n",
    "                    init.uniform_(module.weight.data, -0.1, 0.1)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Normal':\n",
    "                    init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Xavier':\n",
    "                    init.xavier_uniform_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'He':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Orthogonal':\n",
    "                    init.orthogonal_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Kaiming':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported initialization type\")\n",
    "    \n",
    "    def plot_weights(self, figsize = (10,5)):\n",
    "        \n",
    "        self.figsize = figsize\n",
    "        \n",
    "        weights_biases_dict = self.state_dict()\n",
    "        #weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Definition of columns, rows and subplots\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols - 1) // num_cols  \n",
    "        \n",
    "        # For colorbar (collect minimum and maximum values across all tensors)\n",
    "        all_values = np.concatenate([tensor.flatten() for tensor in weights_biases_dict.values()])\n",
    "        min_val = round(all_values.min(), 2)\n",
    "        max_val = round(all_values.max(), 2)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize = self.figsize)\n",
    "        \n",
    "        # Plot images and add values in each subplot\n",
    "        for i, (key, tensor) in enumerate(weights_biases_dict.items()):\n",
    "            row = i // num_cols\n",
    "            col = i % num_cols\n",
    "            ax = axs[row, col]\n",
    "            if 'weight' in key:\n",
    "                im = ax.imshow(tensor, cmap='viridis',vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            elif 'bias' in key:\n",
    "                im = ax.imshow(tensor.unsqueeze(0), cmap='viridis', vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            #ax.axis('off')\n",
    "            \n",
    "            # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "            if len(tensor.shape) == 1:\n",
    "                tensor = tensor.reshape(1, -1)\n",
    "\n",
    "            # Add xticks and yticks\n",
    "            ax.set_xticks(np.arange(0, tensor.shape[1] , step=1))  \n",
    "            ax.tick_params(axis='x', labelsize = 8)\n",
    "            ax.set_yticks(np.arange(0, tensor.shape[0] , step=1))\n",
    "            ax.tick_params(axis='y', labelsize = 8)\n",
    "\n",
    "           \n",
    "            # Add values in the middle of the cell\n",
    "            for y in range(tensor.shape[0]):\n",
    "                for x in range(tensor.shape[1]):\n",
    "                    value = tensor[y, x]\n",
    "                    ax.text(x, y, f'{value:.2f}', fontsize = 8, color='white', ha='center', va='center')\n",
    "            \n",
    "         # Hide extra subplots\n",
    "        for i in range(num_subplots, num_rows * num_cols):\n",
    "            axs.flatten()[i].axis('off')\n",
    "            \n",
    "        # Add a title to the figure\n",
    "        plt.suptitle('Weights and Biases of the Neural Network')\n",
    "        \n",
    "        # Add a colorbar\n",
    "            # Set custom ticks and intervals\n",
    "        tick_interval = 0.2\n",
    "        ticks = np.arange(min_val, max_val, step=tick_interval)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.01])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', ticks = ticks)\n",
    "        cbar.set_label('Range of Weights and Biases') \n",
    "        \n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "class FCN_extended(FCN):\n",
    "    def __init__(self, N_INPUT, hidden_layers, N_OUTPUT, activation='Tanh', initialization='Xavier', original_model_path=None):\n",
    "        super().__init__(N_INPUT, hidden_layers, N_OUTPUT, activation, initialization)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "        \n",
    "        self.original_model_path = original_model_path\n",
    "        self.original_state_dict = self.load_original_state_dict()\n",
    "        self.original_state_dict_keys = list(self.original_state_dict.keys()) \n",
    "        self.original_hidden_layers_neurons = self.original_state_dict[self.original_state_dict_keys[-4]].size(0)\n",
    "        self.original_hidden_layers_keys = [key for key in self.original_state_dict_keys if \"fch\" in key and \"weight\" in key]\n",
    "        self.original_hidden_layers_num = len(set([key.split('.')[-1] for key in self.original_hidden_layers_keys]))\n",
    "\n",
    "        #self.extended_neurons = hidden_layers[-1] # assuming that all hidden layers have the same number of neurons\n",
    "\n",
    "        self.copy_and_initialize_parameters()\n",
    "        \n",
    "        # # Check if hidden layers need to be extended\n",
    "        # if len(hidden_layers) < self.original_hidden_layers_num: \n",
    "        #     raise ValueError(f\"The number of hidden layers of the extended model({len(hidden_layers)}) must be larger as from the original model({self.original_hidden_layers_num})\")\n",
    "        # elif len(hidden_layers) > self.original_hidden_layers_num:\n",
    "        #     self.extend_hidden_layers()\n",
    "        # else:\n",
    "        #     self.extend_neurons() \n",
    "\n",
    "\n",
    "    def copy_and_initialize_parameters(self):\n",
    "        #current_model.initialize_parameters(initialization)  # Initialize current model first\n",
    "        for name, param in self.named_parameters():\n",
    "            print(\"next iteration\")\n",
    "            if name in self.original_state_dict:\n",
    "                print(name)\n",
    "                old_param = self.original_state_dict[name]\n",
    "                if param.shape == old_param.shape:\n",
    "                    print(\"same shape\")\n",
    "                    param.data.copy_(old_param)                    \n",
    "                else:\n",
    "                    if \"weight\" in name: \n",
    "                        if param.shape != old_param.shape:  # Mismatch in dimension 0: increasing neurons\n",
    "                            # Copy matching portion of old weights\n",
    "                            print(f\"weight in name and different size(0)\")\n",
    "                            print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                            \n",
    "                            param.data[:old_param.size(0), :old_param.size(1)].copy_(old_param)\n",
    "                        elif param.size(0) != old_param.size(0):  # Mismatch in dimension 0: increasing neurons\n",
    "                            # Copy matching portion of old weights\n",
    "                            print(f\"weight in name and different size(0)\")\n",
    "                            print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                            \n",
    "                            param.data[:old_param.size(0), :].copy_(old_param)                           \n",
    "                        elif param.size(0) != old_param.size(0) and \"fc0\" in name:\n",
    "                            print(f\"weight in name BUT equal size(0)\")\n",
    "                            print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                            \n",
    "                            param.data[0,:old_param.size(1)].copy_(old_param[0]) \n",
    "               \n",
    "                    if \"bias\" in name: \n",
    "                        print(\"bias in name\")\n",
    "                        if param.size(0) != old_param.size(0):  # Mismatch in dimension 0: increasing neurons\n",
    "                            print(f\"bias in name and different size(0)\")\n",
    "                            print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                            # Copy matching portion of old weights\n",
    "\n",
    "                            param.data[old_param.size(0):].copy_(old_param)\n",
    "                        else:\n",
    "                            print(f\"bias in name BUT equal size(0)\")\n",
    "                            print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "\n",
    "                            param.data.copy_(old_param)\n",
    "\n",
    "            print(\"end iteration\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # for name, param in self.named_parameters():\n",
    "        #     print(\"next iteration\")\n",
    "        #     if name in self.original_state_dict:\n",
    "        #         print(name)\n",
    "        #         old_param = self.original_state_dict[name]\n",
    "        #         if param.shape == old_param.shape:\n",
    "        #             print(\"same shape\")\n",
    "        #             param.data.copy_(old_param)                    \n",
    "        #         else:\n",
    "        #             print(\"different shape\")\n",
    "        #             print(name)\n",
    "        #             if \"weight\" in name: \n",
    "        #                 if param.size(0) != old_param.size(0):  # Mismatch in dimension 0: increasing neurons\n",
    "        #                     # Copy matching portion of old weights\n",
    "        #                     print(f\"weight in name and different size(0)\")\n",
    "        #                     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                            \n",
    "        #                     param.data[:old_param.size(0), :].copy_(old_param)\n",
    "        #                 else:\n",
    "        #                     print(f\"weight in name BUT equal size(0)\")\n",
    "        #                     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                            \n",
    "        #                     param.data[0,:old_param.size(1)].copy_(old_param[0])\n",
    "        #             if \"bias\" in name: \n",
    "        #                 print(\"bias in name\")\n",
    "        #                 if param.size(0) != old_param.size(0):  # Mismatch in dimension 0: increasing neurons\n",
    "        #                     print(f\"bias in name and different size(0)\")\n",
    "        #                     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "        #                     # Copy matching portion of old weights\n",
    "\n",
    "        #                     param.data[old_param.size(0):].copy_(old_param)\n",
    "        #                 else:\n",
    "        #                     print(f\"bias in name BUT equal size(0)\")\n",
    "        #                     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "\n",
    "        #                     param.data.copy_(old_param)\n",
    "\n",
    "        #     print(\"end iteration\")\n",
    "\n",
    "                    \n",
    "                    # if param.size(0) != old_param.size(0) and \"weight\" in name:  # Mismatch in dimension 0: increasing neurons\n",
    "                    #     # Copy matching portion of old weights\n",
    "                    #     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                    #     param.data[:old_param.size(0), :].copy_(old_param)\n",
    "                    # if param.size(0) != old_param.size(0) and \"bias\" in name:  # Mismatch in dimension 0: increasing neurons\n",
    "                    #     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                    #     # Copy matching portion of old weights\n",
    "                    #     param.data[:old_param.size(0)].copy_(old_param)\n",
    "                    #     # The rest of the weight tensor has been initialized by initialize_parameters\n",
    "                    # if param.size(1) != old_param.size(1):\n",
    "                    #     param.data[:, :old_param.size(1)].copy_(old_param)\n",
    "                    #     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                    # print(\"end iteration\")                    \n",
    "                    # if param.size(0) != old_param.size(0):# in \"weight\" in name:  # Mismatch in dimension 0: increasing neurons\n",
    "                    #     # Copy matching portion of old weights\n",
    "                    #     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                    #     param.data[:old_param.size(0):, :].copy_(old_param)\n",
    "                    # # if param.size(0) != old_param.size(0) in \"bias\" in name:  # Mismatch in dimension 0: increasing neurons\n",
    "                    # #     # Copy matching portion of old weights\n",
    "                    # #     param.data[:old_param.size(0):, :].copy_(old_param)\n",
    "                    #     # The rest of the weight tensor has been initialized by initialize_parameters\n",
    "                    # if param.size(1) != old_param.size(1):\n",
    "                    #     param.data[:, :old_param.size(1)].copy_(old_param)\n",
    "\n",
    "\n",
    "            \n",
    "            #: and 'weight' in name:  # Check for matching weight parameters\n",
    "            # if name in self.original_state_dict and 'weight' in name:  # Check for matching weight parameters\n",
    "            #     old_param_weights = self.original_state_dict[name]\n",
    "            #     if param.size(0) != old_param_weights.size(0):  # Mismatch in dimension 0 for weights\n",
    "            #         # Copy matching portion of old weights\n",
    "            #         param.data[:old_param_weights.size(0)].copy_(old_param_weights)\n",
    "            #         # The rest of the weight tensor has been initialized by initialize_parameters\n",
    "            #     else:\n",
    "            #         # Direct copy if sizes match\n",
    "            #         print(param.shape)\n",
    "            #         param.data.copy_(old_param_weights)\n",
    "            # elif name in self.original_state_dict and 'bias' in name:  # Directly copy biases if present\n",
    "            #     old_param_biases = self.original_state_dict[name]\n",
    "            #     if param.size(0) != old_param_biases.size(0):  # Mismatch in dimension 1 for biases\n",
    "            #         # Copy matching portion of old biases\n",
    "            #         param.data[:old_param_biases.size(0)].copy_(old_param_biases)\n",
    "            #         # The rest of the biases tensor has been initialized by initialize_parameters\n",
    "            #     else:\n",
    "            #         # Direct copy if sizes match\n",
    "            #         param.data.copy_(old_param_biases)\n",
    "\n",
    "    \n",
    "    def load_original_state_dict(self):\n",
    "        if self.original_model_path is None:\n",
    "            raise ValueError(\"Path to the original model checkpoint is not provided.\")\n",
    "\n",
    "        if not os.path.exists(self.original_model_path):\n",
    "            raise FileNotFoundError(f\"Provided path '{self.original_model_path}' does not exist.\")\n",
    "\n",
    "        if not os.path.isfile(self.original_model_path):\n",
    "            raise ValueError(f\"Provided path '{self.original_model_path}' is not a file.\")\n",
    "\n",
    "        _, ext = os.path.splitext(self.original_model_path)\n",
    "        if ext not in ['.pt', '.pth']:\n",
    "            raise ValueError(\"Provided file is not a valid checkpoint file.\")\n",
    "        \n",
    "        # Load weights and biases from original_model\n",
    "        return torch.load(self.original_model_path)['model_state_dict']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TrainModel:\n",
    "    def __init__(self, model, num_epochs, save_interval, loss_threshold=None):\n",
    "        self.model = model\n",
    "        self.num_epochs = num_epochs\n",
    "        self.save_interval = save_interval\n",
    "        self.loss_threshold = loss_threshold\n",
    "\n",
    "    def train(self):\n",
    "        optimizer = optim.Adam(self.model.parameters())\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            # Train the model\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = self.model(torch.randn(10, original_input_size))\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, torch.randn(10, original_output_size))\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save model checkpoint\n",
    "            if epoch % self.save_interval == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss\n",
    "                }, f\"original_model_{epoch}.pt\")\n",
    "\n",
    "            # Check loss threshold\n",
    "            if self.loss_threshold is not None and loss.item() < self.loss_threshold:\n",
    "                print(f\"Loss threshold reached at epoch {epoch}. Stopping training.\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6b963-09d3-434c-ba2e-0c499a33fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "original_input_size = 2\n",
    "original_hidden_layers = [4]\n",
    "original_output_size = 1\n",
    "original_model = FCN(original_input_size, original_hidden_layers, original_output_size, activation='Tanh', initialization='Xavier')\n",
    "original_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0b50b-6b6f-4f7b-b96a-3bc3e43e870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.plot_weights(figsize = (10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751f596-47d2-4ebe-8ec2-cb901dfd504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train original model\n",
    "train_model = TrainModel(original_model, num_epochs=1000, save_interval=100, loss_threshold=0.01)\n",
    "train_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5921546-fb93-4c09-9d9c-3aa45df3ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c8c86-fa7c-4476-8e76-23e276bbd7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240abfb4-05d3-4b28-b178-5a3c17873450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extended model\n",
    "extended_input_size = 2\n",
    "extended_hidden_layers = [4,4]\n",
    "extended_output_size = 1\n",
    "extended_model = FCN_extended(extended_input_size, extended_hidden_layers, extended_output_size, activation='Tanh', initialization='Xavier', original_model_path='original_model_1000.pt')\n",
    "extended_model.plot_weights((15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f8bc5-00e3-4e5b-9244-bcac35bf0451",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7167143a-60e7-4c69-8859-8377d133b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train original model\n",
    "train_extended_model = TrainModel(extended_model, num_epochs=1000, save_interval=100, loss_threshold=0.01)\n",
    "train_extended_model.train()\n",
    "extended_model.plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2fe25b-8eb9-4f7c-9e4e-991b3a2aea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original model state and override weights\n",
    "#extended_model.load_override_original_weights_biases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4995617-0e1b-4ae9-a911-72912a7ac308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend neurons in hidden layers\n",
    "#extended_model.extend_neurons(num_neurons=8)\n",
    "#extended_model.plot_weights((15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac7a3c-c2b5-432a-ad3d-24eab392d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extended model\n",
    "extended1_input_size = 2\n",
    "extended1_hidden_layers = [8,8]\n",
    "extended1_output_size = 1\n",
    "extended1_model = FCN_extended(extended1_input_size, extended1_hidden_layers, extended1_output_size, activation='Tanh', initialization='Xavier', original_model_path='original_model_1000.pt')\n",
    "extended1_model.plot_weights((15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542a78f-a754-4d56-a056-c71cca91ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train original model\n",
    "train_extended1_model = TrainModel(extended1_model, num_epochs=1000, save_interval=100, loss_threshold=0.01)\n",
    "train_extended1_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397acfc9-67c9-4c0f-889b-625b198c1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended1_model.plot_weights(figsize = (15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5930132-a188-48ad-a309-5f9c668b07ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extended model\n",
    "extended2_input_size = 2\n",
    "extended2_hidden_layers = [16,16,16,16]\n",
    "extended2_output_size = 1\n",
    "extended2_model = FCN_extended(extended2_input_size, extended2_hidden_layers, extended2_output_size, activation='Tanh', initialization='Xavier', original_model_path='original_model_1000.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b1c04-3b6a-4dea-b5d9-f1928e4757c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended2_model.plot_weights((40,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cb00b-5f6f-4300-b4f0-d26366e124d5",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f9582-03b1-457e-86eb-f2af1f18069e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ad520-0a86-4253-982d-9b861eaf85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_model.fch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b61696-2035-483f-bfb8-34d0f1a45b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if fch is not empty\n",
    "if original_model.fch:\n",
    "    # Print the length of fch\n",
    "    print(\"Number of modules in fch:\", len(original_model.fch))\n",
    "    \n",
    "    # Loop through each module in fch\n",
    "    for i, module in enumerate(original_model.fch):\n",
    "        print(f\"Module {i}:\")\n",
    "        # Check if the module is not empty\n",
    "        if module:\n",
    "            # Print the number of layers in the module\n",
    "            print(\"  Number of layers:\", len(module))\n",
    "        else:\n",
    "            print(\"  Empty module\")\n",
    "else:\n",
    "    print(\"fch is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf8f82-4cc4-4c8a-bb09-bfdc7100a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUT= 2\n",
    "hidden_layers = [4,4]\n",
    "for i , hidden_size in enumerate(hidden_layers[:]):\n",
    "    print(f\"nn.Linear(n: {i}, size: {hidden_size}, lenght of hidden_layers: {len(hidden_layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e9c04-312f-4700-b782-53a85f34af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUT = 2\n",
    "hidden_layers = [4,4]\n",
    "for i, hidden_size in enumerate(hidden_layers[:]):\n",
    "    input_size = N_INPUT if i == 0 else hidden_size\n",
    "    output_size = hidden_size\n",
    "    print( f\" nn.Linear({input_size}, {output_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741ff7b-4a91-42b8-bbcd-898ad134c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_size if i == 0 else hidden_sizes[i-1], hidden_size),\n",
    "                nn.ReLU()\n",
    "            ) for i, hidden_size in enumerate(hidden_sizes)\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "# Example usage\n",
    "input_size = 2\n",
    "hidden_sizes = [4,4]\n",
    "output_size = 1\n",
    "\n",
    "model = SimpleModel(input_size, hidden_sizes, output_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2d230-2413-4c0e-8ff4-68be701e1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f1d9b-315a-425b-b4e0-3079be875793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state_dict without initializing the model first\n",
    "#loaded_state_dict = torch.load('simple_model_state_dict.pth')\n",
    "\n",
    "# Infer the length of hidden layers\n",
    "# Keys will be in the format of 'hidden_layers.0.0.weight', 'hidden_layers.1.0.weight', etc.\n",
    "hidden_layers_keys = [key for key in model.state_dict().keys() if 'hidden_layers' in key and  'weight' in key]\n",
    "hidden_layers_count = len(set([key.split('.')[1] for key in hidden_layers_keys]))\n",
    "#hidden_layers_count = set([key.split('.')[-1] for key in hidden_layers_keys])\n",
    "\n",
    "#hidden_layers_count = [key.split('.')[1] for key in hidden_layers_keys]\n",
    "\n",
    "print(f\"Length of hidden layers: {hidden_layers_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224f3cf-9e02-458d-9eb1-3e59d52a54eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hidden_layers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1eafdf-961c-48b6-9f4e-f26a51b2bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e7240-2fa6-4da9-ab7d-5e63a291bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_keys = list(state_dict.keys())\n",
    "layer_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1bf50e-aa33-48c7-a709-0a9a2ba33e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_keys[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ecfed-86bb-4a58-9dc0-7b1b70f3079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict[layer_keys[-4]].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab3513-a727-4814-a0cd-92dde60e9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "visitor_ids = ['123', '356', '123', '501', '356', '123', '501', '789', '356']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec4334-930a-4c7e-be98-0b27e9657893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of visitor IDs to a set to remove duplicates\n",
    "unique_visitors = set(visitor_ids)\n",
    "\n",
    "# Now, unique_visitors contains only unique IDs\n",
    "print(f\"Unique visitor IDs: {unique_visitors}\")\n",
    "\n",
    "# The number of unique visitors\n",
    "print(f\"Number of unique visitors: {len(unique_visitors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57eb37a-779b-4b31-8e1f-b51de0bb2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the neural network architecture\n",
    "class MyNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 4),  # Input layer to hidden layer\n",
    "            nn.Sigmoid(),     # Apply activation function (e.g., sigmoid)\n",
    "            nn.Linear(4, 1)   # Hidden layer to output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instantiate the neural network model\n",
    "model = MyNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6e318-598a-43ef-8ad7-ecfcf0114b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa47b4-c8f5-449a-ad42-cc222af59c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the state dictionary of the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "import numpy \n",
    "# Access the weights and biases\n",
    "weights_hidden = state_dict['model.0.weight'].numpy()\n",
    "biases_hidden = state_dict['model.0.bias'].numpy()\n",
    "weights_output = state_dict['model.1.weight'].numpy()\n",
    "biases_output = state_dict['model.1.bias'].numpy()\n",
    "\n",
    "# Print weights and biases\n",
    "print(\"Weights of Hidden Layer:\")\n",
    "print(weights_hidden)\n",
    "print(\"\\nBiases of Hidden Layer:\")\n",
    "print(biases_hidden)\n",
    "print(\"\\nWeights of Output Layer:\")\n",
    "print(weights_output)\n",
    "print(\"\\nBiases of Output Layer:\")\n",
    "print(biases_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba2e6af-df2c-4dd6-8f88-a89352f975c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d256c5-56c5-4196-a2c8-cdc39d0ddb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FlexibleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(FlexibleNN, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        # Input layer to first hidden layer\n",
    "        layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        layers.append(nn.Tanh())\n",
    "\n",
    "        # Adding variable number of hidden layers\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            layers.append(nn.Tanh())\n",
    "\n",
    "        # Adding the final output layer\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_size = 2  # Input features\n",
    "hidden_sizes = [4, 3, 2]  # Sizes of hidden layers\n",
    "output_size = 1  # Output features\n",
    "\n",
    "# Create an instance of the network with the specified architecture\n",
    "net = FlexibleNN(input_size, hidden_sizes, output_size)\n",
    "\n",
    "# Example input\n",
    "example_input = torch.rand(1, input_size)\n",
    "\n",
    "# Forward pass through the network\n",
    "output = net(example_input)\n",
    "\n",
    "print(\"Output:\", output)\n",
    "\n",
    "# Displaying the weights and biases\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fcba57-f254-48dc-8a21-b6ad68683f58",
   "metadata": {},
   "source": [
    "# Variance of the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec76e7a-8605-46cd-b761-8a3ad38fcd51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe418c5-24ba-47da-a5ba-55fb88b9ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.init as init\n",
    "\n",
    "# Function to initialize tensors and calculate variance\n",
    "def initialize_and_calculate_variance(initialization_fn):\n",
    "    # Initialize tensor\n",
    "    tensor = torch.empty(8, 2)\n",
    "    initialization_fn(tensor)\n",
    "\n",
    "    # Calculate variance of the tensor\n",
    "    variance = torch.var(tensor)\n",
    "\n",
    "    return tensor, variance.item()\n",
    "\n",
    "# Function to trim tensors and calculate variance\n",
    "def trim_and_calculate_variance(tensor):\n",
    "    # Trim tensor to last 4 rows\n",
    "    trimmed_tensor = tensor[-4:, :]\n",
    "\n",
    "    # Calculate variance of the trimmed tensor\n",
    "    variance = torch.var(trimmed_tensor)\n",
    "\n",
    "    return trimmed_tensor, variance.item()\n",
    "\n",
    "# List of initialization methods\n",
    "initialization_methods = [\n",
    "    init.uniform_,\n",
    "    init.normal_,\n",
    "    init.xavier_uniform_,\n",
    "    init.orthogonal_,\n",
    "    init.kaiming_uniform_\n",
    "]\n",
    "\n",
    "# Initialize and calculate variance for each method\n",
    "initial_tensors = []\n",
    "initial_variances = []\n",
    "trimmed_tensors = []\n",
    "trimmed_variances = []\n",
    "\n",
    "for initialization_method in initialization_methods:\n",
    "    # Initialize tensor and calculate variance\n",
    "    tensor, variance = initialize_and_calculate_variance(initialization_method)\n",
    "    initial_tensors.append(tensor)\n",
    "    initial_variances.append(variance)\n",
    "\n",
    "    # Trim tensor and calculate variance\n",
    "    trimmed_tensor, trimmed_variance = trim_and_calculate_variance(tensor)\n",
    "    trimmed_tensors.append(trimmed_tensor)\n",
    "    trimmed_variances.append(trimmed_variance)\n",
    "\n",
    "# Print initial variances\n",
    "print(\"Initial variances:\")\n",
    "for method, variance in zip(initialization_methods, initial_variances):\n",
    "    print(f\"{method.__name__}: {variance:.4f}\")\n",
    "\n",
    "# Print trimmed variances\n",
    "print(\"\\nTrimmed variances:\")\n",
    "for method, variance in zip(initialization_methods, trimmed_variances):\n",
    "    print(f\"{method.__name__}: {variance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c11b6-48ee-4352-84a2-1533f7d8e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "# Function to initialize tensors and calculate variance\n",
    "def initialize_and_calculate_variance(initialization_fn):\n",
    "    # Initialize tensor\n",
    "    tensor = torch.empty(8, 2)\n",
    "    initialization_fn(tensor)\n",
    "\n",
    "    # Apply Tanh activation function\n",
    "    tensor = F.tanh(tensor)\n",
    "\n",
    "    # Calculate variance of the tensor\n",
    "    variance = torch.var(tensor)\n",
    "\n",
    "    return tensor, variance.item()\n",
    "\n",
    "# Function to trim tensors and calculate variance\n",
    "def trim_and_calculate_variance(tensor):\n",
    "    # Trim tensor to last 4 rows\n",
    "    trimmed_tensor = tensor[-4:, :]\n",
    "\n",
    "    # Calculate variance of the trimmed tensor\n",
    "    variance = torch.var(trimmed_tensor)\n",
    "\n",
    "    return trimmed_tensor, variance.item()\n",
    "\n",
    "# List of initialization methods\n",
    "initialization_methods = [\n",
    "    init.uniform_,\n",
    "    init.normal_,\n",
    "    init.xavier_uniform_,\n",
    "    init.orthogonal_,\n",
    "    init.kaiming_uniform_\n",
    "]\n",
    "\n",
    "# Initialize and calculate variance for each method\n",
    "initial_tensors = []\n",
    "initial_variances = []\n",
    "trimmed_tensors = []\n",
    "trimmed_variances = []\n",
    "\n",
    "for initialization_method in initialization_methods:\n",
    "    # Initialize tensor and calculate variance\n",
    "    tensor, variance = initialize_and_calculate_variance(initialization_method)\n",
    "    initial_tensors.append(tensor)\n",
    "    initial_variances.append(variance)\n",
    "\n",
    "    # Trim tensor and calculate variance\n",
    "    trimmed_tensor, trimmed_variance = trim_and_calculate_variance(tensor)\n",
    "    trimmed_tensors.append(trimmed_tensor)\n",
    "    trimmed_variances.append(trimmed_variance)\n",
    "\n",
    "# Print initial variances\n",
    "print(\"Initial variances (with Tanh activation):\")\n",
    "for method, variance in zip(initialization_methods, initial_variances):\n",
    "    print(f\"{method.__name__}: {variance:.4f}\")\n",
    "\n",
    "# Print trimmed variances\n",
    "print(\"\\nTrimmed variances (with Tanh activation):\")\n",
    "for method, variance in zip(initialization_methods, trimmed_variances):\n",
    "    print(f\"{method.__name__}: {variance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82d527-e46c-45a7-8620-217cf1958c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i % 2 == 0:\n",
    "        continue  # Skip even numbers\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80eb7999-05ab-476d-a148-58cb299ecd4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T20:59:06.097861Z",
     "iopub.status.busy": "2024-02-26T20:59:06.097475Z",
     "iopub.status.idle": "2024-02-26T20:59:07.162298Z",
     "shell.execute_reply": "2024-02-26T20:59:07.160787Z",
     "shell.execute_reply.started": "2024-02-26T20:59:06.097826Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import any of the following Qt binding modules: PyQt5, PySide2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Switch to an interactive backend (e.g., 'qt5')\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mqt5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Your plotting code\u001b[39;00m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2432\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2432\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2436\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m backends_list)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3621\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3617\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWarning: Cannot change to a different GUI toolkit: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3618\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (gui, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select))\n\u001b[1;32m   3619\u001b[0m         gui, backend \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mfind_gui_and_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select)\n\u001b[0;32m-> 3621\u001b[0m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivate_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m configure_inline_support(\u001b[38;5;28mself\u001b[39m, backend)\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;66;03m# Now we must activate the gui pylab wants to use, and fix %run to take\u001b[39;00m\n\u001b[1;32m   3625\u001b[0m \u001b[38;5;66;03m# plot updates into account\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/pylabtools.py:368\u001b[0m, in \u001b[0;36mactivate_matplotlib\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Due to circular imports, pyplot may be only partially initialised\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# when this function runs.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# So avoid needing matplotlib attribute-lookup to access pyplot.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m--> 368\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswitch_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow\u001b[38;5;241m.\u001b[39m_needmain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# We need to detect at runtime whether show() is called by the user.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# For this, we wrap it into a decorator which adds a 'called' flag.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/pyplot.py:342\u001b[0m, in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# have to escape the switch on access logic\u001b[39;00m\n\u001b[1;32m    340\u001b[0m old_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(rcParams, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 342\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_module_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewbackend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m canvas_class \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mFigureCanvas\n\u001b[1;32m    345\u001b[0m required_framework \u001b[38;5;241m=\u001b[39m canvas_class\u001b[38;5;241m.\u001b[39mrequired_interactive_framework\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backends/backend_qt5agg.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backends\n\u001b[1;32m      6\u001b[0m backends\u001b[38;5;241m.\u001b[39m_QT_FORCE_QT5_BINDING \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_qtagg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (    \u001b[38;5;66;03m# noqa: F401, E402 # pylint: disable=W0611\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     _BackendQTAgg, FigureCanvasQTAgg, FigureManagerQT, NavigationToolbar2QT,\n\u001b[1;32m      9\u001b[0m     FigureCanvasAgg, FigureCanvasQT)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;129m@_BackendQTAgg\u001b[39m\u001b[38;5;241m.\u001b[39mexport\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_BackendQT5Agg\u001b[39;00m(_BackendQTAgg):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backends/backend_qtagg.py:9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mctypes\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bbox\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqt_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QT_API, QtCore, QtGui\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_agg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasAgg\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_qt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _BackendQT, FigureCanvasQT\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backends/qt_compat.py:133\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import any of the following Qt binding modules: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m             \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([QT_API \u001b[38;5;28;01mfor\u001b[39;00m _, QT_API \u001b[38;5;129;01min\u001b[39;00m _candidates]))\n\u001b[1;32m    136\u001b[0m         )\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# We should not get there.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected QT_API: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mQT_API\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import any of the following Qt binding modules: PyQt5, PySide2"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Switch to an interactive backend (e.g., 'qt5')\n",
    "%matplotlib qt5\n",
    "\n",
    "# Your plotting code\n",
    "plt.figure()\n",
    "t = np.arange(0.0, 2.0, 0.01)\n",
    "s = 1 + np.sin(2 * np.pi * t)\n",
    "plt.plot(t, s)\n",
    "\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('voltage (mV)')\n",
    "plt.title('About as simple as it gets, folks')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb73b6b-fc6d-4590-acb6-6fd4a069890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cba6e0-a645-412a-b5cc-3b876bf2c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "972daa6c-75c8-44fa-9276-d81273efc6eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T21:00:34.088443Z",
     "iopub.status.busy": "2024-02-26T21:00:34.087988Z",
     "iopub.status.idle": "2024-02-26T21:00:36.625925Z",
     "shell.execute_reply": "2024-02-26T21:00:36.624113Z",
     "shell.execute_reply.started": "2024-02-26T21:00:34.088408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyQt5 in /home/luis/.local/lib/python3.10/site-packages (5.15.10)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.13 in /home/luis/.local/lib/python3.10/site-packages (from PyQt5) (12.13.0)\n",
      "Requirement already satisfied: PyQt5-Qt5>=5.15.2 in /home/luis/.local/lib/python3.10/site-packages (from PyQt5) (5.15.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PySide2 in /home/luis/.local/lib/python3.10/site-packages (5.15.2.1)\n",
      "Requirement already satisfied: shiboken2==5.15.2.1 in /home/luis/.local/lib/python3.10/site-packages (from PySide2) (5.15.2.1)\n"
     ]
    }
   ],
   "source": [
    "# Install PyQt5\n",
    "!pip install PyQt5\n",
    "# or install PySide2\n",
    "!pip install PySide2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7d24d5-4db1-489c-b589-6044f5aa0f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T21:02:35.067960Z",
     "iopub.status.busy": "2024-02-26T21:02:35.067457Z",
     "iopub.status.idle": "2024-02-26T21:02:35.075202Z",
     "shell.execute_reply": "2024-02-26T21:02:35.073941Z",
     "shell.execute_reply.started": "2024-02-26T21:02:35.067921Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb473fe-c2ad-453f-8c1c-55fcd03db383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T21:02:48.620284Z",
     "iopub.status.busy": "2024-02-26T21:02:48.619856Z",
     "iopub.status.idle": "2024-02-26T21:02:48.627486Z",
     "shell.execute_reply": "2024-02-26T21:02:48.625853Z",
     "shell.execute_reply.started": "2024-02-26T21:02:48.620249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b373948-6fde-435a-853e-8926eac3a0f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T21:03:15.978986Z",
     "iopub.status.busy": "2024-02-26T21:03:15.978549Z",
     "iopub.status.idle": "2024-02-26T21:03:16.017099Z",
     "shell.execute_reply": "2024-02-26T21:03:16.015371Z",
     "shell.execute_reply.started": "2024-02-26T21:03:15.978951Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'PyQt5' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPyQt5\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mPyQt5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'PyQt5' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import PyQt5\n",
    "print(PyQt5.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4705b2-51d9-48f1-8ecb-fc53f79c37aa",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb4ed6d1-6921-45ef-8919-4661fa836696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T09:58:46.063744Z",
     "iopub.status.busy": "2024-02-28T09:58:46.063265Z",
     "iopub.status.idle": "2024-02-28T09:58:46.390098Z",
     "shell.execute_reply": "2024-02-28T09:58:46.389546Z",
     "shell.execute_reply.started": "2024-02-28T09:58:46.063705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create some data to display\n",
    "data1 = np.random.rand(10, 10)\n",
    "data2 = np.random.rand(20, 20)\n",
    "\n",
    "# Create a figure with two subplots with different sizes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5),\n",
    "                               gridspec_kw={'width_ratios': [1, 2], 'height_ratios': [1]})\n",
    "\n",
    "# Display data in the first subplot\n",
    "im1 = ax1.imshow(data1)\n",
    "ax1.set_title('Smaller Plot')\n",
    "\n",
    "# Display data in the second subplot, which is larger due to the width_ratios argument\n",
    "im2 = ax2.imshow(data2)\n",
    "ax2.set_title('Larger Plot')\n",
    "\n",
    "# Automatically adjust subplot parameters to give specified padding\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "125b9ca0-d5ec-48a0-a634-5d689d55f809",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T10:09:06.348842Z",
     "iopub.status.busy": "2024-02-28T10:09:06.348349Z",
     "iopub.status.idle": "2024-02-28T10:09:07.754807Z",
     "shell.execute_reply": "2024-02-28T10:09:07.753695Z",
     "shell.execute_reply.started": "2024-02-28T10:09:06.348804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1500 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming state_dict is a dictionary with keys 'layer_x.weights', 'layer_x.biases'\n",
    "# For the sake of example, let's create dummy tensors with the correct shapes\n",
    "state_dict = {\n",
    "    'layer_1.weights': np.random.rand(4, 2),  # From 2 to 4 neurons\n",
    "    'layer_1.biases': np.random.rand(4),\n",
    "    'layer_2.weights': np.random.rand(4, 4),  # From 4 to 4 neurons\n",
    "    'layer_2.biases': np.random.rand(4),\n",
    "    'layer_3.weights': np.random.rand(1, 4),  # From 4 to 1 neuron\n",
    "    'layer_3.biases': np.random.rand(1)\n",
    "}\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10, 15),\n",
    "                         gridspec_kw={'height_ratios': [4, 4, 1]})  # Adjust height ratios based on layer output size\n",
    "\n",
    "for i, layer in enumerate(['layer_1', 'layer_2', 'layer_3']):\n",
    "    weights = state_dict[f'{layer}.weights']\n",
    "    biases = state_dict[f'{layer}.biases']\n",
    "    \n",
    "    # Plot weights matrix\n",
    "    ax = axes[i, 0]\n",
    "    cax = ax.matshow(weights, cmap='viridis')\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "    ax.set_title(f'{layer} Weights')\n",
    "    \n",
    "    # Plot biases vector as a 2D array for consistent visualization\n",
    "    ax = axes[i, 1]\n",
    "    cax = ax.matshow(biases.reshape(-1, 1), cmap='viridis')\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "    ax.set_title(f'{layer} Biases')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f4a35a-568a-419f-9100-bd82f40e58a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
