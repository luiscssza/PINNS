{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c7b585-85ca-4aec-b02a-63c992f545cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:49:07.441742Z",
     "iopub.status.busy": "2024-02-29T13:49:07.441195Z",
     "iopub.status.idle": "2024-02-29T13:49:17.887842Z",
     "shell.execute_reply": "2024-02-29T13:49:17.886542Z",
     "shell.execute_reply.started": "2024-02-29T13:49:07.441698Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the neural network architecture\n",
    "class DampedOscillatorPINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DampedOscillatorPINN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.net(t)\n",
    "\n",
    "# Modified function to compute both loss and residuals\n",
    "def compute_loss_and_residuals(model, t, omega_0, zeta):\n",
    "    t.requires_grad = True\n",
    "    x = model(t)\n",
    "    dx_dt = torch.autograd.grad(x, t, torch.ones_like(x), create_graph=True)[0]\n",
    "    d2x_dt2 = torch.autograd.grad(dx_dt, t, torch.ones_like(dx_dt), create_graph=True)[0]\n",
    "    residuals = d2x_dt2 + 2*zeta*omega_0*dx_dt + omega_0**2*x\n",
    "    loss = torch.mean(residuals**2)\n",
    "    return loss, residuals\n",
    "\n",
    "# Model, optimizer, and training loop setup\n",
    "model = DampedOscillatorPINN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "omega_0 = 1.0  # Natural frequency\n",
    "zeta = 0.1    # Damping ratio\n",
    "\n",
    "# Initialization\n",
    "losses = []\n",
    "epoch_residuals = []\n",
    "\n",
    "# Adjusted training loop\n",
    "for epoch in range(5000):\n",
    "    t = torch.rand(100, 1) * 10  # Generate random time points\n",
    "    loss, residuals = compute_loss_and_residuals(model, t, omega_0, zeta)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:  # Adjust based on your preference for data collection frequency\n",
    "        losses.append(loss.item())\n",
    "        epoch_residuals.append(residuals.mean().item())  # Example: storing mean residual\n",
    "\n",
    "# After training, plot the collected data\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_residuals, label='Mean Residual')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Residual')\n",
    "plt.title('Mean Residual Over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495baa4e-495e-4049-8e3d-bd266f035076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T13:49:22.276852Z",
     "iopub.status.busy": "2024-02-29T13:49:22.276298Z",
     "iopub.status.idle": "2024-02-29T13:49:30.767958Z",
     "shell.execute_reply": "2024-02-29T13:49:30.767057Z",
     "shell.execute_reply.started": "2024-02-29T13:49:22.276813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the neural network architecture\n",
    "class DampedOscillatorPINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DampedOscillatorPINN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.net(t)\n",
    "\n",
    "# Modified function to compute both loss and residuals\n",
    "def compute_loss_and_residuals(model, t, omega_0, zeta):\n",
    "    t.requires_grad = True\n",
    "    x = model(t)\n",
    "    dx_dt = torch.autograd.grad(x, t, torch.ones_like(x), create_graph=True)[0]\n",
    "    d2x_dt2 = torch.autograd.grad(dx_dt, t, torch.ones_like(dx_dt), create_graph=True)[0]\n",
    "    residuals = d2x_dt2 + 2*zeta*omega_0*dx_dt + omega_0**2*x\n",
    "    loss = torch.mean(residuals**2)\n",
    "    return loss, residuals\n",
    "\n",
    "# Model, optimizer, and training loop setup\n",
    "model = DampedOscillatorPINN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "omega_0 = 1.0  # Natural frequency\n",
    "zeta = 0.1    # Damping ratio\n",
    "\n",
    "\n",
    "# Initialization for residuals collection\n",
    "all_residuals = []\n",
    "selected_epoch = 5000  # Example: Collecting residuals at the last epoch\n",
    "\n",
    "for epoch in range(selected_epoch):\n",
    "    t = torch.rand(100, 1) * 10  # Generate random time points within the domain\n",
    "    optimizer.zero_grad()\n",
    "    loss, residuals = compute_loss_and_residuals(model, t, omega_0, zeta)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch == selected_epoch - 1:  # Collect residuals at the specified epoch\n",
    "        all_residuals.append(residuals.detach().numpy())\n",
    "\n",
    "# After training, plot the collected residuals for the specified epoch\n",
    "# Assuming `t` still holds the training points used in the last epoch\n",
    "plt.scatter(t.detach().numpy(), all_residuals[0], alpha=0.6)\n",
    "plt.xlabel('Training Points (t)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals at Training Points')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b93f6bd-d3f1-41d5-bb41-72af0583f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_residuals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba5834-a06d-44b2-a6aa-c7fb375245fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the rest of the model setup is as before\n",
    "\n",
    "# Initialization for residuals collection\n",
    "all_residuals = []\n",
    "selected_epoch = 5000  # Example: Collecting residuals at the last epoch\n",
    "\n",
    "for epoch in range(selected_epoch):\n",
    "    t = torch.rand(100, 1) * 10  # Generate random time points within the domain\n",
    "    optimizer.zero_grad()\n",
    "    loss, residuals = compute_loss_and_residuals(model, t, omega_0, zeta)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch == selected_epoch - 1:  # Collect residuals at the specified epoch\n",
    "        all_residuals.append(residuals.detach().numpy())\n",
    "\n",
    "# After training, plot the collected residuals for the specified epoch\n",
    "# Assuming `t` still holds the training points used in the last epoch\n",
    "plt.scatter(t.detach().numpy(), all_residuals[0], alpha=0.6)\n",
    "plt.xlabel('Training Points (t)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals at Training Points')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd44fbce-3a5f-41e1-b64f-7f52b0908398",
   "metadata": {},
   "source": [
    "## t and zeta as inputs to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8da46-ca62-4ee3-b9ef-fa4659087f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Define the neural network architecture\n",
    "class DampedOscillatorPINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DampedOscillatorPINN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 50),  # Adjusted to accept 2-dimensional input\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 50),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, t, zeta):\n",
    "        # Concatenate t and zeta to form a 2D input\n",
    "        input = torch.cat((t, zeta), dim=1)\n",
    "        return self.net(input)\n",
    "\n",
    "def compute_loss_and_residuals(model, t, zeta, omega_0):\n",
    "    t.requires_grad = True\n",
    "    x = model(t, zeta)  # Assuming the model is adapted to accept zeta as well\n",
    "    dx_dt = torch.autograd.grad(x, t, torch.ones_like(x), create_graph=True)[0]\n",
    "    d2x_dt2 = torch.autograd.grad(dx_dt, t, torch.ones_like(dx_dt), create_graph=True)[0]\n",
    "    \n",
    "    # Use the zeta values in the differential equation\n",
    "    residuals = d2x_dt2 + 2 * zeta * omega_0 * dx_dt + omega_0**2 * x\n",
    "    \n",
    "    # Compute the loss as the mean squared residuals\n",
    "    loss = torch.mean(residuals**2)\n",
    "    return loss, residuals\n",
    "\n",
    "\n",
    "\n",
    "# Example: Generate a grid of t and zeta values\n",
    "t_values = np.linspace(0, 10, 100)  # Time range\n",
    "zeta_values = np.linspace(0.1, 10, 100)  # Damping ratio range\n",
    "T, Zeta = np.meshgrid(t_values, zeta_values)\n",
    "T_flat = T.flatten()\n",
    "Zeta_flat = Zeta.flatten()\n",
    "# Parameters\n",
    "omega_0 = 1.0  # Natural frequency\n",
    "\n",
    "all_residuals = []\n",
    "# Model, Optimizer, and Training\n",
    "model = DampedOscillatorPINN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "selected_epoch = 5000  # Example: Collecting residuals at the last epoch\n",
    "\n",
    "for epoch in range(selected_epoch):\n",
    "    t = torch.rand(100, 1) * 10  # Generate random time points within the domain\n",
    "    optimizer.zero_grad()\n",
    "    loss, residuals = compute_loss_and_residuals(model, t, zeta, omega_0)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch == selected_epoch - 1:  # Collect residuals at the specified epoch\n",
    "        all_residuals.append(residuals.detach().numpy())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming compute_loss_and_residuals is modified to accept zeta values\n",
    "# Compute residuals for each (t, zeta) pair (this is a placeholder for actual computation)\n",
    "# For demonstration, let's assume we obtain residuals like this:\n",
    "# Residuals = np.random.rand(T_flat.shape[0])  # Placeholder for actual residuals computation\n",
    "\n",
    "# Visualization\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(T_flat, Zeta_flat, all_residuals, alpha=0.6)\n",
    "ax.set_xlabel('Time (t)')\n",
    "ax.set_ylabel('Damping Ratio (zeta)')\n",
    "ax.set_zlabel('Residuals')\n",
    "plt.title('Residuals in the (t, zeta) Space')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bad782-f2b8-4abc-86c3-81232136f722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a1f2e-68c7-4cc5-8c69-ffb8044c3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the neural network architecture\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.sin(self.fc1(x))\n",
    "        out = torch.sin(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "# Define the function for solving the damped harmonic oscillator equation\n",
    "def damped_harmonic_oscillator(x, t, u):\n",
    "    gamma = 0.1  # damping coefficient\n",
    "    k = 1.0      # spring constant\n",
    "    m = 1.0      # mass\n",
    "    return -gamma * u - (k/m) * x\n",
    "\n",
    "# Define the loss function\n",
    "def loss_fn(pde_loss, boundary_loss):\n",
    "    return pde_loss.mean() + boundary_loss.mean()\n",
    "\n",
    "# Function to compute the PDE loss\n",
    "def compute_pde_loss(model, x_pde, t_pde):\n",
    "    x_pde.requires_grad = True\n",
    "    t_pde.requires_grad = True\n",
    "\n",
    "    u_pred = model(torch.cat((x_pde, t_pde), dim=1))\n",
    "    x_grad = torch.autograd.grad(u_pred.sum(), x_pde, create_graph=True)[0]\n",
    "    t_grad = torch.autograd.grad(u_pred.sum(), t_pde, create_graph=True)[0]\n",
    "\n",
    "    u_t = t_grad[:, 0]\n",
    "    u_xx = torch.autograd.grad(x_grad[:, 0], x_pde, create_graph=True)[0][:, 0]\n",
    "\n",
    "    pde_loss = u_t - damped_harmonic_oscillator(x_pde, t_pde, u_pred) - u_xx\n",
    "    \n",
    "    return pde_loss\n",
    "\n",
    "# Function to compute the boundary loss\n",
    "def compute_boundary_loss(model, x_lb, x_ub, t_lb, t_ub):\n",
    "    u_lb = model(torch.cat((x_lb, t_lb), dim=1))\n",
    "    u_ub = model(torch.cat((x_ub, t_ub), dim=1))\n",
    "\n",
    "    boundary_loss = (u_lb - 0)**2 + (u_ub - 0)**2  # Natural boundary condition\n",
    "    \n",
    "    return boundary_loss\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train(model, x_pde, t_pde, x_lb, x_ub, t_lb, t_ub, num_epochs=10000, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pde_loss = compute_pde_loss(model, x_pde, t_pde)\n",
    "        boundary_loss = compute_boundary_loss(model, x_lb, x_ub, t_lb, t_ub)\n",
    "\n",
    "        loss = loss_fn(pde_loss, boundary_loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Total Loss: {loss.item()}')\n",
    "\n",
    "    return losses\n",
    "\n",
    "# Training data\n",
    "x_pde = torch.tensor(np.random.uniform(-1, 1, (1000, 1)), dtype=torch.float32, requires_grad=True)\n",
    "t_pde = torch.tensor(np.random.uniform(0, 2, (1000, 1)), dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "x_lb = torch.tensor([[-1.0], [1.0]], dtype=torch.float32, requires_grad=True)\n",
    "x_ub = torch.tensor([[-1.0], [1.0]], dtype=torch.float32, requires_grad=True)\n",
    "t_lb = torch.tensor([[0.0], [0.0]], dtype=torch.float32, requires_grad=True)\n",
    "t_ub = torch.tensor([[2.0], [2.0]], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "# Model, Loss, and Training\n",
    "model = NeuralNet(input_size=2, hidden_size=50, output_size=1)\n",
    "losses = train(model, x_pde, t_pde, x_lb, x_ub, t_lb, t_ub)\n",
    "\n",
    "# Plot the loss\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d94f10-7676-422a-8957-94ecf85b59a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6e4a3-6b0a-4ced-8037-a408eba22d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25443f7-d90b-409d-8269-6db300b4ed32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the weights and biases for the original network\n",
    "# Replace these with your actual values\n",
    "original_weights = {\n",
    "    'hidden_layer1': torch.randn(8, 2),\n",
    "    'hidden_layer2': torch.randn(8, 8),\n",
    "    'output_layer': torch.randn(1, 8),\n",
    "}\n",
    "\n",
    "original_biases = {\n",
    "    'hidden_layer1': torch.randn(8),\n",
    "    'hidden_layer2': torch.randn(8),\n",
    "    'output_layer': torch.randn(1),\n",
    "}\n",
    "\n",
    "# Define the architecture of the new network\n",
    "new_input_size = 2\n",
    "new_hidden_layers = [8, 8]\n",
    "new_output_size = 1\n",
    "\n",
    "# Create a new model with the same architecture as the original one\n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(NewModel, self).__init__()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layers[0])\n",
    "        \n",
    "        # Hidden layers with weights and biases from the original model\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers)-1)\n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the new model\n",
    "new_model = NewModel(new_input_size, new_hidden_layers, new_output_size)\n",
    "\n",
    "# Set the weights and biases from the original model\n",
    "new_model.input_layer.weight.data = torch.transpose(original_weights['hidden_layer1'], 0, 1)\n",
    "new_model.input_layer.bias.data = original_biases['hidden_layer1']\n",
    "\n",
    "for i, layer in enumerate(new_model.hidden_layers):\n",
    "    layer.weight.data = torch.transpose(original_weights[f'hidden_layer{i+2}'], 0, 1)\n",
    "    layer.bias.data = original_biases[f'hidden_layer{i+2}']\n",
    "\n",
    "new_model.output_layer.weight.data = torch.transpose(original_weights['output_layer'], 0, 1)\n",
    "new_model.output_layer.bias.data = original_biases['output_layer']\n",
    "\n",
    "# Visualize the differences in weights and biases\n",
    "def visualize_difference(original, new, layer_name):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Plot weights\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f'{layer_name} Weights')\n",
    "    plt.imshow(original, cmap='viridis')\n",
    "    plt.colorbar(label='Weight Values')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f'Difference in {layer_name} Weights')\n",
    "    plt.imshow(new - original, cmap='coolwarm')\n",
    "    plt.colorbar(label='Weight Difference')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize differences for each layer\n",
    "for layer_name, original_weight in original_weights.items():\n",
    "    new_weight = getattr(new_model, layer_name).weight.data\n",
    "    visualize_difference(original_weight, new_weight, layer_name)\n",
    "\n",
    "# Visualize differences for biases\n",
    "for layer_name, original_bias in original_biases.items():\n",
    "    new_bias = getattr(new_model, layer_name).bias.data\n",
    "    visualize_difference(original_bias.unsqueeze(0), new_bias.unsqueeze(0), layer_name + ' Bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c9143-f857-489d-b2e3-5002526a88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    im = ax.imshow(weights, cmap='coolwarm', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "layer_sizes = [2, 4, 8, 4, 1]\n",
    "\n",
    "# Initialize random weights\n",
    "np.random.seed(42)\n",
    "weights = [np.random.randn(layer_sizes[i], layer_sizes[i+1]) for i in range(len(layer_sizes)-1)]\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(layer_sizes)-1, figsize=(15, 5))\n",
    "\n",
    "# Plot the weights for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Weights Layer {i+1}')\n",
    "\n",
    "    # Show the colorbars\n",
    "    fig.colorbar(im, ax=ax, orientation='horizontal')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f79653-125e-40e6-b8fb-4e54d88d82ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Weights Layer {i+1}')\n",
    "\n",
    "    # Show the colorbars\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ecc82c-fb1d-4d91-b682-fc5009231f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2b93b-bc9c-4372-81a1-57ff6125a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='black', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Weights Layer {i+1}')\n",
    "\n",
    "    # Show the colorbars\n",
    "    fig.colorbar(im, ax=ax, orientation='horizontal')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7fd272-7286-4fc7-bc0c-10930b19f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf248e3-097e-4154-a886-d31df6d9f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4598e-ae08-4009-9a5b-27915ec1d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights and biases from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Layer {i+1}')\n",
    "\n",
    "    # Show the colorbars\n",
    "    #fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16750952-921f-4553-b7d8-1cd1b33e71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title, labels):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers and labels to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}\\n{labels[i, j]}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights and biases from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create labels to indicate weights or biases\n",
    "labels = np.array([['Weight' if 'weight' in key else 'Bias' for key in state_dict.keys()]])\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Layer {i+1}', labels)\n",
    "\n",
    "    # Show the colorbars\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78ada7-6e69-4a32-a1d9-80b36cc856e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title, labels):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers and labels to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}\\n{labels[i, j]}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights and biases from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create labels to indicate weights or biases\n",
    "labels = np.array([['Weight' if 'weight' in key else 'Bias' for key in state_dict.keys()]])  # Note the extra square brackets\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Layer {i+1}', labels)\n",
    "\n",
    "    # Show the colorbars\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad298fdb-673c-42db-af69-79ab371b8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title, labels):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers and labels to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}\\n{labels[i, j]}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights and biases from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create labels to indicate weights or biases\n",
    "labels = np.array([['Weight' if 'weight' in key else 'Bias' for key in state_dict.keys()]])\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Layer {i+1}', labels)\n",
    "\n",
    "    # Show the colorbars\n",
    "    fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e298ec2-8613-47d2-bb4d-1df53fa9e736",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60fb4a-401c-4709-955c-196ca5eae7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f670323e-a753-4f5f-8a01-1339a3104cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the architecture of the original network\n",
    "original_input_size = 2\n",
    "original_hidden_layers = [8, 8]\n",
    "original_output_size = 1\n",
    "\n",
    "# Create the original model with Xavier initialization\n",
    "class OriginalModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(OriginalModel, self).__init__()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layers[0])\n",
    "        init.xavier_uniform_(self.input_layer.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        init.zeros_(self.input_layer.bias.data)\n",
    "        \n",
    "        # Hidden layers with Xavier initialization\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers)-1)\n",
    "        ])\n",
    "        for layer in self.hidden_layers:\n",
    "            init.xavier_uniform_(layer.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "            init.zeros_(layer.bias.data)\n",
    "        \n",
    "        # Output layer with Xavier initialization\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "        init.xavier_uniform_(self.output_layer.weight.data, gain=nn.init.calculate_gain('linear'))\n",
    "        init.zeros_(self.output_layer.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the original model\n",
    "original_model = OriginalModel(original_input_size, original_hidden_layers, original_output_size)\n",
    "\n",
    "# Define the architecture of the new network with increased neurons\n",
    "new_input_size = 2\n",
    "new_hidden_layers = [16, 16]  # Increase the number of neurons\n",
    "new_output_size = 1\n",
    "\n",
    "# Create a new model with the same architecture as the original one\n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(NewModel, self).__init__()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layers[0])\n",
    "        \n",
    "        # Hidden layers with weights and biases from the original model\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers)-1)\n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the new model\n",
    "new_model = NewModel(new_input_size, new_hidden_layers, new_output_size)\n",
    "\n",
    "# Set the weights from the original model using He initialization\n",
    "def initialize_weights_he(model):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            init.kaiming_uniform_(layer.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "            init.zeros_(layer.bias.data)\n",
    "\n",
    "# Initialize weights of the new model using He initialization\n",
    "initialize_weights_he(new_model)\n",
    "\n",
    "# Visualize the differences in weights and biases\n",
    "def visualize_difference(original, new, layer_name):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Plot weights\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f'{layer_name} Weights')\n",
    "    plt.imshow(original, cmap='viridis')\n",
    "    plt.colorbar(label='Weight Values')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f'Difference in {layer_name} Weights')\n",
    "    plt.imshow(new - original, cmap='coolwarm')\n",
    "    plt.colorbar(label='Weight Difference')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize differences for each layer\n",
    "for layer_name, original_weight in original_model.state_dict().items():\n",
    "    new_weight = new_model.state_dict()[layer_name]\n",
    "    visualize_difference(original_weight, new_weight, layer_name)\n",
    "\n",
    "# Visualize differences for biases\n",
    "for layer_name, original_bias in original_model.state_dict().items():\n",
    "    if 'bias' in layer_name:\n",
    "        new_bias = new_model.state_dict()[layer_name]\n",
    "        visualize_difference(original_bias.unsqueeze(0), new_bias.unsqueeze(0), layer_name + ' Bias')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807ef4d-b443-481d-9d9a-eaae0d389ab7",
   "metadata": {},
   "source": [
    "# ADAPTIVE SCHEME II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3695ebe-797f-4ff5-a2d8-510dd00f7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the original model\n",
    "class OriginalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OriginalModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 4)\n",
    "        self.output = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Train and save the original model\n",
    "original_model = OriginalModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(original_model.parameters(), lr=0.01)\n",
    "\n",
    "# Dummy data for training\n",
    "input_data = torch.rand((100, 2))\n",
    "target_data = torch.rand((100, 1))\n",
    "\n",
    "original_weights = []  # List to store original model weights\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = original_model(input_data)\n",
    "    loss = criterion(output, target_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Store the weights for visualization\n",
    "    original_weights.append(original_model.fc1.weight.data.numpy().flatten())\n",
    "\n",
    "# Save the weights and biases\n",
    "torch.save(original_model.state_dict(), 'original_model.pth')\n",
    "\n",
    "# Define the new model with an additional hidden layer\n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NewModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)\n",
    "        self.fc2 = nn.Linear(4, 4)\n",
    "        self.new_layer = nn.Linear(4, 4)  # Additional hidden layer\n",
    "        self.output = nn.Linear(4, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.new_layer(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the new model with the weights and biases of the original model\n",
    "new_model = NewModel()\n",
    "new_model.load_state_dict(torch.load('original_model.pth'))\n",
    "\n",
    "# Check the weights of the new model\n",
    "new_weights = []\n",
    "for epoch in range(10):  # Only for visualization, you can further train as needed\n",
    "    # Store the weights for visualization\n",
    "    new_weights.append(new_model.fc1.weight.data.numpy().flatten())\n",
    "\n",
    "# Plotting the weights\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(original_weights)\n",
    "plt.title('Original Model Weights')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Weight Values')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(new_weights)\n",
    "plt.title('New Model Weights (Initialized from Original)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Weight Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad98b63-762c-45c1-b7cc-9c3c88f57168",
   "metadata": {},
   "source": [
    "# Initialization and activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eba85e4-23a0-4a24-9e9d-57a9f153d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_sizes, activation='relu', initialization='xavier'):\n",
    "        super(FCN, self).__init__()\n",
    "\n",
    "        # Define input and output layers\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "        # Define hidden layers\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(in_size, out_size) for in_size, out_size in zip(hidden_sizes[:-1], hidden_sizes[1:])\n",
    "        ])\n",
    "\n",
    "        # Define ModuleDict for activation functions\n",
    "        self.activations = nn.ModuleDict({\n",
    "            'relu': nn.ReLU(),\n",
    "            'tanh': nn.Tanh(),\n",
    "        })\n",
    "\n",
    "        # Initialize layers\n",
    "        self.init_weights(initialization)\n",
    "\n",
    "        # Set activation function\n",
    "        if activation not in self.activations:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "        self.activation = self.activations[activation]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.activation(hidden_layer(x))\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    def init_weights(self, initialization):\n",
    "        # Initialize input layer\n",
    "        if initialization == 'xavier':\n",
    "            init.xavier_uniform_(self.input_layer.weight)\n",
    "        elif initialization == 'kaiming':\n",
    "            init.kaiming_uniform_(self.input_layer.weight, nonlinearity='relu')\n",
    "        elif initialization == 'zeros':\n",
    "            init.zeros_(self.input_layer.weight)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported initialization type\")\n",
    "\n",
    "        # Initialize hidden layers\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            if initialization == 'xavier':\n",
    "                init.xavier_uniform_(hidden_layer.weight)\n",
    "            elif initialization == 'kaiming':\n",
    "                init.kaiming_uniform_(hidden_layer.weight, nonlinearity='relu')\n",
    "            elif initialization == 'zeros':\n",
    "                init.zeros_(hidden_layer.weight)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported initialization type\")\n",
    "\n",
    "        # Initialize output layer\n",
    "        if initialization == 'xavier':\n",
    "            init.xavier_uniform_(self.output_layer.weight)\n",
    "        elif initialization == 'kaiming':\n",
    "            init.kaiming_uniform_(self.output_layer.weight, nonlinearity='relu')\n",
    "        elif initialization == 'zeros':\n",
    "            init.zeros_(self.output_layer.weight)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported initialization type\")\n",
    "\n",
    "# Example usage:\n",
    "input_size = 10\n",
    "output_size = 5\n",
    "hidden_sizes = [20, 30, 15, 10, 25]  # You can specify any number of neurons in each hidden layer\n",
    "\n",
    "# Create an instance of FCN with ReLU activation and Xavier initialization\n",
    "model = FCN(input_size, output_size, hidden_sizes, activation='relu', initialization='xavier')\n",
    "\n",
    "# Check the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee48140-fe23-422a-9c95-d78e16dd4743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T11:22:43.139375Z",
     "iopub.status.busy": "2024-02-08T11:22:43.138785Z",
     "iopub.status.idle": "2024-02-08T11:22:43.145227Z",
     "shell.execute_reply": "2024-02-08T11:22:43.144152Z",
     "shell.execute_reply.started": "2024-02-08T11:22:43.139338Z"
    }
   },
   "source": [
    "## Visualization of the weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0db1a-1f39-47fb-abce-b6acbe6d6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights and biases from state_dict\n",
    "weights = [state_dict[key].numpy() for key in state_dict.keys()]\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer using a for-loop\n",
    "for i, ax in enumerate(axes):\n",
    "    im = plot_weights(ax, weights[i], f'Layer {i+1}')\n",
    "\n",
    "    # Show the colorbars\n",
    "    #fig.colorbar(im, ax=ax, orientation='vertical')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c02d2-c029-474c-b95c-1c7f2cb00ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Filter out keys containing \"bias\"\n",
    "weights_dict = {key: value for key, value in state_dict.items() if 'bias' not in key}\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights_dict), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights for each layer using a for-loop\n",
    "for i, (key, weights) in enumerate(weights_dict.items()):\n",
    "    im = plot_weights(axes[i], weights.numpy(), f'{key}')\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d1c31-0eca-4e88-8092-6042fef13bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Combine both dictionaries for weights and biases into a single dictionary\n",
    "weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights_biases_dict), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer\n",
    "for i, (key, data) in enumerate(weights_biases_dict.items()):\n",
    "    if 'bias' in key:\n",
    "        im = plot_weights(axes[i], data.numpy().reshape(-1, 1), f'{key} (Biases)')\n",
    "    elif 'weight' in key:\n",
    "        im = plot_weights(axes[i], data.numpy(), f'{key} (Weights)')\n",
    "# Add a colorbar for all the plots\n",
    "divider = make_axes_locatable(axes[-3])\n",
    "cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "cbar.set_label('Value')\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbb7d7-f8e6-4142-b597-9b17f958b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def plot_weights(ax, weights, title):\n",
    "    if len(weights.shape) == 1:\n",
    "        # If the weights are 1D (possibly biases), reshape them to (1, len(weights))\n",
    "        weights = weights.reshape(1, -1)\n",
    "    im = ax.imshow(weights, cmap='viridis', interpolation='none')\n",
    "\n",
    "    # Add numbers to the cells\n",
    "    for i in range(weights.shape[0]):\n",
    "        for j in range(weights.shape[1]):\n",
    "            ax.text(j, i, f'{weights[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return im\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Load weights and biases from the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Combine both dictionaries for weights and biases into a single dictionary\n",
    "weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "\n",
    "# Create a figure for visualization\n",
    "fig, axes = plt.subplots(1, len(weights_biases_dict), figsize=(15, 5))\n",
    "\n",
    "# Plot the weights and biases for each layer\n",
    "max_intensity = 0  # Track the maximum intensity across all plots\n",
    "for i, (key, data) in enumerate(weights_biases_dict.items()):\n",
    "    if 'bias' in key:\n",
    "        im = plot_weights(axes[i], data.numpy().reshape(-1, 1), f'{key} (Biases)')\n",
    "    elif 'weight' in key:\n",
    "        im = plot_weights(axes[i], data.numpy(), f'{key} (Weights)')\n",
    "    \n",
    "    max_intensity = max(max_intensity, np.max(np.abs(data.numpy())))  # Update max intensity\n",
    "\n",
    "# Add a colorbar below all the plots\n",
    "divider = make_axes_locatable(axes[-1])\n",
    "cax = divider.append_axes(\"bottom\", size=\"10%\", pad=0.5)\n",
    "cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "cbar.set_label('Value')\n",
    "\n",
    "# Normalize the color bar based on the maximum intensity across all plots\n",
    "cbar.set_clim(-max_intensity, max_intensity)\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb2b5d-6a51-4366-82a4-6b8e2d768433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def plot_weights(self):\n",
    "        state_dict = self.state_dict()\n",
    "        weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Create a figure for visualization\n",
    "        num_plots = len(weights_biases_dict)\n",
    "        fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))\n",
    "\n",
    "        # Plot the weights and biases for each layer\n",
    "        #max_intensity = 0  # Track the maximum intensity across all plots\n",
    "        for i, (key, data) in enumerate(weights_biases_dict.items()):\n",
    "            ax = axes[i] if num_plots > 1 else axes\n",
    "            if 'bias' in key:\n",
    "                title = f'{key} (Biases)'\n",
    "            elif 'weight' in key:\n",
    "                title = f'{key} (Weights)'\n",
    "                \n",
    "            if len(data.shape) == 1:\n",
    "                # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "                data = data.reshape(1, -1)\n",
    "                \n",
    "            im = ax.imshow(data.numpy(), cmap='viridis', interpolation='none')\n",
    "\n",
    "            # Add numbers to the cells\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    ax.text(j, i, f'{data[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "            ax.set_title(title)\n",
    "            #max_intensity = max(max_intensity, np.max(np.abs(data.numpy())))  # Update max intensity\n",
    "\n",
    "        # Add a colorbar below all the plots\n",
    "        #divider = make_axes_locatable(ax)\n",
    "        #cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "        #cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "        #cbar.set_label('Value')\n",
    "\n",
    "        # Normalize the color bar based on the maximum intensity across all plots\n",
    "        #cbar.set_clim(-max_intensity, max_intensity)\n",
    "\n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Call the plot_weights method\n",
    "model.plot_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38e34b-a6a9-4189-a187-877cf854f2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b66da6-c48d-4b1d-8bbb-ffc11e2b16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT, N_OUTPUT, hidden_layers, activation='Tanh', initialization='He'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_functions = nn.ModuleDict([\n",
    "            [\"Tanh\", nn.Tanh()],\n",
    "            [\"ReLU\", nn.ReLU()],\n",
    "            [\"LeakyReLU\", nn.LeakyReLU()],\n",
    "            [\"Sigmoid\", nn.Sigmoid()],\n",
    "            [\"Softmax\", nn.Softmax(dim=-1)],\n",
    "        ])\n",
    "\n",
    "        if activation not in self.activation_functions:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.activation = self.activation_functions[activation]\n",
    "\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(N_INPUT, hidden_layers[0]),\n",
    "            self.activation\n",
    "        )\n",
    "\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_layers[i], hidden_layers[i + 1]),\n",
    "                self.activation\n",
    "            ) for i in range(len(hidden_layers) - 1)\n",
    "        ])\n",
    "\n",
    "        self.fce = nn.Linear(hidden_layers[-1], N_OUTPUT)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fcs(x)\n",
    "        for layer in self.fch:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.fce(x)\n",
    "        return x\n",
    "    \n",
    "    def initialize_parameters(self, initialization):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if initialization == 'Uniform':\n",
    "                    init.uniform_(module.weight.data, -0.1, 0.1)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Normal':\n",
    "                    init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Xavier':\n",
    "                    init.xavier_uniform_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'He':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Orthogonal':\n",
    "                    init.orthogonal_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Kaiming':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported initialization type\")\n",
    "\n",
    "    def plot_weights(self):\n",
    "        state_dict = self.state_dict()\n",
    "        weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Create a figure for visualization\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols -1) // num_cols\n",
    "        #fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))\n",
    "        fig, axes = plt.subplots(num_rows,\n",
    "                                 ncols, \n",
    "                                 figsize=(5*num_plots, 5)\n",
    "                                )\n",
    "\n",
    "        # Plot the weights and biases for each layer\n",
    "        #max_intensity = 0  # Track the maximum intensity across all plots\n",
    "        for i, (key, data) in enumerate(weights_biases_dict.items()):\n",
    "            ax = axes[i] if num_plots > 1 else axes\n",
    "            if 'bias' in key:\n",
    "                title = f'{key} (Biases)'\n",
    "            elif 'weight' in key:\n",
    "                title = f'{key} (Weights)'\n",
    "                \n",
    "            if len(data.shape) == 1:\n",
    "                # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "                data = data.reshape(1, -1)\n",
    "                \n",
    "            im = ax.imshow(data.numpy(), cmap='viridis', interpolation='none')\n",
    "\n",
    "            # Add numbers to the cells\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    ax.text(j, i, f'{data[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "            ax.set_title(title)\n",
    "            #max_intensity = max(max_intensity, np.max(np.abs(data.numpy())))  # Update max intensity\n",
    "\n",
    "        # Add a colorbar below all the plots\n",
    "        #divider = make_axes_locatable(ax)\n",
    "        #cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "        #cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "        #cbar.set_label('Value')\n",
    "\n",
    "        # Normalize the color bar based on the maximum intensity across all plots\n",
    "        #cbar.set_clim(-max_intensity, max_intensity)\n",
    "\n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_difference(self, original, new, layer_name):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        # Plot weights\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f'{layer_name} Weights')\n",
    "        plt.imshow(original, cmap='viridis')\n",
    "        plt.colorbar(label='Weight Values')\n",
    "        plt.xlabel('Neurons in Previous Layer')\n",
    "        plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(f'Difference in {layer_name} Weights')\n",
    "        plt.imshow(new - original, cmap='coolwarm')\n",
    "        plt.colorbar(label='Weight Difference')\n",
    "        plt.xlabel('Neurons in Previous Layer')\n",
    "        plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Step 1: Create the original model\n",
    "original_input_size = 2\n",
    "original_hidden_layers = [8, 8]\n",
    "original_output_size = 1\n",
    "original_model = FCN(original_input_size, original_output_size, original_hidden_layers, activation='Tanh', initialization='He')\n",
    "original_model.plot_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd8aa2-150b-451a-b4d1-331a33e8036e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27d860-509c-4130-97d7-2c6d64eca1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each tensor using Matplotlib\n",
    "for idx, (key, tensor) in enumerate(tensor_dict.items()):\n",
    "    row = idx // num_cols\n",
    "    col = idx % num_cols\n",
    "    axs[row, col].imshow(tensor, cmap='gray')  # Adjust colormap as needed\n",
    "    axs[row, col].set_title(key)\n",
    "    axs[row, col].axis('off')  # Turn off axis\n",
    "    axs[row, col].set_aspect('auto')  # Set aspect ratio to auto\n",
    "# Plot data in each subplot\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i < num_subplots:\n",
    "        ax.plot(x, y)\n",
    "        ax.set_title(f\"Subplot {i+1}\")\n",
    "    else:\n",
    "        ax.axis('off')  # Hide extra subplots\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5239886-74b9-44e3-bfc5-21baa07774ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = original_model.state_dict()\n",
    "weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "type(weights_biases_dict['fcs.0.weight'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d48ba9-36a0-4281-9354-545452915d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure for visualization\n",
    "num_plots = len(weights_biases_dict)\n",
    "#fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))\n",
    "fig, axes = plt.subplots(nrows = (num_plots +1)//2,\n",
    "                                 ncols = 2, \n",
    "                                 figsize=(5*num_plots, 5)\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6772df81-9738-400c-b3ea-fe2fe7246695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Visualize the weights and biases of the original model\n",
    "for layer_name, param in original_model.named_parameters():\n",
    "    original_weight = param.detach().numpy()\n",
    "    original_model.visualize_difference(original_weight, original_weight, layer_name)\n",
    "\n",
    "# Step 3: Create the extended model with 16 neurons in hidden layers and ReLU activation\n",
    "extended_hidden_layers = [16, 16]\n",
    "extended_model = FCN(original_input_size, original_output_size, extended_hidden_layers, activation='ReLU', initialization='He')\n",
    "\n",
    "# Step 4: Visualize the weights and biases of the extended model\n",
    "for layer_name, param in extended_model.named_parameters():\n",
    "    extended_weight = param.detach().numpy()\n",
    "    extended_model.visualize_difference(extended_weight, extended_weight, layer_name)\n",
    "\n",
    "# Step 5: Overwrite the weights and biases of the extended model with the original model\n",
    "for original_param, extended_param in zip(original_model.parameters(), extended_model.parameters()):\n",
    "    extended_param.data.copy_(original_param.data)\n",
    "\n",
    "# Step 6: Visualize the weights and biases of the extended model after overwriting\n",
    "for layer_name, param in extended_model.named_parameters():\n",
    "    extended_weight = param.detach().numpy()\n",
    "    extended_model.visualize_difference(original_weight, extended_weight, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d710f3-6544-460d-ae4b-8baa198f9685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def plot_weights(self):\n",
    "        state_dict = self.state_dict()\n",
    "        \n",
    "        num_plots = len(state_dict)\n",
    "        fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))\n",
    "\n",
    "        max_intensity = 0  \n",
    "        for i, (key, data) in enumerate(state_dict.items()):\n",
    "            ax = axes[i] if num_plots > 1 else axes\n",
    "            title = f'{key} (Biases)' if 'bias' in key else f'{key} (Weights)'\n",
    "            \n",
    "            if len(data.shape) == 1:\n",
    "                data = data.reshape(1, -1)\n",
    "                \n",
    "            im = ax.imshow(data.numpy(), cmap='viridis', interpolation='none')\n",
    "\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    ax.text(j, i, f'{data[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "            ax.set_title(title)\n",
    "            max_intensity = max(max_intensity, np.max(np.abs(data.numpy()))) \n",
    "\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "        cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "        cbar.set_label('Value')\n",
    "        cbar.set_clim(-max_intensity, max_intensity)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Call the plot_weights method\n",
    "model.plot_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac6b86-d3f3-4d2b-a8a4-28c6ce31ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example dictionary with tensors as values\n",
    "tensor_dict = {\n",
    "    'tensor1': np.random.rand(10, 10),\n",
    "    'tensor2': np.random.rand(10, 10)\n",
    "}\n",
    "\n",
    "# Determine the number of subplots needed\n",
    "num_subplots = len(tensor_dict)\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(1, num_subplots, figsize=(10, 5))\n",
    "\n",
    "# Plot each tensor using Matplotlib\n",
    "for idx, (key, tensor) in enumerate(tensor_dict.items()):\n",
    "    axs[idx].imshow(tensor, cmap='gray')  # Adjust colormap as needed\n",
    "    axs[idx].set_title(key)\n",
    "    axs[idx].axis('off')  # Turn off axis\n",
    "    axs[idx].set_aspect('auto')  # Set aspect ratio to auto\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f808dce-bc84-4e03-82b3-74667b6c7500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example dictionary with tensors as values\n",
    "tensor_dict = {\n",
    "    'tensor1': np.random.rand(10, 10),\n",
    "    'tensor2': np.random.rand(10, 10),\n",
    "    'tensor3': np.random.rand(10, 10),\n",
    "    'tensor4': np.random.rand(10, 10),\n",
    "    'tensor5': np.random.rand(10, 10)\n",
    "}\n",
    "\n",
    "# Determine the number of subplots needed\n",
    "num_subplots = len(tensor_dict)\n",
    "\n",
    "# Create subplots with 3 rows and 2 columns\n",
    "num_rows = 3\n",
    "num_cols = 2\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "\n",
    "# Plot each tensor using Matplotlib\n",
    "for idx, (key, tensor) in enumerate(tensor_dict.items()):\n",
    "    row = idx // num_cols\n",
    "    col = idx % num_cols\n",
    "    axs[row, col].imshow(tensor, cmap='gray')  # Adjust colormap as needed\n",
    "    axs[row, col].set_title(key)\n",
    "    axs[row, col].axis('off')  # Turn off axis\n",
    "    axs[row, col].set_aspect('auto')  # Set aspect ratio to auto\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d6cf6-01b8-42f3-b59e-bb3765a547df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example dictionary with tensors as values\n",
    "tensor_dict = {\n",
    "    'tensor1': np.random.rand(10, 10),\n",
    "    'tensor2': np.random.rand(10, 10),\n",
    "    'tensor3': np.random.rand(10, 10),\n",
    "    'tensor4': np.random.rand(10, 10),\n",
    "    'tensor5': np.random.rand(10, 10)\n",
    "}\n",
    "\n",
    "# Determine the number of subplots needed\n",
    "num_subplots = len(tensor_dict)\n",
    "\n",
    "# Create subplots with 3 rows and 2 columns\n",
    "num_rows = 3\n",
    "num_cols = 2\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "type(axs)\n",
    "# Plot each tensor using Matplotlib\n",
    "for idx, (key, tensor) in enumerate(tensor_dict.items()):\n",
    "    if idx < num_rows * num_cols:\n",
    "        row = idx // num_cols\n",
    "        col = idx % num_cols\n",
    "        axs[row, col].imshow(tensor, cmap='gray')  # Adjust colormap as needed\n",
    "        axs[row, col].set_title(key)\n",
    "        axs[row, col].axis('off')  # Turn off axis\n",
    "        axs[row, col].set_aspect('auto')  # Set aspect ratio to auto\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8680a61-cab7-479b-a4b9-1bd8cf58f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65a30b-767e-48fd-9f2e-b1bf32009626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "x = np.linspace(0, 2*np.pi, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Create odd number of subplots\n",
    "num_subplots = 5\n",
    "num_cols = 2\n",
    "num_rows = (num_subplots + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "\n",
    "# Plot data in each subplot\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i < num_subplots:\n",
    "        ax.plot(x, y)\n",
    "        ax.set_title(f\"Subplot {i+1}\")\n",
    "    else:\n",
    "        ax.axis('off')  # Hide extra subplots\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e7c03-eb99-4d14-8977-15a00c4068b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "data = np.random.rand(28, 28, 5)  # Example image data, assuming grayscale images of size 28x28\n",
    "\n",
    "# Create odd number of subplots\n",
    "num_subplots = 5\n",
    "num_cols = 3\n",
    "num_rows = (num_subplots + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "\n",
    "# Plot images in each subplot\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i < num_subplots:\n",
    "        ax.imshow(data[:, :, i], cmap='gray')  # Assuming grayscale images\n",
    "        ax.set_title(f\"Subplot {i+1}\")\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')  # Hide extra subplots\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d03c2-fb59-4107-a25f-b86e03c77d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example dictionary with tensors as values\n",
    "tensor_dict = {\n",
    "    'tensor1': np.random.rand(28, 28),\n",
    "    'tensor2': np.random.rand(28, 28),\n",
    "    'tensor3': np.random.rand(28, 28),\n",
    "    'tensor4': np.random.rand(28, 28),\n",
    "    'tensor5': np.random.rand(28, 28)\n",
    "}\n",
    "\n",
    "# Create odd number of subplots\n",
    "num_subplots = len(tensor_dict)\n",
    "num_cols = 2\n",
    "num_rows = (num_subplots + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 8))\n",
    "\n",
    "# Plot images in each subplot\n",
    "for i, (key, tensor) in enumerate(tensor_dict.items()):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    axs[row, col].imshow(tensor, cmap='gray')  # Assuming grayscale tensors\n",
    "    axs[row, col].set_title(key)\n",
    "    axs[row, col].axis('off')\n",
    "\n",
    "# Hide extra subplots\n",
    "for i in range(num_subplots, num_rows * num_cols):\n",
    "    axs.flatten()[i].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3cc7a-a031-4787-80e1-e65ddf322412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example dictionary with tensors as values\n",
    "tensor_dict = {\n",
    "    'tensor1': np.random.rand(2, 1),\n",
    "    'tensor2': np.random.rand(1, 4),\n",
    "    'tensor3': np.random.rand(4, 4),\n",
    "    'tensor4': np.random.rand(1, 4),\n",
    "    'tensor5': np.random.rand(1, 1)\n",
    "}\n",
    "\n",
    "# Create odd number of subplots\n",
    "num_subplots = len(tensor_dict)\n",
    "num_cols = 2\n",
    "num_rows = (num_subplots + num_cols - 1) // num_cols  # Calculate number of rows needed\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 15))\n",
    "\n",
    "# Plot images and add values in each subplot\n",
    "for i, (key, tensor) in enumerate(tensor_dict.items()):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    ax = axs[row, col]\n",
    "    print(\"*\"*50)\n",
    "    print(i)\n",
    "    print(key)\n",
    "    print(tensor)\n",
    "    print(\"*\"*10)\n",
    "    print(f\"tensor shape: {tensor.shape}\")\n",
    "    print(tensor.ndim)\n",
    "    print(\"Now tensor\")\n",
    "    ax.imshow(tensor, cmap='viridis', interpolation='none')  # Assuming grayscale tensors\n",
    "    print(\"printed\")\n",
    "    print(\"*\"*50)\n",
    "    ax.set_title(key)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add values in the middle of the cell\n",
    "    for y in range(tensor.shape[0]):\n",
    "        for x in range(tensor.shape[1]):\n",
    "            value = tensor[y, x]\n",
    "            ax.text(x, y, f'{value:.2f}', fontsize = 8, color='red', ha='center', va='center')\n",
    "\n",
    "# Hide extra subplots\n",
    "for i in range(num_subplots, num_rows * num_cols):\n",
    "    axs.flatten()[i].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "type(tensor_dict)\n",
    "print(tensor_dict[\"tensor1\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747a575-9b1b-46f9-97f0-4a6eace57ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tensor_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8629d476-85b0-4ff5-866d-6b25a01567cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tensor_dict[\"tensor1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7ee9d-35f5-42a7-9316-88ddf9703c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def plot_weights(self):\n",
    "        weights_biases_dict = self.state_dict()\n",
    "        #weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Definition of columns, rows and subplots\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols - 1) // num_cols  \n",
    "        \n",
    "        # For colorbar (collect minimum and maximum values across all tensors)\n",
    "        all_values = np.concatenate([tensor.flatten() for tensor in weights_biases_dict.values()])\n",
    "        min_val = round(all_values.min(), 1)\n",
    "        max_val = round(all_values.max(), 1)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "        \n",
    "        # Plot images and add values in each subplot\n",
    "        for i, (key, tensor) in enumerate(weights_biases_dict.items()):\n",
    "            row = i // num_cols\n",
    "            col = i % num_cols\n",
    "            ax = axs[row, col]\n",
    "            if 'weight' in key:\n",
    "                im = ax.imshow(tensor, cmap='viridis',vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}')\n",
    "            elif 'bias' in key:\n",
    "                im = ax.imshow(tensor.unsqueeze(0), cmap='viridis', vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}')\n",
    "            #ax.axis('off')\n",
    "            \n",
    "            # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "            if len(tensor.shape) == 1:\n",
    "                tensor = tensor.reshape(1, -1)\n",
    "\n",
    "            # Add xticks and yticks\n",
    "            ax.set_xticks(np.arange(0, tensor.shape[1] , step=1))  \n",
    "            ax.set_yticks(np.arange(0, tensor.shape[0] , step=1))  \n",
    "           \n",
    "            # Add values in the middle of the cell\n",
    "            for y in range(tensor.shape[0]):\n",
    "                for x in range(tensor.shape[1]):\n",
    "                    value = tensor[y, x]\n",
    "                    ax.text(x, y, f'{value:.2f}', fontsize = 8, color='white', ha='center', va='center')\n",
    "            \n",
    "         # Hide extra subplots\n",
    "        for i in range(num_subplots, num_rows * num_cols):\n",
    "            axs.flatten()[i].axis('off')\n",
    "            \n",
    "        # Add a title to the figure\n",
    "        plt.suptitle('Weights and Biases of the Neural Network')\n",
    "        \n",
    "        # Add a colorbar\n",
    "            # Set custom ticks and intervals\n",
    "        tick_interval = 0.2\n",
    "        ticks = np.arange(min_val, max_val, step=tick_interval)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.01])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', ticks = ticks)\n",
    "        #cbar.set_label('Colorbar Label') Label for the Colorbar\n",
    "        \n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "# Call the plot_weights method\n",
    "model.plot_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f69ab5-1321-46bf-91df-13b2506d460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def plot_weights(self):\n",
    "        state_dict = self.state_dict()\n",
    "        weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Create a figure for visualization\n",
    "        num_plots = len(weights_biases_dict)\n",
    "        fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))\n",
    "\n",
    "        # Plot the weights and biases for each layer\n",
    "        #max_intensity = 0  # Track the maximum intensity across all plots\n",
    "        for i, (key, data) in enumerate(weights_biases_dict.items()):\n",
    "            ax = axes[i] if num_plots > 1 else axes\n",
    "            if 'bias' in key:\n",
    "                title = f'{key} (Biases)'\n",
    "            elif 'weight' in key:\n",
    "                title = f'{key} (Weights)'\n",
    "                \n",
    "            if len(data.shape) == 1:\n",
    "                # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "                data = data.reshape(1, -1)\n",
    "                \n",
    "            im = ax.imshow(data.numpy(), cmap='viridis', interpolation='none')\n",
    "\n",
    "            # Add numbers to the cells\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    ax.text(j, i, f'{data[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "            ax.set_title(title)\n",
    "            #max_intensity = max(max_intensity, np.max(np.abs(data.numpy())))  # Update max intensity\n",
    "\n",
    "        # Add a colorbar below all the plots\n",
    "        #divider = make_axes_locatable(ax)\n",
    "        #cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "        #cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "        #cbar.set_label('Value')\n",
    "\n",
    "        # Normalize the color bar based on the maximum intensity across all plots\n",
    "        #cbar.set_clim(-max_intensity, max_intensity)\n",
    "\n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Call the plot_weights method\n",
    "model.plot_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd479b9-cd2b-4335-9160-c3783430e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def plot_weights(self):\n",
    "        state_dict = self.state_dict()\n",
    "        weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Create a figure for visualization\n",
    "        num_plots = len(weights_biases_dict)\n",
    "        fig, axes = plt.subplots(1, num_plots, figsize=(5*num_plots, 5))\n",
    "\n",
    "        # Plot the weights and biases for each layer\n",
    "        max_intensity = 0  # Track the maximum intensity across all plots\n",
    "        for i, (key, data) in enumerate(weights_biases_dict.items()):\n",
    "            ax = axes[i] if num_plots > 1 else axes\n",
    "            if 'bias' in key:\n",
    "                title = f'{key} (Biases)'\n",
    "            elif 'weight' in key:\n",
    "                title = f'{key} (Weights)'\n",
    "                \n",
    "            if len(data.shape) == 1:\n",
    "                # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "                data = data.reshape(1, -1)\n",
    "                \n",
    "            im = ax.imshow(data.numpy(), cmap='viridis', interpolation='none')\n",
    "\n",
    "            # Add numbers to the cells\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    ax.text(j, i, f'{data[i, j]:.2f}', color='white', ha='center', va='center')\n",
    "\n",
    "            ax.set_title(title)\n",
    "            max_intensity = max(max_intensity, np.max(np.abs(data.numpy())))  # Update max intensity\n",
    "\n",
    "        # Add a colorbar below all the plots\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"bottom\", size=\"5%\", pad=0.5)\n",
    "        cbar = plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "        cbar.set_label('Value')\n",
    "\n",
    "        # Normalize the color bar based on the maximum intensity across all plots\n",
    "        #cbar.set_clim(-max_intensity, max_intensity)\n",
    "\n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = 2\n",
    "hidden_size1 = 4\n",
    "hidden_size2 = 4\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the PyTorch model\n",
    "model = SimpleNN(input_size, hidden_size1, hidden_size2, output_size)\n",
    "\n",
    "# Call the plot_weights method\n",
    "model.plot_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c597434c-a599-4385-b04e-b8b0fb823d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def visualize_difference(self, original, new, layer_name):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        # Plot weights\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f'{layer_name} Weights')\n",
    "        plt.imshow(original, cmap='viridis')\n",
    "        plt.colorbar(label='Weight Values')\n",
    "        plt.xlabel('Neurons in Previous Layer')\n",
    "        plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(f'Difference in {layer_name} Weights')\n",
    "        plt.imshow(new - original, cmap='coolwarm')\n",
    "        plt.colorbar(label='Weight Difference')\n",
    "        plt.xlabel('Neurons in Previous Layer')\n",
    "        plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572688d-29c9-4dec-9758-50c715c9fec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a10a8f-101c-467b-a329-3236684a38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize the weights and biases\n",
    "def visualize_difference(original, new, layer_name):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Plot weights\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f'{layer_name} Weights')\n",
    "    plt.imshow(original, cmap='viridis')\n",
    "    plt.colorbar(label='Weight Values')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f'Difference in {layer_name} Weights')\n",
    "    plt.imshow(new - original, cmap='coolwarm')\n",
    "    plt.colorbar(label='Weight Difference')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to create a model with specified initialization\n",
    "def create_model(input_size, hidden_layers, output_size, initialization='he'):\n",
    "    model = nn.Sequential()\n",
    "    \n",
    "    # Add input layer\n",
    "    model.add_module('input_layer', nn.Linear(input_size, hidden_layers[0]))\n",
    "    if initialization == 'he':\n",
    "        init.kaiming_uniform_(model.input_layer.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "        init.zeros_(model.input_layer.bias.data)\n",
    "\n",
    "    # Add hidden layers\n",
    "    for i in range(len(hidden_layers) - 1):\n",
    "        layer = nn.Linear(hidden_layers[i], hidden_layers[i + 1])\n",
    "        model.add_module(f'hidden_layer{i + 1}', layer)\n",
    "        if initialization == 'he':\n",
    "            init.kaiming_uniform_(layer.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "            init.zeros_(layer.bias.data)\n",
    "\n",
    "    # Add output layer\n",
    "    model.add_module('output_layer', nn.Linear(hidden_layers[-1], output_size))\n",
    "    if initialization == 'he':\n",
    "        init.kaiming_uniform_(model.output_layer.weight.data, mode='fan_in', nonlinearity='linear')\n",
    "        init.zeros_(model.output_layer.bias.data)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Step 1: Create the original model\n",
    "original_input_size = 2\n",
    "original_hidden_layers = [8, 8]\n",
    "original_output_size = 1\n",
    "original_model = create_model(original_input_size, original_hidden_layers, original_output_size, initialization='he')\n",
    "\n",
    "# Step 2: Visualize the weights and biases of the original model\n",
    "for layer_name, original_weight in original_model.named_parameters():\n",
    "    visualize_difference(original_weight.detach().numpy(), original_weight.detach().numpy(), layer_name)\n",
    "\n",
    "# Step 3: Create the extended model with 16 neurons in hidden layers\n",
    "extended_input_size = 2\n",
    "extended_hidden_layers = [16, 16]\n",
    "extended_output_size = 1\n",
    "extended_model = create_model(extended_input_size, extended_hidden_layers, extended_output_size, initialization='he')\n",
    "\n",
    "# Step 4: Visualize the weights and biases of the extended model\n",
    "for layer_name, extended_weight in extended_model.named_parameters():\n",
    "    visualize_difference(extended_weight.detach().numpy(), extended_weight.detach().numpy(), layer_name)\n",
    "\n",
    "# Step 5: Overwrite the weights and biases of the extended model with the original model\n",
    "for original_param, extended_param in zip(original_model.parameters(), extended_model.parameters()):\n",
    "    extended_param.data.copy_(original_param.data)\n",
    "\n",
    "# Step 6: Visualize the weights and biases of the extended model after overwriting\n",
    "for layer_name, extended_weight in extended_model.named_parameters():\n",
    "    visualize_difference(original_weight.detach().numpy(), extended_weight.detach().numpy(), layer_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b3a93-0bbd-4f43-a9d2-b560f9cab46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple fully connected neural network\n",
    "class MyFCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyFCNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)  # Example: input size=10, output size=5\n",
    "        self.fc2 = nn.Linear(4, 1)   # Example: input size=5, output size=2\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "model = MyFCNet()\n",
    "\n",
    "# Get the state_dict of the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "# Extract weights and biases from the state_dict\n",
    "for key, value in state_dict.items():\n",
    "    if 'weight' in key:\n",
    "        print(f\"Layer: {key}, Shape: {value.shape}\")\n",
    "        print(\"Weights:\")\n",
    "        print(value)\n",
    "    elif 'bias' in key:\n",
    "        print(f\"Layer: {key}, Shape: {value.shape}\")\n",
    "        print(\"Biases:\")\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee472dbf-d387-426f-8942-802ecdae1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor with shape (4,)\n",
    "tensor = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "# Transform the tensor to shape (4, 1)\n",
    "tensor_reshaped = tensor.unsqueeze(0)\n",
    "\n",
    "print(\"Original tensor shape:\", tensor.shape)\n",
    "print(\"Transformed tensor shape:\", tensor_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5880b-7921-4ad0-9cf9-ef7b703b96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple model using nn.Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "\n",
    "# Initialize some input data\n",
    "input_data = torch.randn(3, 10)\n",
    "\n",
    "# Forward pass through the model\n",
    "output = model(input_data)\n",
    "\n",
    "# Print the output\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff3d373-98fd-45e5-b52f-036ce297e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the model parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef18881-6a28-4ad2-967f-407273319db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7252d31-6e6d-4280-b553-f8ffe5029832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_sizes[0]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_sizes[i], hidden_size),\n",
    "                nn.ReLU()\n",
    "            ) for i, hidden_size in enumerate(hidden_sizes[1:])\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_size = 2\n",
    "hidden_sizes = [4, 8, 8, 4]\n",
    "output_size = 1\n",
    "\n",
    "model = SimpleModel(input_size, hidden_sizes, output_size)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da54a9ec-0513-4c65-a53c-73678ada7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932e9bb-3f85-4ee7-b67b-97b7035e0e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2d73c-3b29-4cb5-a6d2-4839ef00060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example weight matrix (2x3) and bias vector (2,)\n",
    "W = torch.randn(2, 3)\n",
    "x = torch.randn(3)\n",
    "b = torch.randn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea815ca-818c-4400-88b9-06f40a0fb0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5c51ec-fe88-4440-a80e-6481fda30610",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbd9c8-b29c-4516-819d-2a6ea91f3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff30b63-ecd2-4d50-b67d-894bf4552da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform matrix multiplication\n",
    "result = torch.matmul(W, x)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871d93a-aadf-4e56-800c-bc19857a2319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add bias vector element-wise to each row of the result\n",
    "result_with_bias = result + b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b012fff-da02-4693-be63-9f492aa77dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result with bias:\", result_with_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594b1e5-52f7-410a-8ef9-80495b5c2433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db9d4e-0776-4a88-8923-056cdd4226ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8247e4-9b73-4686-8014-3e763b485550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture of the original network\n",
    "original_input_size = 2\n",
    "original_hidden_layers = [8, 8]\n",
    "original_output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8380b3-6539-4a36-bdb6-c6de593e4233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the original model with Xavier initialization\n",
    "class OriginalModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(OriginalModel, self).__init__()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layers[0])\n",
    "        init.xavier_uniform_(self.input_layer.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        init.zeros_(self.input_layer.bias.data)\n",
    "        \n",
    "        # Hidden layers with Xavier initialization\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers)-1)\n",
    "        ])\n",
    "        for layer in self.hidden_layers:\n",
    "            init.xavier_uniform_(layer.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "            init.zeros_(layer.bias.data)\n",
    "        \n",
    "        # Output layer with Xavier initialization\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "        init.xavier_uniform_(self.output_layer.weight.data, gain=nn.init.calculate_gain('linear'))\n",
    "        init.zeros_(self.output_layer.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4ade0-d2a1-4ea8-96cf-cf26a48c74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create an instance of the original model\n",
    "original_model = OriginalModel(original_input_size, original_hidden_layers, original_output_size)\n",
    "\n",
    "# Define the architecture of the new network with increased neurons\n",
    "new_input_size = 2\n",
    "new_hidden_layers = [16, 16]  # Increase the number of neurons\n",
    "new_output_size = 1\n",
    "\n",
    "# Create a new model with the same architecture as the original one\n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size):\n",
    "        super(NewModel, self).__init__()\n",
    "        \n",
    "        # Input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layers[0])\n",
    "        \n",
    "        # Hidden layers with weights and biases from the original model\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_layers[i], hidden_layers[i+1]) for i in range(len(hidden_layers)-1)\n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the new model\n",
    "new_model = NewModel(new_input_size, new_hidden_layers, new_output_size)\n",
    "\n",
    "# Set the weights from the original model using He initialization\n",
    "def initialize_weights_he(model):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            init.kaiming_uniform_(layer.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "            init.zeros_(layer.bias.data)\n",
    "\n",
    "# Initialize weights of the new model using He initialization\n",
    "initialize_weights_he(new_model)\n",
    "\n",
    "# Visualize the differences in weights and biases\n",
    "def visualize_difference(original, new, layer_name):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Plot weights\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(f'{layer_name} Weights')\n",
    "    plt.imshow(original, cmap='viridis')\n",
    "    plt.colorbar(label='Weight Values')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(f'Difference in {layer_name} Weights')\n",
    "    plt.imshow(new - original, cmap='coolwarm')\n",
    "    plt.colorbar(label='Weight Difference')\n",
    "    plt.xlabel('Neurons in Previous Layer')\n",
    "    plt.ylabel('Neurons in Current Layer')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize differences for each layer\n",
    "for layer_name, original_weight in original_model.state_dict().items():\n",
    "    new_weight = new_model.state_dict()[layer_name]\n",
    "    visualize_difference(original_weight, new_weight, layer_name)\n",
    "\n",
    "# Visualize differences for biases\n",
    "for layer_name, original_bias in original_model.state_dict().items():\n",
    "    if 'bias' in layer_name:\n",
    "        new_bias = new_model.state_dict()[layer_name]\n",
    "        visualize_difference(original_bias.unsqueeze(0), new_bias.unsqueeze(0), layer_name + ' Bias')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afdd9b6-a055-431c-8591-16a4c9a946a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def find_max_min_values(state_dict):\n",
    "    max_value = float('-inf')\n",
    "    min_value = float('inf')\n",
    "\n",
    "    for key, tensor in state_dict.items():\n",
    "        if isinstance(tensor, torch.Tensor):\n",
    "            if tensor.dim() == 0:\n",
    "                tensor_max = tensor.item()\n",
    "                tensor_min = tensor.item()\n",
    "            else:\n",
    "                tensor_max = torch.max(tensor).item()\n",
    "                tensor_min = torch.min(tensor).item()\n",
    "            max_value = max(max_value, tensor_max)\n",
    "            min_value = min(min_value, tensor_min)\n",
    "\n",
    "    return max_value, min_value\n",
    "\n",
    "# Example usage\n",
    "model = YourModel()  # Instantiate your model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "max_value, min_value = find_max_min_values(state_dict)\n",
    "print(\"Max value:\", max_value)\n",
    "print(\"Min value:\", min_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316ffe9-fd28-403d-ad7b-dbecfbf5f61e",
   "metadata": {},
   "source": [
    "# AS II Old versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1003e-bf5a-4777-9cf5-d3d4b1e35741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT = 2, hidden_layers = [4], N_OUTPUT = 1,  activation='Tanh', initialization='Xavier'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_functions = nn.ModuleDict([\n",
    "            [\"Tanh\", nn.Tanh()],\n",
    "            [\"ReLU\", nn.ReLU()],\n",
    "            [\"LeakyReLU\", nn.LeakyReLU()],\n",
    "            [\"Sigmoid\", nn.Sigmoid()],\n",
    "            [\"Softmax\", nn.Softmax(dim=-1)],\n",
    "        ])\n",
    "\n",
    "        if activation not in self.activation_functions:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.activation = self.activation_functions[activation]\n",
    "\n",
    "        #self.fci = nn.Sequential(\n",
    "        #    nn.Linear(N_INPUT, hidden_layers[0]),\n",
    "        #    self.activation\n",
    "        #)\n",
    "        self.fci = nn.Linear(N_INPUT, hidden_layers[0])\n",
    "\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_layers[i], hidden_layers[i + 1]),\n",
    "                self.activation\n",
    "            ) for i in range(len(hidden_layers) - 1)\n",
    "        ])\n",
    "\n",
    "        self.fco = nn.Linear(hidden_layers[-1], N_OUTPUT)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fci(x))\n",
    "        for layer in self.fch:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "    \n",
    "    def initialize_parameters(self, initialization):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if initialization == 'Uniform':\n",
    "                    init.uniform_(module.weight.data, -0.1, 0.1)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Normal':\n",
    "                    init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Xavier':\n",
    "                    init.xavier_uniform_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'He':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Orthogonal':\n",
    "                    init.orthogonal_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Kaiming':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported initialization type\")\n",
    "\n",
    "    def plot_weights(self, figsize = (10,5)):\n",
    "        self.figsize = figsize\n",
    "        weights_biases_dict = self.state_dict()\n",
    "        #weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Definition of columns, rows and subplots\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols - 1) // num_cols  \n",
    "        \n",
    "        # For colorbar (collect minimum and maximum values across all tensors)\n",
    "        all_values = np.concatenate([tensor.flatten() for tensor in weights_biases_dict.values()])\n",
    "        min_val = round(all_values.min(), 2)\n",
    "        max_val = round(all_values.max(), 2)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize = self.figsize)\n",
    "        \n",
    "        # Plot images and add values in each subplot\n",
    "        for i, (key, tensor) in enumerate(weights_biases_dict.items()):\n",
    "            row = i // num_cols\n",
    "            col = i % num_cols\n",
    "            ax = axs[row, col]\n",
    "            if 'weight' in key:\n",
    "                im = ax.imshow(tensor, cmap='viridis',vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            elif 'bias' in key:\n",
    "                im = ax.imshow(tensor.unsqueeze(0), cmap='viridis', vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            #ax.axis('off')\n",
    "            \n",
    "            # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "            if len(tensor.shape) == 1:\n",
    "                tensor = tensor.reshape(1, -1)\n",
    "\n",
    "            # Add xticks and yticks\n",
    "            ax.set_xticks(np.arange(0, tensor.shape[1] , step=1))  \n",
    "            ax.tick_params(axis='x', labelsize = 8)\n",
    "            ax.set_yticks(np.arange(0, tensor.shape[0] , step=1))\n",
    "            ax.tick_params(axis='y', labelsize = 8)\n",
    "\n",
    "           \n",
    "            # Add values in the middle of the cell\n",
    "            for y in range(tensor.shape[0]):\n",
    "                for x in range(tensor.shape[1]):\n",
    "                    value = tensor[y, x]\n",
    "                    ax.text(x, y, f'{value:.2f}', fontsize = 8, color='white', ha='center', va='center')\n",
    "            \n",
    "         # Hide extra subplots\n",
    "        for i in range(num_subplots, num_rows * num_cols):\n",
    "            axs.flatten()[i].axis('off')\n",
    "            \n",
    "        # Add a title to the figure\n",
    "        plt.suptitle('Weights and Biases of the Neural Network')\n",
    "        \n",
    "        # Add a colorbar\n",
    "            # Set custom ticks and intervals\n",
    "        tick_interval = 0.2\n",
    "        ticks = np.arange(min_val, max_val, step=tick_interval)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.01])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', ticks = ticks)\n",
    "        cbar.set_label('Range of Weights and Biases') \n",
    "        \n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "# Step 1: Create the original model\n",
    "original_input_size = 2\n",
    "original_hidden_layers = [4,4]\n",
    "original_output_size = 1\n",
    "original_model = FCN(original_input_size, original_hidden_layers, original_output_size, activation='Tanh', initialization='Xavier')\n",
    "original_model.plot_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f043097-7e86-4887-a7c6-8ed63f1e8d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326f56d-362a-4349-af0c-c5c5ae09312a",
   "metadata": {},
   "source": [
    "## ASII: extended methods added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbe6533-4807-430b-b43b-0a9db3982b10",
   "metadata": {},
   "source": [
    "### BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636809c5-91a5-4df4-9d8b-93cb3ff1c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT = 2, hidden_layers = [4], N_OUTPUT = 1, activation='Tanh', initialization='Xavier'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_functions = nn.ModuleDict([\n",
    "            [\"Tanh\", nn.Tanh()],\n",
    "            [\"ReLU\", nn.ReLU()],\n",
    "            [\"LeakyReLU\", nn.LeakyReLU()],\n",
    "            [\"Sigmoid\", nn.Sigmoid()],\n",
    "            [\"Softmax\", nn.Softmax(dim=-1)],\n",
    "        ])\n",
    "\n",
    "        if activation not in self.activation_functions:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.activation = self.activation_functions[activation]\n",
    "\n",
    "        self.fci = nn.Linear(N_INPUT, hidden_layers[0])\n",
    "\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_layers[i], hidden_size),\n",
    "                self.activation\n",
    "            ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        ])\n",
    "\n",
    "        self.fco = nn.Linear(hidden_layers[-1], N_OUTPUT)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fci(x))\n",
    "        for layer in self.fch:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "        \n",
    "    def initialize_parameters(self, initialization):\n",
    "        \n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if initialization == 'Uniform':\n",
    "                    init.uniform_(module.weight.data, -0.1, 0.1)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Normal':\n",
    "                    init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Xavier':\n",
    "                    init.xavier_uniform_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'He':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Orthogonal':\n",
    "                    init.orthogonal_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Kaiming':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported initialization type\")\n",
    "\n",
    "    def plot_weights(self, figsize = (10,5)):\n",
    "        \n",
    "        self.figsize = figsize\n",
    "        \n",
    "        weights_biases_dict = self.state_dict()\n",
    "        #weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Definition of columns, rows and subplots\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols - 1) // num_cols  \n",
    "        \n",
    "        # For colorbar (collect minimum and maximum values across all tensors)\n",
    "        all_values = np.concatenate([tensor.flatten() for tensor in weights_biases_dict.values()])\n",
    "        min_val = round(all_values.min(), 2)\n",
    "        max_val = round(all_values.max(), 2)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize = self.figsize)\n",
    "        \n",
    "        # Plot images and add values in each subplot\n",
    "        for i, (key, tensor) in enumerate(weights_biases_dict.items()):\n",
    "            row = i // num_cols\n",
    "            col = i % num_cols\n",
    "            ax = axs[row, col]\n",
    "            if 'weight' in key:\n",
    "                im = ax.imshow(tensor, cmap='viridis',vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            elif 'bias' in key:\n",
    "                im = ax.imshow(tensor.unsqueeze(0), cmap='viridis', vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            #ax.axis('off')\n",
    "            \n",
    "            # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "            if len(tensor.shape) == 1:\n",
    "                tensor = tensor.reshape(1, -1)\n",
    "\n",
    "            # Add xticks and yticks\n",
    "            ax.set_xticks(np.arange(0, tensor.shape[1] , step=1))  \n",
    "            ax.tick_params(axis='x', labelsize = 8)\n",
    "            ax.set_yticks(np.arange(0, tensor.shape[0] , step=1))\n",
    "            ax.tick_params(axis='y', labelsize = 8)\n",
    "\n",
    "           \n",
    "            # Add values in the middle of the cell\n",
    "            for y in range(tensor.shape[0]):\n",
    "                for x in range(tensor.shape[1]):\n",
    "                    value = tensor[y, x]\n",
    "                    ax.text(x, y, f'{value:.2f}', fontsize = 8, color='white', ha='center', va='center')\n",
    "            \n",
    "         # Hide extra subplots\n",
    "        for i in range(num_subplots, num_rows * num_cols):\n",
    "            axs.flatten()[i].axis('off')\n",
    "            \n",
    "        # Add a title to the figure\n",
    "        plt.suptitle('Weights and Biases of the Neural Network')\n",
    "        \n",
    "        # Add a colorbar\n",
    "            # Set custom ticks and intervals\n",
    "        tick_interval = 0.2\n",
    "        ticks = np.arange(min_val, max_val, step=tick_interval)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.01])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', ticks = ticks)\n",
    "        cbar.set_label('Range of Weights and Biases') \n",
    "        \n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "class FCN_extended(FCN):\n",
    "    def __init__(self, N_INPUT, hidden_layers, N_OUTPUT, activation='Tanh', initialization='Xavier', original_model_path=None):\n",
    "        super().__init__(N_INPUT, hidden_layers, N_OUTPUT, activation, initialization)\n",
    "    \n",
    "        self.original_model_path = original_model_path\n",
    "        \n",
    "        self.load_override_original_weights_biases()\n",
    "\n",
    "    def load_override_original_weights_biases(self):\n",
    "        if self.original_model_path is None:\n",
    "            raise ValueError(\"Path to the original model checkpoint is not provided.\")\n",
    "\n",
    "        if not os.path.exists(self.original_model_path):\n",
    "            raise FileNotFoundError(f\"Provided path '{self.original_model_path}' does not exist.\")\n",
    "\n",
    "        if not os.path.isfile(self.original_model_path):\n",
    "            raise ValueError(f\"Provided path '{self.original_model_path}' is not a file.\")\n",
    "\n",
    "        _, ext = os.path.splitext(self.original_model_path)\n",
    "        if ext not in ['.pt', '.pth']:\n",
    "            raise ValueError(\"Provided file is not a valid checkpoint file.\")\n",
    "        \n",
    "        # Load weights and biases from original_model\n",
    "        original_state_dict = torch.load(self.original_model_path)['model_state_dict']\n",
    "        \n",
    "        # Update extended model state dictionary with original model's parameters\n",
    "        self.load_state_dict(original_state_dict, strict=False)\n",
    "        \n",
    "        # Override weights and biases from original model\n",
    "        for name, param in self.named_parameters():\n",
    "            #print(f\"name: {name}, param: {param}\")\n",
    "            if name in original_state_dict:\n",
    "                param.data.copy_(original_state_dict[name].data)\n",
    "\n",
    "    def extend_hidden_layers(self, num_hidden_layers):\n",
    "        current_hidden_layers = len(self.fch)\n",
    "        if current_hidden_layers > num_hidden_layers:\n",
    "            raise ValueError(\"Cannot reduce the number of hidden layers.\")\n",
    "\n",
    "        for _ in range(num_hidden_layers - current_hidden_layers):\n",
    "            new_layer = nn.Sequential(\n",
    "                nn.Linear(self.hidden_layers[-1], self.hidden_layers[-1]),\n",
    "                self.activation)\n",
    "\n",
    "            self.fch.append(new_layer)\n",
    "\n",
    "    def extend_neurons(self, num_neurons):\n",
    "        if len(self.fch) == 0:\n",
    "            raise ValueError(\"Cannot extend neurons with no hidden layers.\")\n",
    "\n",
    "        for layer in self.fch:\n",
    "            current_neurons = layer[0].in_features\n",
    "            if current_neurons < num_neurons:\n",
    "                new_weights = torch.cat([layer[0].weight.data, torch.randn(num_neurons - current_neurons, current_neurons)], dim=0)\n",
    "                new_biases = torch.cat([layer[0].bias.data, torch.zeros(num_neurons - current_neurons)], dim=0)\n",
    "                layer[0].weight.data = new_weights\n",
    "                layer[0].bias.data = new_biases\n",
    "            elif current_neurons > num_neurons:\n",
    "                layer[0].weight.data = layer[0].weight.data[:num_neurons, :]\n",
    "                layer[0].bias.data = layer[0].bias.data[:num_neurons]\n",
    "\n",
    "class TrainModel:\n",
    "    def __init__(self, model, num_epochs, save_interval, loss_threshold=None):\n",
    "        self.model = model\n",
    "        self.num_epochs = num_epochs\n",
    "        self.save_interval = save_interval\n",
    "        self.loss_threshold = loss_threshold\n",
    "\n",
    "    def train(self):\n",
    "        optimizer = optim.Adam(self.model.parameters())\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            # Train the model\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = self.model(torch.randn(10, original_input_size))\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, torch.randn(10, original_output_size))\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save model checkpoint\n",
    "            if epoch % self.save_interval == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss\n",
    "                }, f\"original_model_{epoch}.pt\")\n",
    "\n",
    "            # Check loss threshold\n",
    "            if self.loss_threshold is not None and loss.item() < self.loss_threshold:\n",
    "                print(f\"Loss threshold reached at epoch {epoch}. Stopping training.\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94c7c03-1e5f-4596-a754-ff86eac07be0",
   "metadata": {},
   "source": [
    "### Updating the FCN_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8113b5f-0306-4ef7-b059-e8f34d192cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BACKUP:\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT = 2, hidden_layers = [4], N_OUTPUT = 1, activation='Tanh', initialization='Xavier'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_functions = nn.ModuleDict([\n",
    "            [\"Tanh\", nn.Tanh()],\n",
    "            [\"ReLU\", nn.ReLU()],\n",
    "            [\"LeakyReLU\", nn.LeakyReLU()],\n",
    "            [\"Sigmoid\", nn.Sigmoid()],\n",
    "            [\"Softmax\", nn.Softmax(dim=-1)],\n",
    "        ])\n",
    "\n",
    "        if activation not in self.activation_functions:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.activation = self.activation_functions[activation]\n",
    "\n",
    "        # self.fci = nn.Linear(N_INPUT, hidden_layers[0])\n",
    "\n",
    "        # self.fch = nn.ModuleList([\n",
    "        #     nn.Sequential(\n",
    "        #         nn.Linear(hidden_layers[i], hidden_size),\n",
    "        #         self.activation\n",
    "        #     ) for i, hidden_size in enumerate(hidden_layers[1:])    # ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        # ])\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(N_INPUT if i == 0 else hidden_sizes[i-1], hidden_size),\n",
    "                self.activation\n",
    "            ) for i, hidden_size in enumerate(hidden_layers[:])    # ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        ])\n",
    "\n",
    "        self.fco = nn.Linear(hidden_layers[-1], N_OUTPUT)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.activation(self.fci(x))\n",
    "        for layer in self.fch:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "    def initialize_parameters(self, initialization):\n",
    "        \n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if initialization == 'Uniform':\n",
    "                    init.uniform_(module.weight.data, -0.1, 0.1)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Normal':\n",
    "                    init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Xavier':\n",
    "                    init.xavier_uniform_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'He':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Orthogonal':\n",
    "                    init.orthogonal_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Kaiming':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported initialization type\")\n",
    "    \n",
    "    def plot_weights(self, figsize = (10,5)):\n",
    "        \n",
    "        self.figsize = figsize\n",
    "        \n",
    "        weights_biases_dict = self.state_dict()\n",
    "        #weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Definition of columns, rows and subplots\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols - 1) // num_cols  \n",
    "        \n",
    "        # For colorbar (collect minimum and maximum values across all tensors)\n",
    "        all_values = np.concatenate([tensor.flatten() for tensor in weights_biases_dict.values()])\n",
    "        min_val = round(all_values.min(), 2)\n",
    "        max_val = round(all_values.max(), 2)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize = self.figsize)\n",
    "        \n",
    "        # Plot images and add values in each subplot\n",
    "        for i, (key, tensor) in enumerate(weights_biases_dict.items()):\n",
    "            row = i // num_cols\n",
    "            col = i % num_cols\n",
    "            ax = axs[row, col]\n",
    "            if 'weight' in key:\n",
    "                im = ax.imshow(tensor, cmap='viridis',vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            elif 'bias' in key:\n",
    "                im = ax.imshow(tensor.unsqueeze(0), cmap='viridis', vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            #ax.axis('off')\n",
    "            \n",
    "            # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "            if len(tensor.shape) == 1:\n",
    "                tensor = tensor.reshape(1, -1)\n",
    "\n",
    "            # Add xticks and yticks\n",
    "            ax.set_xticks(np.arange(0, tensor.shape[1] , step=1))  \n",
    "            ax.tick_params(axis='x', labelsize = 8)\n",
    "            ax.set_yticks(np.arange(0, tensor.shape[0] , step=1))\n",
    "            ax.tick_params(axis='y', labelsize = 8)\n",
    "\n",
    "           \n",
    "            # Add values in the middle of the cell\n",
    "            for y in range(tensor.shape[0]):\n",
    "                for x in range(tensor.shape[1]):\n",
    "                    value = tensor[y, x]\n",
    "                    ax.text(x, y, f'{value:.2f}', fontsize = 8, color='white', ha='center', va='center')\n",
    "            \n",
    "         # Hide extra subplots\n",
    "        for i in range(num_subplots, num_rows * num_cols):\n",
    "            axs.flatten()[i].axis('off')\n",
    "            \n",
    "        # Add a title to the figure\n",
    "        plt.suptitle('Weights and Biases of the Neural Network')\n",
    "        \n",
    "        # Add a colorbar\n",
    "            # Set custom ticks and intervals\n",
    "        tick_interval = 0.2\n",
    "        ticks = np.arange(min_val, max_val, step=tick_interval)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.01])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', ticks = ticks)\n",
    "        cbar.set_label('Range of Weights and Biases') \n",
    "        \n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "class FCN_extended(FCN):\n",
    "    def __init__(self, N_INPUT, hidden_layers, N_OUTPUT, activation='Tanh', initialization='Xavier', original_model_path=None):\n",
    "        super().__init__(N_INPUT, hidden_layers, N_OUTPUT, activation, initialization)\n",
    "    \n",
    "        self.original_model_path = original_model_path\n",
    "        self.original_neurons =  self.fch[0]0].in_features # assuming that all hidden layers have the same number of neurons \n",
    "        print(f\"Original_neurons in __init__: {self.original_neurons}\")      \n",
    "        self.extended_neurons = hidden_layers[-1] # assuming that all hidden layers have the same number of neurons \n",
    "        print(f\"extended_neurons: {self.extended_neurons}\")\n",
    "        # Check if hidden layers need to be extended\n",
    "        if len(hidden_layers) < len(self.fch): \n",
    "            raise ValueError(\"The number of hidden layers of the extended model must be larger as the original model\")\n",
    "        elif len(hidden_layers) > len(self.fch):\n",
    "            #self.extend_hidden_layers(len(hidden_layers))\n",
    "            self.load_override_original_weights_biases()\n",
    "        else:\n",
    "            self.extend_neurons() \n",
    "            \n",
    "    def load_override_original_weights_biases(self):\n",
    "        if self.original_model_path is None:\n",
    "            raise ValueError(\"Path to the original model checkpoint is not provided.\")\n",
    "\n",
    "        if not os.path.exists(self.original_model_path):\n",
    "            raise FileNotFoundError(f\"Provided path '{self.original_model_path}' does not exist.\")\n",
    "\n",
    "        if not os.path.isfile(self.original_model_path):\n",
    "            raise ValueError(f\"Provided path '{self.original_model_path}' is not a file.\")\n",
    "\n",
    "        _, ext = os.path.splitext(self.original_model_path)\n",
    "        if ext not in ['.pt', '.pth']:\n",
    "            raise ValueError(\"Provided file is not a valid checkpoint file.\")\n",
    "        \n",
    "        # Load weights and biases from original_model\n",
    "        original_state_dict = torch.load(self.original_model_path)['model_state_dict']\n",
    "        \n",
    "        # Update extended model state dictionary with original model's parameters\n",
    "        self.load_state_dict(original_state_dict, strict=False)\n",
    "        \n",
    "        # Override weights and biases from original model\n",
    "        for name, param in self.named_parameters():\n",
    "            if name in original_state_dict:\n",
    "                param.data.copy_(original_state_dict[name].data)\n",
    "\n",
    "    def extend_hidden_layers(self, num_hidden_layers):\n",
    "        current_hidden_layers = len(self.fch)\n",
    "        if current_hidden_layers > num_hidden_layers:\n",
    "            raise ValueError(\"Cannot reduce the number of hidden layers.\")\n",
    "\n",
    "        for _ in range(num_hidden_layers - current_hidden_layers):\n",
    "            new_layer = nn.Sequential(\n",
    "                nn.Linear(self.hidden_layers[-1], self.hidden_layers[-1]),\n",
    "                self.activation)\n",
    "\n",
    "            self.fch.append(new_layer)\n",
    "\n",
    "    def extend_neurons(self):\n",
    "        if len(self.fch) == 0:\n",
    "            raise ValueError(\"Cannot extend neurons with no hidden layers.\")\n",
    "\n",
    "        for layer in self.fch:\n",
    "            original_neurons = layer[0].weight.size(0)\n",
    "            print(f\"Original_neurons: {original_neurons}\")\n",
    "            print(f\"Original neurons in layer {layer[0]} extend_neurons: {original_neurons}\")\n",
    "            # if original_neurons < self.extended_neurons:\n",
    "            #     # Extend weights using the provided initialization\n",
    "            #     init_fn = getattr(init, self.initialization)      # getattr( use to access dynamically the attributes or methods of an object based on a string name )\n",
    "            #     new_weights = init_fn(layer[0].weight.new_empty(self.extended_neurons - original_neurons, original_neurons))\n",
    "            #     new_biases = init.constant_(layer[0].bias.new_empty(self.extended_neurons - original_neurons), 0)\n",
    "            #     layer[0].weight.data = torch.cat([layer[0].weight.data, new_weights], dim=0)\n",
    "            #     layer[0].bias.data = torch.cat([layer[0].bias.data, new_biases], dim=0)\n",
    "            # else:\n",
    "            #     raise ValueError(\"Maintaining or reducing the number of neurons is not allowed\")\n",
    "class TrainModel:\n",
    "    def __init__(self, model, num_epochs, save_interval, loss_threshold=None):\n",
    "        self.model = model\n",
    "        self.num_epochs = num_epochs\n",
    "        self.save_interval = save_interval\n",
    "        self.loss_threshold = loss_threshold\n",
    "\n",
    "    def train(self):\n",
    "        optimizer = optim.Adam(self.model.parameters())\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            # Train the model\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = self.model(torch.randn(10, original_input_size))\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, torch.randn(10, original_output_size))\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save model checkpoint\n",
    "            if epoch % self.save_interval == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss\n",
    "                }, f\"original_model_{epoch}.pt\")\n",
    "\n",
    "            # Check loss threshold\n",
    "            if self.loss_threshold is not None and loss.item() < self.loss_threshold:\n",
    "                print(f\"Loss threshold reached at epoch {epoch}. Stopping training.\")\n",
    "                break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc03e1f4-6aaf-4a37-aacf-f35d923a968e",
   "metadata": {},
   "source": [
    "## New version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b3653-531a-41ca-9cbf-f25779eaf9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT = 2, hidden_layers = [4], N_OUTPUT = 1, activation='Tanh', initialization='Xavier'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_functions = nn.ModuleDict([\n",
    "            [\"Tanh\", nn.Tanh()],\n",
    "            [\"ReLU\", nn.ReLU()],\n",
    "            [\"LeakyReLU\", nn.LeakyReLU()],\n",
    "            [\"Sigmoid\", nn.Sigmoid()],\n",
    "            [\"Softmax\", nn.Softmax(dim=-1)],\n",
    "        ])\n",
    "\n",
    "        if activation not in self.activation_functions:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.activation = self.activation_functions[activation]\n",
    "\n",
    "        # self.fci = nn.Linear(N_INPUT, hidden_layers[0])\n",
    "\n",
    "        # self.fch = nn.ModuleList([\n",
    "        #     nn.Sequential(\n",
    "        #         nn.Linear(hidden_layers[i], hidden_size),\n",
    "        #         self.activation\n",
    "        #     ) for i, hidden_size in enumerate(hidden_layers[1:])    # ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        # ])\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(N_INPUT if i == 0 else hidden_size, hidden_size),\n",
    "                self.activation\n",
    "            ) for i, hidden_size in enumerate(hidden_layers[:])    # ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        ])\n",
    "\n",
    "        self.fco = nn.Linear(hidden_layers[-1], N_OUTPUT)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.activation(self.fci(x))\n",
    "        for layer in self.fch:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "    def initialize_parameters(self, initialization):\n",
    "        \n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if initialization == 'Uniform':\n",
    "                    init.uniform_(module.weight.data, -0.1, 0.1)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Normal':\n",
    "                    init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Xavier':\n",
    "                    init.xavier_uniform_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'He':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Orthogonal':\n",
    "                    init.orthogonal_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Kaiming':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported initialization type\")\n",
    "    \n",
    "    def plot_weights(self, figsize = (10,5)):\n",
    "        \n",
    "        self.figsize = figsize\n",
    "        \n",
    "        weights_biases_dict = self.state_dict()\n",
    "        #weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Definition of columns, rows and subplots\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols - 1) // num_cols  \n",
    "        \n",
    "        # For colorbar (collect minimum and maximum values across all tensors)\n",
    "        all_values = np.concatenate([tensor.flatten() for tensor in weights_biases_dict.values()])\n",
    "        min_val = round(all_values.min(), 2)\n",
    "        max_val = round(all_values.max(), 2)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize = self.figsize)\n",
    "        \n",
    "        # Plot images and add values in each subplot\n",
    "        for i, (key, tensor) in enumerate(weights_biases_dict.items()):\n",
    "            row = i // num_cols\n",
    "            col = i % num_cols\n",
    "            ax = axs[row, col]\n",
    "            if 'weight' in key:\n",
    "                im = ax.imshow(tensor, cmap='viridis',vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            elif 'bias' in key:\n",
    "                im = ax.imshow(tensor.unsqueeze(0), cmap='viridis', vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            #ax.axis('off')\n",
    "            \n",
    "            # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "            if len(tensor.shape) == 1:\n",
    "                tensor = tensor.reshape(1, -1)\n",
    "\n",
    "            # Add xticks and yticks\n",
    "            ax.set_xticks(np.arange(0, tensor.shape[1] , step=1))  \n",
    "            ax.tick_params(axis='x', labelsize = 8)\n",
    "            ax.set_yticks(np.arange(0, tensor.shape[0] , step=1))\n",
    "            ax.tick_params(axis='y', labelsize = 8)\n",
    "\n",
    "           \n",
    "            # Add values in the middle of the cell\n",
    "            for y in range(tensor.shape[0]):\n",
    "                for x in range(tensor.shape[1]):\n",
    "                    value = tensor[y, x]\n",
    "                    ax.text(x, y, f'{value:.2f}', fontsize = 8, color='white', ha='center', va='center')\n",
    "            \n",
    "         # Hide extra subplots\n",
    "        for i in range(num_subplots, num_rows * num_cols):\n",
    "            axs.flatten()[i].axis('off')\n",
    "            \n",
    "        # Add a title to the figure\n",
    "        plt.suptitle('Weights and Biases of the Neural Network')\n",
    "        \n",
    "        # Add a colorbar\n",
    "            # Set custom ticks and intervals\n",
    "        tick_interval = 0.2\n",
    "        ticks = np.arange(min_val, max_val, step=tick_interval)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.01])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', ticks = ticks)\n",
    "        cbar.set_label('Range of Weights and Biases') \n",
    "        \n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "class FCN_extended(FCN):\n",
    "    def __init__(self, N_INPUT, hidden_layers, N_OUTPUT, activation='Tanh', initialization='Xavier', original_model_path=None):\n",
    "        super().__init__(N_INPUT, hidden_layers, N_OUTPUT, activation, initialization)\n",
    "    \n",
    "        self.original_model_path = original_model_path\n",
    "        self.original_state_dict = self.load_original_state_dict()\n",
    "        self.original_state_dict_keys = list(self.original_state_dict.keys()) \n",
    "        self.original_hidden_layers_neurons = self.original_state_dict[self.original_state_dict_keys[-4]].size(0)\n",
    "        self.original_hidden_layers_keys = [key for key in self.original_state_dict_keys if \"fch\" in key and \"weight\" in key]\n",
    "        self.original_hidden_layers_num = len(set([key.split('.')[-1] for key in self.original_hidden_layers_keys]))\n",
    "\n",
    "        self.extended_neurons = hidden_layers[-1] # assuming that all hidden layers have the same number of neurons\n",
    "        #print(self.original_state_dict_keys)\n",
    "        #print(self.original_hidden_layers_keys)\n",
    "        #print(len(hidden_layers))\n",
    "        #print(self.original_hidden_layers_num)\n",
    "        # len(set([key.split('.')[1] for key in hidden_layers_keys]))\n",
    "        \n",
    "        # Check if hidden layers need to be extended\n",
    "        if len(hidden_layers) < self.original_hidden_layers_num: \n",
    "            raise ValueError(f\"The number of hidden layers of the extended model({len(hidden_layers)}) must be larger as from the original model({self.original_hidden_layers_num})\")\n",
    "        elif len(hidden_layers) > self.original_hidden_layers_num:\n",
    "            self.extend_hidden_layers()\n",
    "        else:\n",
    "            self.extend_neurons() \n",
    "            \n",
    "    def load_original_state_dict(self):\n",
    "        if self.original_model_path is None:\n",
    "            raise ValueError(\"Path to the original model checkpoint is not provided.\")\n",
    "\n",
    "        if not os.path.exists(self.original_model_path):\n",
    "            raise FileNotFoundError(f\"Provided path '{self.original_model_path}' does not exist.\")\n",
    "\n",
    "        if not os.path.isfile(self.original_model_path):\n",
    "            raise ValueError(f\"Provided path '{self.original_model_path}' is not a file.\")\n",
    "\n",
    "        _, ext = os.path.splitext(self.original_model_path)\n",
    "        if ext not in ['.pt', '.pth']:\n",
    "            raise ValueError(\"Provided file is not a valid checkpoint file.\")\n",
    "        \n",
    "        # Load weights and biases from original_model\n",
    "        return torch.load(self.original_model_path)['model_state_dict']\n",
    "\n",
    "    def extend_hidden_layers(self):        \n",
    "        # Update extended model state dictionary with original model's parameters\n",
    "        self.load_state_dict(self.original_state_dict, strict=False)\n",
    "        \n",
    "        # Transfer weights and biases from original model to extended model\n",
    "        for name, param in self.named_parameters():\n",
    "            if name in self.original_state_dict:\n",
    "                param.data.copy_(self.original_state_dict[name].data)\n",
    "\n",
    "    def extend_hidden_layers_old(self, num_hidden_layers):\n",
    "        current_hidden_layers = len(self.fch)\n",
    "        if current_hidden_layers > num_hidden_layers:\n",
    "            raise ValueError(\"Cannot reduce the number of hidden layers.\")\n",
    "\n",
    "        for _ in range(num_hidden_layers - current_hidden_layers):\n",
    "            new_layer = nn.Sequential(\n",
    "                nn.Linear(self.hidden_layers[-1], self.hidden_layers[-1]),\n",
    "                self.activation)\n",
    "\n",
    "            self.fch.append(new_layer)\n",
    "\n",
    "    def extend_neurons(self):\n",
    "        if len(self.fch) == 0:\n",
    "            raise ValueError(\"Cannot extend neurons with no hidden layers.\")\n",
    "\n",
    "        for ((name, param)) in zip(self.named_parameters(), self.original_state_dict.items()):\n",
    "            print(f\"Current model - {name}: shape {param.shape}\")\n",
    "            print(f\"Old model - {name}: shape {param.shape}\")\n",
    "        # for  ((),())layer_extended, layer_original in zip(self.fch, :\n",
    "        #     #original_neurons = layer[0].weight.size(0)\n",
    "        #     #print(f\"Original_neurons: {original_neurons}\")\n",
    "        #     #print(f\"Original neurons in layer {layer[0]} extend_neurons: {original_neurons}\")\n",
    "        #     if self.original_hidden_layers_neurons < self.extended_neurons:\n",
    "        #         # self.initialize_parameters(self.initialization)\n",
    "        #         # # Extend weights using the provided initialization\n",
    "        #         # init_fn = getattr(init, self.initialization)      # getattr( use to access dynamically the attributes or methods of an object based on a string name )\n",
    "        #         # new_weights = init_fn(layer[0].weight.new_empty(self.extended_neurons - self.original_neurons_hidden_layers, self.original_neurons_hidden_layers))\n",
    "        #         # new_biases = init.constant_(layer[0].bias.new_empty(self.extended_neurons - self.original_neurons_hidden_layers), 0)\n",
    "        #         # layer[0].weight.data = torch.cat([layer[0].weight.data, new_weights], dim=0)\n",
    "        #         # layer[0].bias.data = torch.cat([layer[0].bias.data, new_biases], dim=0)\n",
    "        #         # Initialize new weights for additional neurons\n",
    "        #         #print(self.fch.keys())\n",
    "        #         print(layer[0].weight)\n",
    "        #         new_weights = torch.cat([layer[0].weight, layer[0].weight.data.new_empty(self.extended_neurons - self.original_hidden_layers_neurons, self.original_hidden_layers_neurons)], dim=0)\n",
    "\n",
    "        #         #new_weights = torch.cat([layer[0].weight.data, layer[0].weight.data.new_empty(self.extended_neurons - self.original_hidden_layers_neurons, self.original_hidden_layers_neurons)], dim=0)\n",
    "        #         #new_biases = torch.cat([layer[0].bias.data, layer[0].bias.data.new_empty(self.extended_neurons - self.original_hidden_layers_neurons)], dim=0)\n",
    "        #         # Update the layer's weights and biases\n",
    "        #         #layer[0].weight.data = new_weights\n",
    "        #         #layer[0].bias.data = new_biases\n",
    "        #     else:\n",
    "        #         raise ValueError(\"Maintaining or reducing the number of neurons is not allowed\")\n",
    "class TrainModel:\n",
    "    def __init__(self, model, num_epochs, save_interval, loss_threshold=None):\n",
    "        self.model = model\n",
    "        self.num_epochs = num_epochs\n",
    "        self.save_interval = save_interval\n",
    "        self.loss_threshold = loss_threshold\n",
    "\n",
    "    def train(self):\n",
    "        optimizer = optim.Adam(self.model.parameters())\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            # Train the model\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = self.model(torch.randn(10, original_input_size))\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, torch.randn(10, original_output_size))\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save model checkpoint\n",
    "            if epoch % self.save_interval == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss\n",
    "                }, f\"original_model_{epoch}.pt\")\n",
    "\n",
    "            # Check loss threshold\n",
    "            if self.loss_threshold is not None and loss.item() < self.loss_threshold:\n",
    "                print(f\"Loss threshold reached at epoch {epoch}. Stopping training.\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f4a1f-37a5-46d1-b12b-2233732a84be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "original = torch.rand(1,4)\n",
    "original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da63d95c-c6ff-443c-a9b7-3c6003a7f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended = torch.rand(1,8)\n",
    "extended.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f1de9-af25-4b06-a82c-61cd2797082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3980874-a0ff-4079-bd3b-401c008a00b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1231f15-a408-452d-80a5-0ac3e7ef8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended[0,:original.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a58676-45ec-4166-b315-f15e6cbfe28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended[0,:original.size(1)].copy_(original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315ff37-edf2-480c-8a30-08836a987862",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"a\", \"b\",\"c\"]\n",
    "test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96087aa4-a0d0-4faf-bf44-96ed65345ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param.data[:old_param.size(0),:].copy_(old_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333639d-b2e5-4de7-90d3-3ce68e0242ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT = 2, hidden_layers = [4], N_OUTPUT = 1, activation='Tanh', initialization='Xavier'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation_functions = nn.ModuleDict([\n",
    "            [\"Tanh\", nn.Tanh()],\n",
    "            [\"ReLU\", nn.ReLU()],\n",
    "            [\"LeakyReLU\", nn.LeakyReLU()],\n",
    "            [\"Sigmoid\", nn.Sigmoid()],\n",
    "            [\"Softmax\", nn.Softmax(dim=-1)],\n",
    "        ])\n",
    "\n",
    "        if activation not in self.activation_functions:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.activation = self.activation_functions[activation]\n",
    "\n",
    "        # self.fci = nn.Linear(N_INPUT, hidden_layers[0])\n",
    "\n",
    "        # self.fch = nn.ModuleList([\n",
    "        #     nn.Sequential(\n",
    "        #         nn.Linear(hidden_layers[i], hidden_size),\n",
    "        #         self.activation\n",
    "        #     ) for i, hidden_size in enumerate(hidden_layers[1:])    # ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        # ])\n",
    "        self.fch = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(N_INPUT if i == 0 else hidden_size, hidden_size),\n",
    "                self.activation\n",
    "            ) for i, hidden_size in enumerate(hidden_layers[:])    # ) for i, hidden_size in enumerate(hidden_layers[1:])\n",
    "        ])\n",
    "\n",
    "        self.fco = nn.Linear(hidden_layers[-1], N_OUTPUT)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.activation(self.fci(x))\n",
    "        for layer in self.fch:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "    def initialize_parameters(self, initialization):\n",
    "        \n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if initialization == 'Uniform':\n",
    "                    init.uniform_(module.weight.data, -0.1, 0.1)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Normal':\n",
    "                    init.normal_(module.weight.data, mean=0, std=0.01)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Xavier':\n",
    "                    init.xavier_uniform_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'He':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Orthogonal':\n",
    "                    init.orthogonal_(module.weight.data)\n",
    "                    init.zeros_(module.bias.data)\n",
    "                elif initialization == 'Kaiming':\n",
    "                    init.kaiming_uniform_(module.weight.data, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                    init.zeros_(module.bias.data)\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported initialization type\")\n",
    "    \n",
    "    def plot_weights(self, figsize = (10,5)):\n",
    "        \n",
    "        self.figsize = figsize\n",
    "        \n",
    "        weights_biases_dict = self.state_dict()\n",
    "        #weights_biases_dict = {key: value for key, value in state_dict.items()}\n",
    "        \n",
    "        # Definition of columns, rows and subplots\n",
    "        num_subplots = len(weights_biases_dict)\n",
    "        num_cols = 2\n",
    "        num_rows = (num_subplots + num_cols - 1) // num_cols  \n",
    "        \n",
    "        # For colorbar (collect minimum and maximum values across all tensors)\n",
    "        all_values = np.concatenate([tensor.flatten() for tensor in weights_biases_dict.values()])\n",
    "        min_val = round(all_values.min(), 2)\n",
    "        max_val = round(all_values.max(), 2)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize = self.figsize)\n",
    "        \n",
    "        # Plot images and add values in each subplot\n",
    "        for i, (key, tensor) in enumerate(weights_biases_dict.items()):\n",
    "            row = i // num_cols\n",
    "            col = i % num_cols\n",
    "            ax = axs[row, col]\n",
    "            if 'weight' in key:\n",
    "                im = ax.imshow(tensor, cmap='viridis',vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            elif 'bias' in key:\n",
    "                im = ax.imshow(tensor.unsqueeze(0), cmap='viridis', vmin=min_val, vmax=max_val, interpolation='none')\n",
    "                ax.set_title(f'{key}', fontsize = 8)\n",
    "            #ax.axis('off')\n",
    "            \n",
    "            # If the data is 1D (possibly biases), reshape them to (1, len(data))\n",
    "            if len(tensor.shape) == 1:\n",
    "                tensor = tensor.reshape(1, -1)\n",
    "\n",
    "            # Add xticks and yticks\n",
    "            ax.set_xticks(np.arange(0, tensor.shape[1] , step=1))  \n",
    "            ax.tick_params(axis='x', labelsize = 8)\n",
    "            ax.set_yticks(np.arange(0, tensor.shape[0] , step=1))\n",
    "            ax.tick_params(axis='y', labelsize = 8)\n",
    "\n",
    "           \n",
    "            # Add values in the middle of the cell\n",
    "            for y in range(tensor.shape[0]):\n",
    "                for x in range(tensor.shape[1]):\n",
    "                    value = tensor[y, x]\n",
    "                    ax.text(x, y, f'{value:.2f}', fontsize = 8, color='white', ha='center', va='center')\n",
    "            \n",
    "         # Hide extra subplots\n",
    "        for i in range(num_subplots, num_rows * num_cols):\n",
    "            axs.flatten()[i].axis('off')\n",
    "            \n",
    "        # Add a title to the figure\n",
    "        plt.suptitle('Weights and Biases of the Neural Network')\n",
    "        \n",
    "        # Add a colorbar\n",
    "            # Set custom ticks and intervals\n",
    "        tick_interval = 0.2\n",
    "        ticks = np.arange(min_val, max_val, step=tick_interval)\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.25, 0.05, 0.5, 0.01])  # [left, bottom, width, height]\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal', ticks = ticks)\n",
    "        cbar.set_label('Range of Weights and Biases') \n",
    "        \n",
    "        # Show the plots\n",
    "        plt.show()\n",
    "\n",
    "class FCN_extended(FCN):\n",
    "    def __init__(self, N_INPUT, hidden_layers, N_OUTPUT, activation='Tanh', initialization='Xavier', original_model_path=None):\n",
    "        super().__init__(N_INPUT, hidden_layers, N_OUTPUT, activation, initialization)\n",
    "\n",
    "        self.initialize_parameters(initialization)\n",
    "        \n",
    "        self.original_model_path = original_model_path\n",
    "        self.original_state_dict = self.load_original_state_dict()\n",
    "        self.original_state_dict_keys = list(self.original_state_dict.keys()) \n",
    "        self.original_hidden_layers_neurons = self.original_state_dict[self.original_state_dict_keys[-4]].size(0)\n",
    "        self.original_hidden_layers_keys = [key for key in self.original_state_dict_keys if \"fch\" in key and \"weight\" in key]\n",
    "        self.original_hidden_layers_num = len(set([key.split('.')[-1] for key in self.original_hidden_layers_keys]))\n",
    "\n",
    "        #self.extended_neurons = hidden_layers[-1] # assuming that all hidden layers have the same number of neurons\n",
    "\n",
    "        self.copy_and_initialize_parameters()\n",
    "        \n",
    "        # # Check if hidden layers need to be extended\n",
    "        # if len(hidden_layers) < self.original_hidden_layers_num: \n",
    "        #     raise ValueError(f\"The number of hidden layers of the extended model({len(hidden_layers)}) must be larger as from the original model({self.original_hidden_layers_num})\")\n",
    "        # elif len(hidden_layers) > self.original_hidden_layers_num:\n",
    "        #     self.extend_hidden_layers()\n",
    "        # else:\n",
    "        #     self.extend_neurons() \n",
    "\n",
    "\n",
    "    def copy_and_initialize_parameters(self):\n",
    "        #current_model.initialize_parameters(initialization)  # Initialize current model first\n",
    "        for name, param in self.named_parameters():\n",
    "            print(\"next iteration\")\n",
    "            if name in self.original_state_dict:\n",
    "                print(name)\n",
    "                old_param = self.original_state_dict[name]\n",
    "                if param.shape == old_param.shape:\n",
    "                    print(\"same shape\")\n",
    "                    param.data.copy_(old_param)                    \n",
    "                else:\n",
    "                    if \"weight\" in name: \n",
    "                        if param.shape != old_param.shape:  # Mismatch in dimension 0: increasing neurons\n",
    "                            # Copy matching portion of old weights\n",
    "                            print(f\"weight in name and different size(0)\")\n",
    "                            print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                            \n",
    "                            param.data[:old_param.size(0), :old_param.size(1)].copy_(old_param)\n",
    "                        elif param.size(0) != old_param.size(0):  # Mismatch in dimension 0: increasing neurons\n",
    "                            # Copy matching portion of old weights\n",
    "                            print(f\"weight in name and different size(0)\")\n",
    "                            print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                            \n",
    "                            param.data[:old_param.size(0), :].copy_(old_param)                           \n",
    "                        elif param.size(0) != old_param.size(0) and \"fc0\" in name:\n",
    "                            print(f\"weight in name BUT equal size(0)\")\n",
    "                            print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                            \n",
    "                            param.data[0,:old_param.size(1)].copy_(old_param[0]) \n",
    "               \n",
    "                    if \"bias\" in name: \n",
    "                        print(\"bias in name\")\n",
    "                        if param.size(0) != old_param.size(0):  # Mismatch in dimension 0: increasing neurons\n",
    "                            print(f\"bias in name and different size(0)\")\n",
    "                            print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                            # Copy matching portion of old weights\n",
    "\n",
    "                            param.data[old_param.size(0):].copy_(old_param)\n",
    "                        else:\n",
    "                            print(f\"bias in name BUT equal size(0)\")\n",
    "                            print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "\n",
    "                            param.data.copy_(old_param)\n",
    "\n",
    "            print(\"end iteration\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # for name, param in self.named_parameters():\n",
    "        #     print(\"next iteration\")\n",
    "        #     if name in self.original_state_dict:\n",
    "        #         print(name)\n",
    "        #         old_param = self.original_state_dict[name]\n",
    "        #         if param.shape == old_param.shape:\n",
    "        #             print(\"same shape\")\n",
    "        #             param.data.copy_(old_param)                    \n",
    "        #         else:\n",
    "        #             print(\"different shape\")\n",
    "        #             print(name)\n",
    "        #             if \"weight\" in name: \n",
    "        #                 if param.size(0) != old_param.size(0):  # Mismatch in dimension 0: increasing neurons\n",
    "        #                     # Copy matching portion of old weights\n",
    "        #                     print(f\"weight in name and different size(0)\")\n",
    "        #                     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                            \n",
    "        #                     param.data[:old_param.size(0), :].copy_(old_param)\n",
    "        #                 else:\n",
    "        #                     print(f\"weight in name BUT equal size(0)\")\n",
    "        #                     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                            \n",
    "        #                     param.data[0,:old_param.size(1)].copy_(old_param[0])\n",
    "        #             if \"bias\" in name: \n",
    "        #                 print(\"bias in name\")\n",
    "        #                 if param.size(0) != old_param.size(0):  # Mismatch in dimension 0: increasing neurons\n",
    "        #                     print(f\"bias in name and different size(0)\")\n",
    "        #                     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "        #                     # Copy matching portion of old weights\n",
    "\n",
    "        #                     param.data[old_param.size(0):].copy_(old_param)\n",
    "        #                 else:\n",
    "        #                     print(f\"bias in name BUT equal size(0)\")\n",
    "        #                     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "\n",
    "        #                     param.data.copy_(old_param)\n",
    "\n",
    "        #     print(\"end iteration\")\n",
    "\n",
    "                    \n",
    "                    # if param.size(0) != old_param.size(0) and \"weight\" in name:  # Mismatch in dimension 0: increasing neurons\n",
    "                    #     # Copy matching portion of old weights\n",
    "                    #     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                    #     param.data[:old_param.size(0), :].copy_(old_param)\n",
    "                    # if param.size(0) != old_param.size(0) and \"bias\" in name:  # Mismatch in dimension 0: increasing neurons\n",
    "                    #     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                    #     # Copy matching portion of old weights\n",
    "                    #     param.data[:old_param.size(0)].copy_(old_param)\n",
    "                    #     # The rest of the weight tensor has been initialized by initialize_parameters\n",
    "                    # if param.size(1) != old_param.size(1):\n",
    "                    #     param.data[:, :old_param.size(1)].copy_(old_param)\n",
    "                    #     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                    # print(\"end iteration\")                    \n",
    "                    # if param.size(0) != old_param.size(0):# in \"weight\" in name:  # Mismatch in dimension 0: increasing neurons\n",
    "                    #     # Copy matching portion of old weights\n",
    "                    #     print(f\"Name: {name}, extended:{param.shape}, original: {old_param.shape}\")\n",
    "                    #     param.data[:old_param.size(0):, :].copy_(old_param)\n",
    "                    # # if param.size(0) != old_param.size(0) in \"bias\" in name:  # Mismatch in dimension 0: increasing neurons\n",
    "                    # #     # Copy matching portion of old weights\n",
    "                    # #     param.data[:old_param.size(0):, :].copy_(old_param)\n",
    "                    #     # The rest of the weight tensor has been initialized by initialize_parameters\n",
    "                    # if param.size(1) != old_param.size(1):\n",
    "                    #     param.data[:, :old_param.size(1)].copy_(old_param)\n",
    "\n",
    "\n",
    "            \n",
    "            #: and 'weight' in name:  # Check for matching weight parameters\n",
    "            # if name in self.original_state_dict and 'weight' in name:  # Check for matching weight parameters\n",
    "            #     old_param_weights = self.original_state_dict[name]\n",
    "            #     if param.size(0) != old_param_weights.size(0):  # Mismatch in dimension 0 for weights\n",
    "            #         # Copy matching portion of old weights\n",
    "            #         param.data[:old_param_weights.size(0)].copy_(old_param_weights)\n",
    "            #         # The rest of the weight tensor has been initialized by initialize_parameters\n",
    "            #     else:\n",
    "            #         # Direct copy if sizes match\n",
    "            #         print(param.shape)\n",
    "            #         param.data.copy_(old_param_weights)\n",
    "            # elif name in self.original_state_dict and 'bias' in name:  # Directly copy biases if present\n",
    "            #     old_param_biases = self.original_state_dict[name]\n",
    "            #     if param.size(0) != old_param_biases.size(0):  # Mismatch in dimension 1 for biases\n",
    "            #         # Copy matching portion of old biases\n",
    "            #         param.data[:old_param_biases.size(0)].copy_(old_param_biases)\n",
    "            #         # The rest of the biases tensor has been initialized by initialize_parameters\n",
    "            #     else:\n",
    "            #         # Direct copy if sizes match\n",
    "            #         param.data.copy_(old_param_biases)\n",
    "\n",
    "    \n",
    "    def load_original_state_dict(self):\n",
    "        if self.original_model_path is None:\n",
    "            raise ValueError(\"Path to the original model checkpoint is not provided.\")\n",
    "\n",
    "        if not os.path.exists(self.original_model_path):\n",
    "            raise FileNotFoundError(f\"Provided path '{self.original_model_path}' does not exist.\")\n",
    "\n",
    "        if not os.path.isfile(self.original_model_path):\n",
    "            raise ValueError(f\"Provided path '{self.original_model_path}' is not a file.\")\n",
    "\n",
    "        _, ext = os.path.splitext(self.original_model_path)\n",
    "        if ext not in ['.pt', '.pth']:\n",
    "            raise ValueError(\"Provided file is not a valid checkpoint file.\")\n",
    "        \n",
    "        # Load weights and biases from original_model\n",
    "        return torch.load(self.original_model_path)['model_state_dict']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TrainModel:\n",
    "    def __init__(self, model, num_epochs, save_interval, loss_threshold=None):\n",
    "        self.model = model\n",
    "        self.num_epochs = num_epochs\n",
    "        self.save_interval = save_interval\n",
    "        self.loss_threshold = loss_threshold\n",
    "\n",
    "    def train(self):\n",
    "        optimizer = optim.Adam(self.model.parameters())\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(1, self.num_epochs + 1):\n",
    "            # Train the model\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = self.model(torch.randn(10, original_input_size))\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, torch.randn(10, original_output_size))\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Save model checkpoint\n",
    "            if epoch % self.save_interval == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss\n",
    "                }, f\"original_model_{epoch}.pt\")\n",
    "\n",
    "            # Check loss threshold\n",
    "            if self.loss_threshold is not None and loss.item() < self.loss_threshold:\n",
    "                print(f\"Loss threshold reached at epoch {epoch}. Stopping training.\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6b963-09d3-434c-ba2e-0c499a33fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "original_input_size = 2\n",
    "original_hidden_layers = [4]\n",
    "original_output_size = 1\n",
    "original_model = FCN(original_input_size, original_hidden_layers, original_output_size, activation='Tanh', initialization='Xavier')\n",
    "original_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c0b50b-6b6f-4f7b-b96a-3bc3e43e870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.plot_weights(figsize = (10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751f596-47d2-4ebe-8ec2-cb901dfd504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train original model\n",
    "train_model = TrainModel(original_model, num_epochs=1000, save_interval=100, loss_threshold=0.01)\n",
    "train_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5921546-fb93-4c09-9d9c-3aa45df3ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c8c86-fa7c-4476-8e76-23e276bbd7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240abfb4-05d3-4b28-b178-5a3c17873450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extended model\n",
    "extended_input_size = 2\n",
    "extended_hidden_layers = [4,4]\n",
    "extended_output_size = 1\n",
    "extended_model = FCN_extended(extended_input_size, extended_hidden_layers, extended_output_size, activation='Tanh', initialization='Xavier', original_model_path='original_model_1000.pt')\n",
    "extended_model.plot_weights((15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f8bc5-00e3-4e5b-9244-bcac35bf0451",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7167143a-60e7-4c69-8859-8377d133b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train original model\n",
    "train_extended_model = TrainModel(extended_model, num_epochs=1000, save_interval=100, loss_threshold=0.01)\n",
    "train_extended_model.train()\n",
    "extended_model.plot_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2fe25b-8eb9-4f7c-9e4e-991b3a2aea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original model state and override weights\n",
    "#extended_model.load_override_original_weights_biases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4995617-0e1b-4ae9-a911-72912a7ac308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend neurons in hidden layers\n",
    "#extended_model.extend_neurons(num_neurons=8)\n",
    "#extended_model.plot_weights((15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac7a3c-c2b5-432a-ad3d-24eab392d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extended model\n",
    "extended1_input_size = 2\n",
    "extended1_hidden_layers = [8,8]\n",
    "extended1_output_size = 1\n",
    "extended1_model = FCN_extended(extended1_input_size, extended1_hidden_layers, extended1_output_size, activation='Tanh', initialization='Xavier', original_model_path='original_model_1000.pt')\n",
    "extended1_model.plot_weights((15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542a78f-a754-4d56-a056-c71cca91ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train original model\n",
    "train_extended1_model = TrainModel(extended1_model, num_epochs=1000, save_interval=100, loss_threshold=0.01)\n",
    "train_extended1_model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397acfc9-67c9-4c0f-889b-625b198c1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended1_model.plot_weights(figsize = (15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5930132-a188-48ad-a309-5f9c668b07ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extended model\n",
    "extended2_input_size = 2\n",
    "extended2_hidden_layers = [16,16,16,16]\n",
    "extended2_output_size = 1\n",
    "extended2_model = FCN_extended(extended2_input_size, extended2_hidden_layers, extended2_output_size, activation='Tanh', initialization='Xavier', original_model_path='original_model_1000.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b1c04-3b6a-4dea-b5d9-f1928e4757c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended2_model.plot_weights((40,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cb00b-5f6f-4300-b4f0-d26366e124d5",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f9582-03b1-457e-86eb-f2af1f18069e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ad520-0a86-4253-982d-9b861eaf85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_model.fch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b61696-2035-483f-bfb8-34d0f1a45b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if fch is not empty\n",
    "if original_model.fch:\n",
    "    # Print the length of fch\n",
    "    print(\"Number of modules in fch:\", len(original_model.fch))\n",
    "    \n",
    "    # Loop through each module in fch\n",
    "    for i, module in enumerate(original_model.fch):\n",
    "        print(f\"Module {i}:\")\n",
    "        # Check if the module is not empty\n",
    "        if module:\n",
    "            # Print the number of layers in the module\n",
    "            print(\"  Number of layers:\", len(module))\n",
    "        else:\n",
    "            print(\"  Empty module\")\n",
    "else:\n",
    "    print(\"fch is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf8f82-4cc4-4c8a-bb09-bfdc7100a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUT= 2\n",
    "hidden_layers = [4,4]\n",
    "for i , hidden_size in enumerate(hidden_layers[:]):\n",
    "    print(f\"nn.Linear(n: {i}, size: {hidden_size}, lenght of hidden_layers: {len(hidden_layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e9c04-312f-4700-b782-53a85f34af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUT = 2\n",
    "hidden_layers = [4,4]\n",
    "for i, hidden_size in enumerate(hidden_layers[:]):\n",
    "    input_size = N_INPUT if i == 0 else hidden_size\n",
    "    output_size = hidden_size\n",
    "    print( f\" nn.Linear({input_size}, {output_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741ff7b-4a91-42b8-bbcd-898ad134c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_size if i == 0 else hidden_sizes[i-1], hidden_size),\n",
    "                nn.ReLU()\n",
    "            ) for i, hidden_size in enumerate(hidden_sizes)\n",
    "        ])\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "# Example usage\n",
    "input_size = 2\n",
    "hidden_sizes = [4,4]\n",
    "output_size = 1\n",
    "\n",
    "model = SimpleModel(input_size, hidden_sizes, output_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2d230-2413-4c0e-8ff4-68be701e1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f1d9b-315a-425b-b4e0-3079be875793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state_dict without initializing the model first\n",
    "#loaded_state_dict = torch.load('simple_model_state_dict.pth')\n",
    "\n",
    "# Infer the length of hidden layers\n",
    "# Keys will be in the format of 'hidden_layers.0.0.weight', 'hidden_layers.1.0.weight', etc.\n",
    "hidden_layers_keys = [key for key in model.state_dict().keys() if 'hidden_layers' in key and  'weight' in key]\n",
    "hidden_layers_count = len(set([key.split('.')[1] for key in hidden_layers_keys]))\n",
    "#hidden_layers_count = set([key.split('.')[-1] for key in hidden_layers_keys])\n",
    "\n",
    "#hidden_layers_count = [key.split('.')[1] for key in hidden_layers_keys]\n",
    "\n",
    "print(f\"Length of hidden layers: {hidden_layers_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224f3cf-9e02-458d-9eb1-3e59d52a54eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(hidden_layers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1eafdf-961c-48b6-9f4e-f26a51b2bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e7240-2fa6-4da9-ab7d-5e63a291bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_keys = list(state_dict.keys())\n",
    "layer_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1bf50e-aa33-48c7-a709-0a9a2ba33e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_keys[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ecfed-86bb-4a58-9dc0-7b1b70f3079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict[layer_keys[-4]].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab3513-a727-4814-a0cd-92dde60e9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "visitor_ids = ['123', '356', '123', '501', '356', '123', '501', '789', '356']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec4334-930a-4c7e-be98-0b27e9657893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of visitor IDs to a set to remove duplicates\n",
    "unique_visitors = set(visitor_ids)\n",
    "\n",
    "# Now, unique_visitors contains only unique IDs\n",
    "print(f\"Unique visitor IDs: {unique_visitors}\")\n",
    "\n",
    "# The number of unique visitors\n",
    "print(f\"Number of unique visitors: {len(unique_visitors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57eb37a-779b-4b31-8e1f-b51de0bb2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the neural network architecture\n",
    "class MyNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 4),  # Input layer to hidden layer\n",
    "            nn.Sigmoid(),     # Apply activation function (e.g., sigmoid)\n",
    "            nn.Linear(4, 1)   # Hidden layer to output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instantiate the neural network model\n",
    "model = MyNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6e318-598a-43ef-8ad7-ecfcf0114b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa47b4-c8f5-449a-ad42-cc222af59c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the state dictionary of the model\n",
    "state_dict = model.state_dict()\n",
    "\n",
    "import numpy \n",
    "# Access the weights and biases\n",
    "weights_hidden = state_dict['model.0.weight'].numpy()\n",
    "biases_hidden = state_dict['model.0.bias'].numpy()\n",
    "weights_output = state_dict['model.1.weight'].numpy()\n",
    "biases_output = state_dict['model.1.bias'].numpy()\n",
    "\n",
    "# Print weights and biases\n",
    "print(\"Weights of Hidden Layer:\")\n",
    "print(weights_hidden)\n",
    "print(\"\\nBiases of Hidden Layer:\")\n",
    "print(biases_hidden)\n",
    "print(\"\\nWeights of Output Layer:\")\n",
    "print(weights_output)\n",
    "print(\"\\nBiases of Output Layer:\")\n",
    "print(biases_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba2e6af-df2c-4dd6-8f88-a89352f975c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d256c5-56c5-4196-a2c8-cdc39d0ddb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FlexibleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(FlexibleNN, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        # Input layer to first hidden layer\n",
    "        layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "        layers.append(nn.Tanh())\n",
    "\n",
    "        # Adding variable number of hidden layers\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            layers.append(nn.Linear(hidden_sizes[i-1], hidden_sizes[i]))\n",
    "            layers.append(nn.Tanh())\n",
    "\n",
    "        # Adding the final output layer\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_size = 2  # Input features\n",
    "hidden_sizes = [4, 3, 2]  # Sizes of hidden layers\n",
    "output_size = 1  # Output features\n",
    "\n",
    "# Create an instance of the network with the specified architecture\n",
    "net = FlexibleNN(input_size, hidden_sizes, output_size)\n",
    "\n",
    "# Example input\n",
    "example_input = torch.rand(1, input_size)\n",
    "\n",
    "# Forward pass through the network\n",
    "output = net(example_input)\n",
    "\n",
    "print(\"Output:\", output)\n",
    "\n",
    "# Displaying the weights and biases\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fcba57-f254-48dc-8a21-b6ad68683f58",
   "metadata": {},
   "source": [
    "# Variance of the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe418c5-24ba-47da-a5ba-55fb88b9ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.init as init\n",
    "\n",
    "# Function to initialize tensors and calculate variance\n",
    "def initialize_and_calculate_variance(initialization_fn):\n",
    "    # Initialize tensor\n",
    "    tensor = torch.empty(8, 2)\n",
    "    initialization_fn(tensor)\n",
    "\n",
    "    # Calculate variance of the tensor\n",
    "    variance = torch.var(tensor)\n",
    "\n",
    "    return tensor, variance.item()\n",
    "\n",
    "# Function to trim tensors and calculate variance\n",
    "def trim_and_calculate_variance(tensor):\n",
    "    # Trim tensor to last 4 rows\n",
    "    trimmed_tensor = tensor[-4:, :]\n",
    "\n",
    "    # Calculate variance of the trimmed tensor\n",
    "    variance = torch.var(trimmed_tensor)\n",
    "\n",
    "    return trimmed_tensor, variance.item()\n",
    "\n",
    "# List of initialization methods\n",
    "initialization_methods = [\n",
    "    init.uniform_,\n",
    "    init.normal_,\n",
    "    init.xavier_uniform_,\n",
    "    init.orthogonal_,\n",
    "    init.kaiming_uniform_\n",
    "]\n",
    "\n",
    "# Initialize and calculate variance for each method\n",
    "initial_tensors = []\n",
    "initial_variances = []\n",
    "trimmed_tensors = []\n",
    "trimmed_variances = []\n",
    "\n",
    "for initialization_method in initialization_methods:\n",
    "    # Initialize tensor and calculate variance\n",
    "    tensor, variance = initialize_and_calculate_variance(initialization_method)\n",
    "    initial_tensors.append(tensor)\n",
    "    initial_variances.append(variance)\n",
    "\n",
    "    # Trim tensor and calculate variance\n",
    "    trimmed_tensor, trimmed_variance = trim_and_calculate_variance(tensor)\n",
    "    trimmed_tensors.append(trimmed_tensor)\n",
    "    trimmed_variances.append(trimmed_variance)\n",
    "\n",
    "# Print initial variances\n",
    "print(\"Initial variances:\")\n",
    "for method, variance in zip(initialization_methods, initial_variances):\n",
    "    print(f\"{method.__name__}: {variance:.4f}\")\n",
    "\n",
    "# Print trimmed variances\n",
    "print(\"\\nTrimmed variances:\")\n",
    "for method, variance in zip(initialization_methods, trimmed_variances):\n",
    "    print(f\"{method.__name__}: {variance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c11b6-48ee-4352-84a2-1533f7d8e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "# Function to initialize tensors and calculate variance\n",
    "def initialize_and_calculate_variance(initialization_fn):\n",
    "    # Initialize tensor\n",
    "    tensor = torch.empty(8, 2)\n",
    "    initialization_fn(tensor)\n",
    "\n",
    "    # Apply Tanh activation function\n",
    "    tensor = F.tanh(tensor)\n",
    "\n",
    "    # Calculate variance of the tensor\n",
    "    variance = torch.var(tensor)\n",
    "\n",
    "    return tensor, variance.item()\n",
    "\n",
    "# Function to trim tensors and calculate variance\n",
    "def trim_and_calculate_variance(tensor):\n",
    "    # Trim tensor to last 4 rows\n",
    "    trimmed_tensor = tensor[-4:, :]\n",
    "\n",
    "    # Calculate variance of the trimmed tensor\n",
    "    variance = torch.var(trimmed_tensor)\n",
    "\n",
    "    return trimmed_tensor, variance.item()\n",
    "\n",
    "# List of initialization methods\n",
    "initialization_methods = [\n",
    "    init.uniform_,\n",
    "    init.normal_,\n",
    "    init.xavier_uniform_,\n",
    "    init.orthogonal_,\n",
    "    init.kaiming_uniform_\n",
    "]\n",
    "\n",
    "# Initialize and calculate variance for each method\n",
    "initial_tensors = []\n",
    "initial_variances = []\n",
    "trimmed_tensors = []\n",
    "trimmed_variances = []\n",
    "\n",
    "for initialization_method in initialization_methods:\n",
    "    # Initialize tensor and calculate variance\n",
    "    tensor, variance = initialize_and_calculate_variance(initialization_method)\n",
    "    initial_tensors.append(tensor)\n",
    "    initial_variances.append(variance)\n",
    "\n",
    "    # Trim tensor and calculate variance\n",
    "    trimmed_tensor, trimmed_variance = trim_and_calculate_variance(tensor)\n",
    "    trimmed_tensors.append(trimmed_tensor)\n",
    "    trimmed_variances.append(trimmed_variance)\n",
    "\n",
    "# Print initial variances\n",
    "print(\"Initial variances (with Tanh activation):\")\n",
    "for method, variance in zip(initialization_methods, initial_variances):\n",
    "    print(f\"{method.__name__}: {variance:.4f}\")\n",
    "\n",
    "# Print trimmed variances\n",
    "print(\"\\nTrimmed variances (with Tanh activation):\")\n",
    "for method, variance in zip(initialization_methods, trimmed_variances):\n",
    "    print(f\"{method.__name__}: {variance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82d527-e46c-45a7-8620-217cf1958c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i % 2 == 0:\n",
    "        continue  # Skip even numbers\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed71915-32e1-4d2c-9a8c-a43cf32c1298",
   "metadata": {},
   "source": [
    "### Interactive visualization in matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80eb7999-05ab-476d-a148-58cb299ecd4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T09:07:35.623255Z",
     "iopub.status.busy": "2024-02-29T09:07:35.622765Z",
     "iopub.status.idle": "2024-02-29T09:07:36.737055Z",
     "shell.execute_reply": "2024-02-29T09:07:36.736267Z",
     "shell.execute_reply.started": "2024-02-29T09:07:35.623216Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import any of the following Qt binding modules: PyQt5, PySide2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Switch to an interactive backend (e.g., 'qt5')\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mqt5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Your plotting code\u001b[39;00m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2432\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2430\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2432\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2436\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m backends_list)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3621\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3617\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWarning: Cannot change to a different GUI toolkit: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3618\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (gui, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select))\n\u001b[1;32m   3619\u001b[0m         gui, backend \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mfind_gui_and_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select)\n\u001b[0;32m-> 3621\u001b[0m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivate_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m configure_inline_support(\u001b[38;5;28mself\u001b[39m, backend)\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;66;03m# Now we must activate the gui pylab wants to use, and fix %run to take\u001b[39;00m\n\u001b[1;32m   3625\u001b[0m \u001b[38;5;66;03m# plot updates into account\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/pylabtools.py:368\u001b[0m, in \u001b[0;36mactivate_matplotlib\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# Due to circular imports, pyplot may be only partially initialised\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# when this function runs.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# So avoid needing matplotlib attribute-lookup to access pyplot.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m--> 368\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswitch_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow\u001b[38;5;241m.\u001b[39m_needmain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# We need to detect at runtime whether show() is called by the user.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# For this, we wrap it into a decorator which adds a 'called' flag.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/pyplot.py:342\u001b[0m, in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# have to escape the switch on access logic\u001b[39;00m\n\u001b[1;32m    340\u001b[0m old_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(rcParams, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 342\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_module_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewbackend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m canvas_class \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mFigureCanvas\n\u001b[1;32m    345\u001b[0m required_framework \u001b[38;5;241m=\u001b[39m canvas_class\u001b[38;5;241m.\u001b[39mrequired_interactive_framework\n",
      "File \u001b[0;32m/usr/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backends/backend_qt5agg.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backends\n\u001b[1;32m      6\u001b[0m backends\u001b[38;5;241m.\u001b[39m_QT_FORCE_QT5_BINDING \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_qtagg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (    \u001b[38;5;66;03m# noqa: F401, E402 # pylint: disable=W0611\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     _BackendQTAgg, FigureCanvasQTAgg, FigureManagerQT, NavigationToolbar2QT,\n\u001b[1;32m      9\u001b[0m     FigureCanvasAgg, FigureCanvasQT)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;129m@_BackendQTAgg\u001b[39m\u001b[38;5;241m.\u001b[39mexport\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_BackendQT5Agg\u001b[39;00m(_BackendQTAgg):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backends/backend_qtagg.py:9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mctypes\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bbox\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqt_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QT_API, QtCore, QtGui\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_agg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasAgg\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_qt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _BackendQT, FigureCanvasQT\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/matplotlib/backends/qt_compat.py:133\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    134\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import any of the following Qt binding modules: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m             \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([QT_API \u001b[38;5;28;01mfor\u001b[39;00m _, QT_API \u001b[38;5;129;01min\u001b[39;00m _candidates]))\n\u001b[1;32m    136\u001b[0m         )\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# We should not get there.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected QT_API: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mQT_API\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import any of the following Qt binding modules: PyQt5, PySide2"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Switch to an interactive backend (e.g., 'qt5')\n",
    "%matplotlib qt5\n",
    "\n",
    "# Your plotting code\n",
    "plt.figure()\n",
    "t = np.arange(0.0, 2.0, 0.01)\n",
    "s = 1 + np.sin(2 * np.pi * t)\n",
    "plt.plot(t, s)\n",
    "\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('voltage (mV)')\n",
    "plt.title('About as simple as it gets, folks')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb73b6b-fc6d-4590-acb6-6fd4a069890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cba6e0-a645-412a-b5cc-3b876bf2c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972daa6c-75c8-44fa-9276-d81273efc6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyQt5\n",
    "!pip install PyQt5\n",
    "# or install PySide2\n",
    "!pip install PySide2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d24d5-4db1-489c-b589-6044f5aa0f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb473fe-c2ad-453f-8c1c-55fcd03db383",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b373948-6fde-435a-853e-8926eac3a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt5\n",
    "print(PyQt5.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e4f4c-bdc1-4427-b001-fd10e844eff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "/home/luis/.local/lib/python3 -m pip install PyQt5 PySide2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4705b2-51d9-48f1-8ecb-fc53f79c37aa",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4ed6d1-6921-45ef-8919-4661fa836696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create some data to display\n",
    "data1 = np.random.rand(10, 10)\n",
    "data2 = np.random.rand(20, 20)\n",
    "\n",
    "# Create a figure with two subplots with different sizes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5),\n",
    "                               gridspec_kw={'width_ratios': [1, 2], 'height_ratios': [1]})\n",
    "\n",
    "# Display data in the first subplot\n",
    "im1 = ax1.imshow(data1)\n",
    "ax1.set_title('Smaller Plot')\n",
    "\n",
    "# Display data in the second subplot, which is larger due to the width_ratios argument\n",
    "im2 = ax2.imshow(data2)\n",
    "ax2.set_title('Larger Plot')\n",
    "\n",
    "# Automatically adjust subplot parameters to give specified padding\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b9ca0-d5ec-48a0-a634-5d689d55f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming state_dict is a dictionary with keys 'layer_x.weights', 'layer_x.biases'\n",
    "# For the sake of example, let's create dummy tensors with the correct shapes\n",
    "state_dict = {\n",
    "    'layer_1.weights': np.random.rand(4, 2),  # From 2 to 4 neurons\n",
    "    'layer_1.biases': np.random.rand(4),\n",
    "    'layer_2.weights': np.random.rand(4, 4),  # From 4 to 4 neurons\n",
    "    'layer_2.biases': np.random.rand(4),\n",
    "    'layer_3.weights': np.random.rand(1, 4),  # From 4 to 1 neuron\n",
    "    'layer_3.biases': np.random.rand(1)\n",
    "}\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10, 15),\n",
    "                         gridspec_kw={'height_ratios': [4, 4, 1]})  # Adjust height ratios based on layer output size\n",
    "\n",
    "for i, layer in enumerate(['layer_1', 'layer_2', 'layer_3']):\n",
    "    weights = state_dict[f'{layer}.weights']\n",
    "    biases = state_dict[f'{layer}.biases']\n",
    "    \n",
    "    # Plot weights matrix\n",
    "    ax = axes[i, 0]\n",
    "    cax = ax.matshow(weights, cmap='viridis')\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "    ax.set_title(f'{layer} Weights')\n",
    "    \n",
    "    # Plot biases vector as a 2D array for consistent visualization\n",
    "    ax = axes[i, 1]\n",
    "    cax = ax.matshow(biases.reshape(-1, 1), cmap='viridis')\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "    ax.set_title(f'{layer} Biases')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf20654-11c8-4aa6-add3-1953454d6906",
   "metadata": {},
   "source": [
    "## Class inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c1ad85-6748-471e-83f4-4e65dc90dc76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T08:21:12.540101Z",
     "iopub.status.busy": "2024-03-05T08:21:12.539611Z",
     "iopub.status.idle": "2024-03-05T08:21:12.557444Z",
     "shell.execute_reply": "2024-03-05T08:21:12.556388Z",
     "shell.execute_reply.started": "2024-03-05T08:21:12.540043Z"
    }
   },
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        # Initialization specific to A\n",
    "        self.A_method()\n",
    "\n",
    "    def A_method(self):\n",
    "        print(\"A_method called. Instance of class A.\")\n",
    "\n",
    "    def shared_method(self):\n",
    "        print(\"This is a shared method from A.\")\n",
    "\n",
    "class B(A):\n",
    "    def __init__(self):\n",
    "        # B's own initialization, not calling A's __init__\n",
    "        self.B_method()\n",
    "\n",
    "    def B_method(self):\n",
    "        print(\"B_instance_name\")\n",
    "\n",
    "    # Inheriting shared_method from A is automatic because we do not override it here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929ff5d8-65cc-4d45-9446-f1a7ebe6ace3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T08:21:13.223705Z",
     "iopub.status.busy": "2024-03-05T08:21:13.223326Z",
     "iopub.status.idle": "2024-03-05T08:21:13.230522Z",
     "shell.execute_reply": "2024-03-05T08:21:13.229176Z",
     "shell.execute_reply.started": "2024-03-05T08:21:13.223672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_method called. Instance of class A.\n",
      "This is a shared method from A.\n",
      "B_instance_name\n",
      "This is a shared method from A.\n"
     ]
    }
   ],
   "source": [
    "a_instance = A()  # This should print \"A_method called. Instance of class A.\"\n",
    "a_instance.shared_method()  # This should print \"This is a shared method from A.\"\n",
    "\n",
    "b_instance = B()  # This should print \"B_instance_name\"\n",
    "b_instance.shared_method()  # This should also print \"This is a shared method from A.\", showing inheritance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d9146c-1b70-40b0-85b3-0cf1c8979dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
